# app/polza_client.py
from __future__ import annotations

import base64
import hashlib
import io
import json
import logging
import mimetypes
import os
import re
import time
from typing import List, Dict, Any, Optional, Union, Tuple, Iterable

from openai import OpenAI
import requests

from .config import Cfg  # –∫–ª—é—á–∏/–º–æ–¥–µ–ª–∏/–±–∞–∑–æ–≤—ã–π URL
from .templates import build_describe_prompt, build_extract_prompt

# Pillow ‚Äî –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ (–¥–∞—É–Ω—Å–∫–µ–π–ª/—Å–∂–∞—Ç–∏–µ). –ï—Å–ª–∏ –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º raw-–±–∞–π—Ç—ã.
try:
    from PIL import Image  # type: ignore
    _PIL_OK = True
except Exception:
    _PIL_OK = False


# -----------------------------
# –ö–ª–∏–µ–Ω—Ç Polza (OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π)
# -----------------------------
_client = OpenAI(
    base_url=(Cfg.BASE_POLZA or "").rstrip("/"),
    api_key=Cfg.POLZA_KEY,
)

__all__ = [
    "embeddings",
    "chat_with_gpt",
    "chat_with_gpt_stream",
    # –Ω–æ–≤–æ–µ:
    "chat_with_gpt_multimodal",
    "chat_with_gpt_stream_multimodal",
    "probe_embedding_dim",
    "vision_describe",
    "vision_describe_many",
    "vision_extract_values",
    "vision_extract_table_values",  # <‚Äî –¥–æ–±–∞–≤–∏–ª–∏
    "vision_describe_with_values",  # –Ω–æ–≤—ã–π —Ä–µ–∂–∏–º: –æ–ø–∏—Å–∞–Ω–∏–µ + –ø–æ–ø—ã—Ç–∫–∞ –≤—ã—Ç–∞—â–∏—Ç—å —á–∏—Å–ª–∞
]

# -----------------------------
# –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Ö–µ–ª–ø–µ—Ä—ã
# -----------------------------

# –£–¥–∞–ª—è–µ–º —É–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –ø–æ–ª–æ–º–∞—Ç—å JSON –≤ SSE –ø–æ—Ç–æ–∫–∞—Ö (–∫—Ä–æ–º–µ \t, \r, \n)
_CTRL_BAD = re.compile(r"[\x00-\x08\x0B\x0C\x0E-\x1F]")

def _sanitize_text_for_json(s: str) -> str:
    """
    –£–±–∏—Ä–∞–µ–º —Å–∏–º–≤–æ–ª—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è + U+2028/U+2029 (line/para sep), –∞ —Ç–∞–∫–∂–µ –æ–¥–∏–Ω–æ—á–Ω—ã–µ –æ–±—Ä–∞—Ç–Ω—ã–µ —Å–ª—ç—à–∏
    –Ω–∞ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏–Ω–æ–≥–¥–∞ –ª–æ–º–∞—é—Ç —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—é —É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤.
    """
    t = (s or "")
    t = _CTRL_BAD.sub(" ", t)
    t = t.replace("\u2028", " ").replace("\u2029", " ")
    # –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –∫–µ–π—Å ¬´–Ω–µ–∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏¬ª: —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ–¥–∏–Ω–æ—á–Ω—ã–π –±—ç–∫—Å–ª—ç—à
    if t.endswith("\\"):
        t = t[:-1] + " "
    return t


def _sanitize_messages(messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    –°–∞–Ω–∏—Ç–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å–æ–æ–±—â–µ–Ω–∏–π:
    - message['content'] –µ—Å–ª–∏ —ç—Ç–æ str;
    - content-–ø–∞—Ä—Ç {"type":"text","text":...} –µ—Å–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç ‚Äî –º–∞—Å—Å–∏–≤ —á–∞—Å—Ç–µ–π.
    –û—Å—Ç–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ (image_url –∏ —Ç.–ø.) –Ω–µ —Ç—Ä–æ–≥–∞–µ–º.
    """
    out: List[Dict[str, Any]] = []
    for m in (messages or []):
        mm = dict(m)
        c = mm.get("content")
        if isinstance(c, str):
            mm["content"] = _sanitize_text_for_json(c)
        elif isinstance(c, list):
            parts: List[Any] = []
            for p in c:
                if isinstance(p, dict) and p.get("type") == "text":
                    q = dict(p)
                    q["text"] = _sanitize_text_for_json(str(q.get("text", "")))
                    parts.append(q)
                else:
                    parts.append(p)
            mm["content"] = parts
        out.append(mm)
    return out


def _chunk_text(s: str, maxlen: int = 480) -> Iterable[str]:
    """
    –ê–∫–∫—É—Ä–∞—Ç–Ω–æ —Ä–µ–∂–µ–º –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —á–∞—Å—Ç—è–º–∏.
    """
    s = s or ""
    if not s:
        return []
    i, n = 0, len(s)

    def _cut_point(seg: str, limit: int) -> int:
        if len(seg) <= limit:
            return len(seg)
        for token in ("\n", ". ", " "):
            pos = seg.rfind(token, 0, limit)
            if pos != -1:
                return pos + (0 if token == "\n" else len(token))
        return limit

    while i < n:
        cut = _cut_point(s[i:], maxlen)
        yield s[i:i + cut]
        i += cut


def _file_bytes(path: str) -> bytes:
    with open(path, "rb") as f:
        return f.read()


def _detect_mime(path: str, data: Optional[bytes] = None) -> str:
    # 1) –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
    mime, _ = mimetypes.guess_type(path)
    if mime:
        return mime
    # 2) –ø–æ –ø—Ä–æ—Å—Ç—ã–º —Å–∏–≥–Ω–∞—Ç—É—Ä–∞–º
    b = data or b""
    if b.startswith(b"\xff\xd8"):
        return "image/jpeg"
    if b.startswith(b"\x89PNG\r\n\x1a\n"):
        return "image/png"
    if b.startswith(b"GIF87a") or b.startswith(b"GIF89a"):
        return "image/gif"
    if b[:4] in (b"II*\x00", b"MM\x00*"):
        return "image/tiff"
    return "application/octet-stream"


def _sha256_file(path: str) -> str:
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(65536), b""):
            h.update(chunk)
    return h.hexdigest()


def _resize_and_encode_base64(path: str) -> Tuple[str, int]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (data_url, size_bytes). –£—á–∏—Ç—ã–≤–∞–µ—Ç –ª–∏–º–∏—Ç—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞.
    –ï—Å–ª–∏ Pillow –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî –∫–æ–¥–∏—Ä—É–µ–º –∫–∞–∫ –µ—Å—Ç—å (–º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ –ª–∏–º–∏—Ç–∞).
    """
    raw = _file_bytes(path)
    mime = _detect_mime(path, raw)

    # –ï—Å–ª–∏ PIL –µ—Å—Ç—å ‚Äî –¥–∞—É–Ω—Å–∫–µ–π–ª–∏–º –¥–ª–∏–Ω–Ω—É—é —Å—Ç–æ—Ä–æ–Ω—É –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JPEG/PNG
    if _PIL_OK:
        try:
            img = Image.open(io.BytesIO(raw))
            img = img.convert("RGB")  # –≤–æ –∏–∑–±–µ–∂–∞–Ω–∏–µ —ç–∫–∑–æ—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∂–∏–º–æ–≤
            max_side = int(getattr(Cfg, "VISION_MAX_SIDE_PX", 2048) or 2048)
            w, h = img.size
            scale = 1.0
            if max(w, h) > max_side:
                scale = max_side / float(max(w, h))
                new_size = (max(1, int(w * scale)), max(1, int(h * scale)))
                img = img.resize(new_size, Image.LANCZOS)

            # JPEG –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–µ–µ –ø–æ —Ä–∞–∑–º–µ—Ä—É
            out = io.BytesIO()
            img.save(out, format="JPEG", quality=int(getattr(Cfg, "VISION_JPEG_QUALITY", 88) or 88), optimize=True)
            data = out.getvalue()
            out.close()

            # –ï—Å–ª–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ ‚Äî –µ—â—ë —Ä–∞–∑ —É–∂–º—ë–º –∫–∞—á–µ—Å—Ç–≤–æ–º
            max_bytes = int(getattr(Cfg, "VISION_MAX_IMAGE_BYTES", 2_500_000) or 2_500_000)
            if len(data) > max_bytes:
                q = max(40, int((getattr(Cfg, "VISION_JPEG_QUALITY", 88) or 88) * 0.75))
                out2 = io.BytesIO()
                img.save(out2, format="JPEG", quality=q, optimize=True)
                data2 = out2.getvalue()
                out2.close()
                if len(data2) < len(data):
                    data = data2

            mime = "image/jpeg"
            b64 = base64.b64encode(data).decode("ascii")
            return (f"data:{mime};base64,{b64}", len(data))
        except Exception:
            # –§–æ–ª–±—ç–∫ ‚Äî –∫–∞–∫ –µ—Å—Ç—å
            pass

    b64 = base64.b64encode(raw).decode("ascii")
    return (f"data:{mime};base64,{b64}", len(raw))


def _path_is_url(p: str) -> bool:
    return bool(re.match(r"^https?://", str(p).strip(), flags=re.IGNORECASE))


def _image_part_for(path: str) -> Optional[Dict[str, Any]]:
    """
    –ì–æ—Ç–æ–≤–∏—Ç message part –ø–æ–¥ OpenAI/Polza:
      {"type":"image_url","image_url":{"url":"data:..."}}
    –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –ø–æ Cfg.VISION_IMAGE_TRANSPORT.
    """
    if not path:
        return None
    # —Ñ–∏–ª—å—Ç—Ä —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π (–º—è–≥–∫–∏–π)
    ext = os.path.splitext(path)[1].lstrip(".").lower()
    try:
        if ext and hasattr(Cfg, "is_image_ext_allowed") and not Cfg.is_image_ext_allowed(ext):
            # –≤—Å—ë —Ä–∞–≤–Ω–æ –ø–æ–ø—Ä–æ–±—É–µ–º ‚Äî –º–Ω–æ–≥–∏–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É—é—Ç –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è/—Å –≤–µ–±–ø–æ–º –∏ —Ç.–ø.
            pass
    except Exception:
        pass

    if _path_is_url(path):
        return {"type": "image_url", "image_url": {"url": path}}

    transport = (getattr(Cfg, "VISION_IMAGE_TRANSPORT", "base64") or "base64").lower()

    if transport == "url":
        # –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –ø—Ä–∏ —Ä–µ–∂–∏–º–µ url ‚Äî –º—è–≥–∫–∏–π —Ñ–æ–ª–±—ç–∫ –≤ base64 (data:)
        data_url, _ = _resize_and_encode_base64(path)
        return {"type": "image_url", "image_url": {"url": data_url}}

    # –±–∞–∑–æ–≤—ã–π —Å–ª—É—á–∞–π ‚Äî base64 (data:)
    data_url, _ = _resize_and_encode_base64(path)
    return {"type": "image_url", "image_url": {"url": data_url}}


def _sanitize_description(s: str) -> str:
    """
    –ü—Ä–∏–≤–æ–¥–∏–º –æ—Ç–≤–µ—Ç –ø–æ–¥ –≤—Å—Ç–∞–≤–∫—É –≤ ¬´‚Ä¶ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ ___¬ª. –£–±–∏—Ä–∞–µ–º –≤–≤–æ–¥–Ω—ã–µ, —Å–∂–∏–º–∞–µ–º –¥–æ 1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
    """
    t = (s or "").strip()
    repl = {
        "–ù–∞ —Ä–∏—Å—É–Ω–∫–µ –ø–æ–∫–∞–∑–∞–Ω–æ": "",
        "–ù–∞ —Ä–∏—Å—É–Ω–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ": "",
        "–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –ø–æ–∫–∞–∑–∞–Ω–æ": "",
        "–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ": "",
        "–ù–∞ —Ñ–æ—Ç–æ –ø–æ–∫–∞–∑–∞–Ω–æ": "",
        "–ù–∞ —Ñ–æ—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ": "",
        "–†–∏—Å—É–Ω–æ–∫ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç": "",
        "–î–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç": "",
        "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç": "",
    }
    for k, v in repl.items():
        t = t.replace(k, v)
    t = t.replace("–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è", "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∞")
    t = " ".join(t.split())
    if "." in t:
        t = t.split(".")[0] + "."
    return t if t else "—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–æ–ø–∏—Å–∞–Ω–∏–µ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ)."


# –ü—Ä–æ—Å—Ç–µ–Ω—å–∫–∏–π in-memory –∫—ç—à (–Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å)
_VISION_CACHE: Dict[Tuple[str, str, str], Dict[str, Any]] = {}

# –î–∏—Å–∫–æ–≤—ã–π –∫—ç—à (–ø–µ—Ä–µ–∂–∏–≤–∞–µ—Ç —Ä–µ—Å—Ç–∞—Ä—Ç –ø—Ä–æ—Ü–µ—Å—Å–∞)
def _vcache_path(key: Tuple[str, str, str]) -> str:
    # –∫–ª—é—á –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–ª–∏–Ω–Ω—ã–º ‚Äî —Ö—ç—à–∏—Ä—É–µ–º –≤ –∏–º—è —Ñ–∞–π–ª–∞
    h = hashlib.sha256("|".join(key).encode("utf-8")).hexdigest()
    return os.path.join(getattr(Cfg, "VISION_CACHE_DIR", "/tmp/vision_cache"), f"{h}.json")

def _vcache_get(key: Tuple[str, str, str]) -> Optional[Dict[str, Any]]:
    try:
        fp = _vcache_path(key)
        if os.path.exists(fp):
            with open(fp, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    return None

def _vcache_put(key: Tuple[str, str, str], data: Dict[str, Any]) -> None:
    try:
        os.makedirs(getattr(Cfg, "VISION_CACHE_DIR", "/tmp/vision_cache"), exist_ok=True)
        fp = _vcache_path(key)
        payload = dict(data)
        payload["_cached_at"] = int(time.time())
        with open(fp, "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False)
    except Exception:
        pass


# -----------------------------
# –ü—É–±–ª–∏—á–Ω—ã–µ API ‚Äî —Ç–µ–∫—Å—Ç
# -----------------------------

def embeddings(texts: List[str]) -> List[List[float]]:
    if not texts:
        return []
    try:
        resp = _client.embeddings.create(
            model=Cfg.POLZA_EMB,
            input=texts,
        )
        return [item.embedding for item in resp.data]
    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: %s", e)
        raise


def chat_with_gpt(
    messages: List[Dict[str, Any]],
    temperature: float = 0.2,
    max_tokens: int = 800,
    **extra: Any,
) -> str:
    """
    –ù–µ—Å—Ç—Ä–∏–º–æ–≤—ã–π —á–∞—Ç-–≤—ã–∑–æ–≤ (—Å —Å–∞–Ω–∞—Ü–∏–µ–π —Å–æ–æ–±—â–µ–Ω–∏–π).
    –í–ê–ñ–ù–û: —É–º–µ–µ—Ç "–¥–æ–∑–∞–∫–∞–∑—ã–≤–∞—Ç—å" –æ—Ç–≤–µ—Ç, –µ—Å–ª–∏ completion –æ–±–æ—Ä–≤–∞–ª–∞—Å—å (finish_reason != 'stop').
    """
    try:
        smsg = _sanitize_messages(messages)

        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏: –µ—Å–ª–∏ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö –µ—Å—Ç—å image_url ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º vision-–º–æ–¥–µ–ª—å.
        use_vision = any(
            isinstance(m.get("content"), list)
            and any(isinstance(p, dict) and p.get("type") == "image_url" for p in m["content"])
            for m in smsg
        )
        model = Cfg.vision_model() if (use_vision and Cfg.vision_active()) else Cfg.POLZA_CHAT

        # –§–∏–ª—å—Ç—Ä—É–µ–º extra, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ—Ç–µ—Ä–µ—Ç—å –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –∫–ª—é—á–∏
        blocked = {"model", "messages", "temperature", "max_tokens", "stream"}
        pass_extra = {k: v for k, v in (extra or {}).items() if k not in blocked}

        # ---- helper: –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å ----
        def _one_call(msgs: List[Dict[str, Any]]) -> Any:
            return _client.chat.completions.create(
                model=model,
                messages=msgs,
                temperature=temperature,
                max_tokens=max_tokens,
                **pass_extra,
            )

        # ---- 1) –ø–µ—Ä–≤—ã–π –æ—Ç–≤–µ—Ç ----
        cmpl = _one_call(smsg)

        choice = (cmpl.choices or [None])[0]
        if not choice or not getattr(choice, "message", None):
            return ""

        text = ((choice.message.content or "") if hasattr(choice.message, "content") else "") or ""
        text = text.strip()

        finish_reason = getattr(choice, "finish_reason", None) or ""

        # ---- 2) –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –æ–±–æ—Ä–≤–∞–Ω ‚Äî –¥–æ–∑–∞–∫–∞–∑—ã–≤–∞–µ–º "–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ" ----
        # –ò–Ω–æ–≥–¥–∞ API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫—É—Å–æ–∫, –Ω–æ finish_reason –Ω–µ 'stop' ‚Üí —ç—Ç–æ –∏ –µ—Å—Ç—å "–æ–±—Ä—ã–≤".
        # –î–æ–∑–∞–∫–∞–∑ –¥–µ–ª–∞–µ–º –∞–∫–∫—É—Ä–∞—Ç–Ω–æ: –ø–µ—Ä–µ–¥–∞–µ–º —É–∂–µ –≤—ã–¥–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –ø—Ä–æ—Å–∏–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å.
        max_continuations = 2  # –æ–±—ã—á–Ω–æ —Ö–≤–∞—Ç–∞–µ—Ç 1-2
        continuations_done = 0

        def _looks_cut(s: str) -> bool:
            if not s:
                return False
            # –æ–±—Ä—ã–≤ –ø–æ—Å—Ä–µ–¥–∏ —Å–ª–æ–≤–∞/—Å—Ç—Ä–æ–∫–∏ (–∫–∞–∫ —É —Ç–µ–±—è "–∫–æ—Ä—Ä")
            if re.search(r"[–ê-–Ø–∞-—èA-Za-z0-9]\Z", s) and not s.endswith((".", "!", "?", "‚Ä¶", ")", "]", '"', "¬ª")):
                # –µ—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞ —Å–ª–∏—à–∫–æ–º "—Å—ã—Ä–∞—è" ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ –æ–±—Ä—ã–≤
                last = s.splitlines()[-1].strip()
                return len(last) > 0 and not last.endswith((".", "!", "?", "‚Ä¶", ")", "]", '"', "¬ª"))
            return False

        while continuations_done < max_continuations and (finish_reason and finish_reason != "stop" or _looks_cut(text)):
            continuations_done += 1

            cont_msgs = list(smsg)
            cont_msgs.append(
                {
                    "role": "assistant",
                    "content": text,
                }
            )
            cont_msgs.append(
                {
                    "role": "user",
                    "content": (
                        "–ü—Ä–æ–¥–æ–ª–∂–∏ –æ—Ç–≤–µ—Ç —Å –º–µ—Å—Ç–∞, –≥–¥–µ –æ–±–æ—Ä–≤–∞–ª–æ—Å—å. "
                        "–ù–∏—á–µ–≥–æ –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–π, –ø—Ä–æ—Å—Ç–æ –¥–æ–ø–∏—à–∏ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø—É–Ω–∫—Ç—ã/—Ä–∞–∑–¥–µ–ª—ã –¥–æ –∫–æ–Ω—Ü–∞."
                    ),
                }
            )

            cmpl2 = _one_call(cont_msgs)
            ch2 = (cmpl2.choices or [None])[0]
            if not ch2 or not getattr(ch2, "message", None):
                break

            add = ((ch2.message.content or "") if hasattr(ch2.message, "content") else "") or ""
            add = add.strip()

            if not add:
                break

            # —Å–∫–ª–µ–∏–≤–∞–µ–º
            text = (text.rstrip() + "\n" + add.lstrip()).strip()
            finish_reason = getattr(ch2, "finish_reason", None) or ""

        return text

    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ —á–∞—Ç-–º–æ–¥–µ–ª–∏: %s", e)
        return "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."


def _iter_sse_lines(resp) -> Iterable[str]:
    """
    –ß–∏—Ç–∞–µ–º SSE –∫–∞–∫ –ë–ê–ô–¢–´ –∏ –¥–µ–∫–æ–¥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ UTF-8 (—Å–µ—Ä–≤–µ—Ä–Ω—ã–µ charset-—ã –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º),
    —á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å mojibake –Ω–∞ cp1251/latin-1.
    """
    for raw in resp.iter_lines(decode_unicode=False):
        if not raw:
            continue
        try:
            line = raw.decode("utf-8", "replace")
        except Exception:
            # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π: –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ —Å–æ–≤—Å–µ–º –Ω–µ—Ç–∏–ø–∏—á–Ω–æ–µ
            line = raw.decode("latin-1", "replace")
        if line.startswith(":"):
            continue
        if line.startswith("data:"):
            yield line[5:].strip()
        else:
            yield line.strip()


def chat_with_gpt_stream(
    messages: List[Dict[str, Any]],
    temperature: float = 0.2,
    max_tokens: int = 800,
) -> Iterable[str]:
    """
    –°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–∞—è –≤–µ—Ä—Å–∏—è —Å —Ä—É—á–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º SSE (—É—Å—Ç–æ–π—á–∏–≤–æ –∫ ¬´–±–∏—Ç—ã–º¬ª —Å—Ç—Ä–æ–∫–∞–º JSON).
    –ï—Å–ª–∏ –ø–æ—Ç–æ–∫ –æ–±—Ä—ã–≤–∞–µ—Ç—Å—è –¥–æ –ø–µ—Ä–≤–æ–π –¥–µ–ª—å—Ç—ã ‚Äî –º—è–≥–∫–∏–π —Ñ–æ–ª–±—ç–∫ –Ω–∞ –Ω–µ—Å—Ç—Ä–∏–º.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç image_url-–ø–∞—Ä—Ç—ã.
    """
    def _gen():
        yielded_any = False
        resp = None
        try:
            smsg = _sanitize_messages(messages)

            # –ï—Å–ª–∏ –µ—Å—Ç—å image_url ‚Äî –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ vision-–º–æ–¥–µ–ª—å.
            use_vision = any(
                isinstance(m.get("content"), list) and any(
                    isinstance(p, dict) and p.get("type") == "image_url"
                    for p in m["content"]
                )
                for m in smsg
            )
            model = Cfg.vision_model() if (use_vision and Cfg.vision_active()) else Cfg.POLZA_CHAT

            payload = {
                "model": model,
                "messages": smsg,
                "temperature": temperature,
                "max_tokens": max_tokens,
                "stream": True,
            }
            headers = {
                "Authorization": f"Bearer {Cfg.POLZA_KEY}",
                "Content-Type": "application/json; charset=utf-8",
                "Accept": "text/event-stream",
                "Accept-Charset": "utf-8",
            }
            url = f"{(Cfg.BASE_POLZA or '').rstrip('/')}/chat/completions"
            # —Ç–∞–π–º–∞—É—Ç—ã
            vision_timeout = float(getattr(Cfg, "VISION_TIMEOUT_SEC", 120) or 120.0)
            resp = requests.post(
                url,
                headers=headers,
                json=payload,
                stream=True,
                timeout=(10, vision_timeout if use_vision else 300),
            )
            resp.raise_for_status()

            pending: Optional[str] = None
            for data in _iter_sse_lines(resp):
                if data == "[DONE]":
                    break

                # –ï—Å–ª–∏ –¥–æ —ç—Ç–æ–≥–æ –ø–æ–ª—É—á–∏–ª–∏ –Ω–µ–ø–æ–ª–Ω—ã–π JSON ‚Äî —Å–∫–ª–µ–∏–º
                if pending:
                    data = pending + data
                    pending = None

                try:
                    obj = json.loads(data)
                except json.JSONDecodeError:
                    # –ü—Ä–∏—à—ë–ª –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π JSON ‚Äî –∂–¥—ë–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
                    pending = data
                    continue

                # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –¥–≤–∞ —Ñ–æ—Ä–º–∞—Ç–∞:
                # 1) {"delta": "..."} –∏–ª–∏ {"delta": {"content": "..."}}
                # 2) {"choices":[{"delta":{"content":"..."}}]} ‚Äî openai-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π
                piece: str = ""

                if "delta" in obj:
                    d = obj["delta"]
                    if isinstance(d, dict):
                        # –µ—Å–ª–∏ —ç—Ç–æ reasoning-—á–∞–Ω–∫ –±–µ–∑ content ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        if d.get("reasoning") or d.get("reasoning_content") or d.get("thinking"):
                            piece = ""
                        else:
                            piece = str(d.get("content") or "").strip()
                    else:
                        # —É–ø—Ä–æ—â—ë–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —ç—Ç–æ —É–∂–µ –∫—É—Å–æ–∫ –≤–∏–¥–∏–º–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                        piece = str(d or "").strip()
                else:
                    chs = obj.get("choices") or []
                    if chs:
                        d = chs[0].get("delta") or {}
                        if isinstance(d, dict):
                            # —Ç—É—Ç –∫–∞–∫ —Ä–∞–∑ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π openai-—Ñ–æ—Ä–º–∞—Ç:
                            # delta = {"role": "...", "content": "..."} –∏–ª–∏ {"reasoning": "..."}
                            if d.get("reasoning") or d.get("reasoning_content") or d.get("thinking"):
                                piece = ""
                            else:
                                piece = str(d.get("content") or "").strip()

                if piece:
                    yielded_any = True
                    yield piece



            # –ï—Å–ª–∏ –ø–æ—Ç–æ–∫ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è, –∞ –≤ pending –≤–∏—Å–∏—Ç –≤–∞–ª–∏–¥–Ω—ã–π JSON ‚Äî –¥–æ–±–µ—Ä—ë–º
            if pending:
                try:
                    obj = json.loads(pending)
                    piece: str = ""

                    if "delta" in obj:
                        d = obj["delta"]
                        if isinstance(d, dict):
                            piece = str(d.get("content") or "").strip()
                        else:
                            piece = str(d or "").strip()
                    else:
                        chs = obj.get("choices") or []
                        if chs:
                            d = chs[0].get("delta") or {}
                            if isinstance(d, dict):
                                if d.get("reasoning") or d.get("reasoning_content") or d.get("thinking"):
                                    piece = ""
                                else:
                                    piece = str(d.get("content") or "").strip()

                    if piece:
                        yielded_any = True
                        yield piece
                except Exception:
                    pass


        except Exception as e:
            logging.error("chat_with_gpt_stream: stream aborted: %s", e)
            if not yielded_any:
                # –§–æ–ª–±—ç–∫ –Ω–∞ –Ω–µ—Å—Ç—Ä–∏–º ‚Äî —Ä–µ–∂–µ–º –Ω–∞ —á–∞—Å—Ç–∏, —á—Ç–æ–±—ã UI –ø—Ä–æ–¥–æ–ª–∂–∞–ª ¬´–∫–∞–ø–∞—Ç—å¬ª
                try:
                    answer = chat_with_gpt(messages, temperature=temperature, max_tokens=max_tokens)
                    for part in _chunk_text(answer, 480):
                        yield part
                except Exception as e2:
                    logging.exception("chat_with_gpt_stream fallback failed: %s", e2)
        finally:
            try:
                if resp is not None:
                    resp.close()
            except Exception:
                pass

    return _gen()


def probe_embedding_dim(default: int | None = None) -> int | None:
    try:
        vecs = embeddings(["__probe__"])
        if not vecs:
            return default
        return len(vecs[0])
    except Exception:
        return default


# -----------------------------
# –ù–æ–≤–æ–µ: –ø—Ä–æ—Å—Ç—ã–µ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –æ–±—ë—Ä—Ç–∫–∏ (—Ç–µ–∫—Å—Ç + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
# -----------------------------

def _make_image_parts(paths: Optional[List[str]]) -> List[Dict[str, Any]]:
    if not paths:
        return []
    max_n = int(getattr(Cfg, "VISION_MAX_IMAGES_PER_REQUEST", 4) or 4)
    parts: List[Dict[str, Any]] = []
    for p in (paths or [])[:max_n]:
        if not p:
            continue
        if not p:
            logging.warning("vision: empty image path received")
            continue

        if _path_is_url(p):
            part = _image_part_for(p)
            if part:
                parts.append(part)
            else:
                logging.error("vision: failed to attach image from URL: %r", p)
            continue

        if os.path.exists(p):
            try:
                part = _image_part_for(p)
                if part:
                    parts.append(part)
                else:
                    logging.error("vision: _image_part_for returned None for path=%r", p)
            except Exception as e:
                logging.exception("vision: error while processing image %r: %s", p, e)
        else:
            logging.warning("vision: local image path not found: %r", p)

    return parts

def chat_with_gpt_multimodal(
    prompt: str,
    image_paths: Optional[List[str]] = None,
    *,
    system: Optional[str] = None,
    temperature: float = 0.2,
    max_tokens: int = 800,
    **extra: Any,
) -> str:
    """
    –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π –≤—ã–∑–æ–≤ —á–∞—Ç–∞ —Å –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º 0..N –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
    –ï—Å–ª–∏ VISION_DISABLED ‚Äî —É–ø–∞–¥—ë–º –≤ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è).
    """
    user_content: List[Dict[str, Any]] = [{"type": "text", "text": prompt or ""}]
    user_content += _make_image_parts(image_paths)
    messages: List[Dict[str, Any]] = []
    if system:
        messages.append({"role": "system", "content": system})
    messages.append({"role": "user", "content": user_content})
    return chat_with_gpt(messages, temperature=temperature, max_tokens=max_tokens, **extra)

def chat_with_gpt_stream_multimodal(
    prompt: str,
    image_paths: Optional[List[str]] = None,
    *,
    system: Optional[str] = None,
    temperature: float = 0.2,
    max_tokens: int = 800,
) -> Iterable[str]:
    """
    –°—Ç—Ä–∏–º-–≤–∞—Ä–∏–∞–Ω—Ç –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ —á–∞—Ç–∞ (—Ç–µ–∫—Å—Ç + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è).
    """
    user_content: List[Dict[str, Any]] = [{"type": "text", "text": prompt or ""}]
    user_content += _make_image_parts(image_paths)
    messages: List[Dict[str, Any]] = []
    if system:
        messages.append({"role": "system", "content": system})
    messages.append({"role": "user", "content": user_content})
    return chat_with_gpt_stream(messages, temperature=temperature, max_tokens=max_tokens)


# -----------------------------
# Vision ‚Äî low/high level
# -----------------------------

def _vision_messages(
    content_parts: List[Dict[str, Any]],
    *,
    system_hint: Optional[str],
    temperature: float,
    max_tokens: int,
    want_tags: bool
) -> str:
    """
    –í—ã–∑–æ–≤ chat.completions —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º-–º–∞—Å—Å–∏–≤–æ–º (image_url + —Ç–µ–∫—Å—Ç).
    –ï—Å–ª–∏ want_tags=True ‚Äî –ø—Ä–æ—Å–∏–º JSON (response_format=json_object); –ø—Ä–∏ –æ—à–∏–±–∫–µ ‚Äî –ø–æ–≤—Ç–æ—Ä—è–µ–º –±–µ–∑ –Ω–µ–≥–æ.
    """
    sys = system_hint or (
        "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –¥–∏–ø–ª–æ–º–∞–º. –î–∞–π –∫—Ä–∞—Ç–∫–æ–µ, –¥–µ–ª–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏, "
        "–æ–¥–Ω–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º, –±–µ–∑ –≤–≤–æ–¥–Ω—ã—Ö —Ç–∏–ø–∞ '–ù–∞ —Ä–∏—Å—É–Ω–∫–µ', '–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏', "
        "–±–µ–∑ –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏–π –∏ –æ—Ü–µ–Ω–æ–∫. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–µ–¥–º–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∑–∞—Ç–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç/–Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ, "
        "–∑–∞—Ç–µ–º 1‚Äì3 –∫–ª—é—á–µ–≤—ã–µ –¥–µ—Ç–∞–ª–∏. –õ–∞–∫–æ–Ω–∏—á–Ω–æ."
    )

    # –ì–æ—Ç–æ–≤–∏–º —Å–∞–Ω–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (–∫–∞–∫ –º–∞—Å—Å–∏–≤ —á–∞—Å—Ç–µ–π)
    sanitized = _sanitize_messages([{"role": "user", "content": content_parts}])[0]["content"]

    try:
        kwargs: Dict[str, Any] = dict(
            model=Cfg.vision_model() if Cfg.vision_active() else Cfg.POLZA_CHAT,
            messages=[
                {"role": "system", "content": sys},
                {"role": "user", "content": sanitized},
            ],
            temperature=temperature,
            max_tokens=max_tokens,
        )
        if want_tags:
            kwargs["response_format"] = {"type": "json_object"}

        cmpl = _client.chat.completions.create(**kwargs)
        msg = cmpl.choices[0].message
        text = (msg.content or "").strip()
        return text



    except Exception as e:
        logging.warning("vision JSON response_format failed, retrying without it: %s", e)
        try:
            # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–æ–¥–µ–ª–∏ (401/403) ‚Äî –º—è–≥–∫–æ —Ñ–æ–ª–ª–±—ç–∫–∞–µ–º –Ω–∞ —á–∞—Ç-–º–æ–¥–µ–ª—å
            fallback_model = Cfg.vision_model() if Cfg.vision_active() else Cfg.POLZA_CHAT
            status = getattr(e, "status_code", None)
            if status in (401, 403):
                fallback_model = Cfg.POLZA_CHAT

            cmpl = _client.chat.completions.create(
                model=fallback_model,
                messages=[
                    {"role": "system", "content": sys},
                    {"role": "user", "content": sanitized},
                ],
                temperature=temperature,
                max_tokens=max_tokens,
            )
            return (cmpl.choices[0].message.content or "").strip()
        except Exception as e2:
            logging.exception("vision_describe: –æ–±–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å: %s", e2)
            return ""


def _norm_unit(u: Optional[str]) -> str:
    t = (u or "").strip().lower()
    if t in {"%", "percent", "perc", "pct"}:
        return "%"
    if t in {"‚Ä∞", "permil", "per mille"}:
        return "‚Ä∞"
    if t in {"pp", "–ø.–ø.", "–ø–ø"}:
        return "–ø.–ø."
    if t in {"pcs", "—à—Ç", "—à—Ç—É–∫", "–µ–¥", "units", "unit"}:
        return "—à—Ç"
    if t in {"rub", "‚ÇΩ", "—Ä—É–±", "—Ä—É–±.", "—Ä", "—Ä."}:
        return "‚ÇΩ"
    if t in {"eur", "‚Ç¨", "–µ–≤—Ä–æ"}:
        return "‚Ç¨"
    if t in {"usd", "$", "–¥–æ–ª–ª–∞—Ä", "–¥–æ–ª–ª."}:
        return "$"
    if t in {"—Ç—ã—Å", "—Ç—ã—Å.", "k"}:
        return "—Ç—ã—Å."
    if t in {"–º–ª–Ω", "–º–ª–Ω.", "mln", "m"}:
        return "–º–ª–Ω"
    return t


def vision_describe(
    image_or_images: Union[str, List[str]],
    lang: str = "ru",
    *,
    temperature: float = 0.0,
    max_tokens: int = 180,
    system_hint: Optional[str] = None,
) -> Dict[str, Any]:
    """
    –û–ø–∏—Å—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ(—è) ¬´–¥–ª—è –ø–æ–¥–ø–∏—Å–∏¬ª: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç JSON {description, tags, raw_text}.
    –í—à–∏–≤–∞–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∫–∞–∫ image_url (data: base64) –ª–∏–±–æ http(s) —Å—Å—ã–ª–∫—É ‚Äî –ø–æ Cfg.VISION_IMAGE_TRANSPORT.
    –î–∞—É–Ω—Å–∫–µ–π–ª–∏—Ç/—Å–∂–∏–º–∞–µ—Ç –¥–æ –ª–∏–º–∏—Ç–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞.
    """
    if not Cfg.vision_active():
        return {
            "description": "–º–æ–¥—É–ª—å –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ—Ç–∫–ª—é—á—ë–Ω (VISION_ENABLED=False).",
            "tags": [],
            "raw_text": "",
        }

    paths: List[str] = [image_or_images] if isinstance(image_or_images, str) else list(image_or_images or [])
    orig_paths = list(paths)

    # —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—é, –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º http(s)
    norm_paths: List[str] = []
    for p in paths:
        if not p:
            continue
        if _path_is_url(p) or os.path.exists(p):
            norm_paths.append(p)
        else:
            logging.warning(
                "vision_describe: image path is not accessible: %r "
                "(–≤–æ–∑–º–æ–∂–µ–Ω –±–∞–≥ –≤ figures/indexer ‚Äî –ø—É—Ç—å None –∏–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)",
                p,
            )

    if not norm_paths:
        logging.error(
            "vision_describe: no accessible images. original_paths=%r (likely indexer bug)",
            orig_paths,
        )
        return {
            "description": "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ.",
            "tags": [],
            "raw_text": "",
        }

    # –õ–∏–º–∏—Ç –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    norm_paths = norm_paths[: max(1, int(getattr(Cfg, "VISION_MAX_IMAGES_PER_REQUEST", 4) or 4))]

    # –ö—ç—à –ø–æ –Ω–∞–±–æ—Ä—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    shas: List[str] = []
    for p in norm_paths:
        shas.append(p if _path_is_url(p) else _sha256_file(p))
    multi_key = hashlib.sha256(("|".join(shas)).encode("utf-8")).hexdigest()
    cache_key = (multi_key, (lang or "ru").lower(), Cfg.vision_model() or Cfg.POLZA_CHAT)

    # 1) –ø–∞–º—è—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–∞
    if cache_key in _VISION_CACHE:
        return _VISION_CACHE[cache_key]
    # 2) –¥–∏—Å–∫–æ–≤—ã–π –∫—ç—à
    disk = _vcache_get(cache_key)
    if disk:
        _VISION_CACHE[cache_key] = disk
        return disk

    # –®–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞ (RU/EN)
    tmpl = build_describe_prompt(
        caption=None,
        context=None,
        lang=lang,
        sentences_min=Cfg.VISION_DESCRIBE_SENTENCES_MIN,
        sentences_max=Cfg.VISION_DESCRIBE_SENTENCES_MAX,
        require_json=Cfg.VISION_JSON_STRICT,
    )

    # –î–æ–±–∞–≤–ª—è–µ–º —è–≤–Ω—É—é –ø—Ä–æ—Å—å–±—É –≤–µ—Ä–Ω—É—Ç—å –í–°–ï –Ω–∞–¥–ø–∏—Å–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–æ–ª–µ raw_text
    if lang.lower().startswith("ru"):
        extra = (
            "\n\n–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –µ—Å–ª–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç, –≤–µ—Ä–Ω–∏ –µ–≥–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é "
            "–≤ –ø–æ–ª–µ \"raw_text\" —Ç–æ–≥–æ –∂–µ JSON. –ü–µ—Ä–µ—á–∏—Å–ª–∏ –≤—Å–µ —á–∏—Ç–∞–µ–º—ã–µ –Ω–∞–¥–ø–∏—Å–∏ "
            "–∫–∞–∫ –º–æ–∂–Ω–æ —Ç–æ—á–Ω–µ–µ, —á–µ—Ä–µ–∑ —Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π."
        )
    else:
        extra = (
            "\n\nAdditionally: if there is any text on the image, return it verbatim "
            'in the "raw_text" field of the same JSON. List all readable labels '
            "as accurately as possible, separated by semicolons."
        )

    user_prompt = (tmpl["user"] or "") + extra

    content_parts: List[Dict[str, Any]] = [{"type": "text", "text": user_prompt}]
    for p in norm_paths:
        part = _image_part_for(p)
        if part:
            content_parts.append(part)

    raw = _vision_messages(
        content_parts,
        system_hint=(system_hint or tmpl["system"]),
        temperature=temperature,
        max_tokens=max_tokens,
        want_tags=Cfg.VISION_JSON_STRICT,  # –ø—Ä–æ—Å–∏–º JSON
    )

    # –°—Ç–∞—Ä–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON; –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å (—Ç–µ–∫—Å—Ç –º–æ–¥–µ–ª–∏)
        # –°—Ç–∞—Ä–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON; –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å (—Ç–µ–∫—Å—Ç –º–æ–¥–µ–ª–∏)
    desc: str = ""
    tags: List[str] = []
    raw_text: str = ""
    if raw:
        try:
            obj = json.loads(raw)
            desc = str(obj.get("description", "")).strip()
            tgs = obj.get("tags", [])
            if isinstance(tgs, list):
                tags = [str(x).strip() for x in tgs if str(x).strip()]
            raw_text = str(obj.get("raw_text", "")).strip()
        except Exception:
            # –º–æ–¥–µ–ª—å –æ—Ç–≤–µ—Ç–∏–ª–∞ –Ω–µ JSON ‚Äî —Ç—Ä–∞–∫—Ç—É–µ–º —Ü–µ–ª–∏–∫–æ–º –∫–∞–∫ –æ–ø–∏—Å–∞–Ω–∏–µ
            desc = (raw or "").strip()

    # üîÅ –§–û–õ–ë–≠–ö: –µ—Å–ª–∏ –ø–æ—Å–ª–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ —Ç–µ–∫—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –ø–æ–ª—É—á–µ–Ω,
    # –ø—Ä–æ–±—É–µ–º –≤—ã—Ç–∞—â–∏—Ç—å –µ–≥–æ —á–µ—Ä–µ–∑ vision_extract_values (—Ç–∞–º –æ–±—ã—á–Ω–æ –µ—Å—Ç—å raw_text)
    if not raw_text:
        try:
            extra_vals = vision_extract_values(
                image_or_images,
                caption_hint=desc or None,
                ocr_hint=None,
                temperature=0.0,
                max_tokens=900,
                lang=lang,
            )
            rt = extra_vals.get("raw_text")
            if isinstance(rt, list):
                raw_text = "; ".join(
                    str(x).strip() for x in rt if str(x).strip()
                )
        except Exception as e:
            logging.warning("vision_describe: fallback via vision_extract_values failed: %s", e)

    # –°–∞–Ω–∏—Ç–∞–π–∑ + —Ñ–æ–ª–ª–±—ç–∫, –µ—Å–ª–∏ –ø–æ—Å–ª–µ —Å–∞–Ω–∏—Ç–∞–π–∑–∞ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø—É—Å—Ç–æ/–∑–∞–≥–ª—É—à–∫–∞
    sanitized = _sanitize_description(desc)
    _fallback_placeholder = "—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–æ–ø–∏—Å–∞–Ω–∏–µ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ)."
    if (not sanitized or sanitized == _fallback_placeholder) and (raw or "").strip():
        r = (raw or "").strip()
        sanitized = (r.split(".")[0] + ".") if "." in r else r

    res = {
        "description": sanitized,
        "tags": tags,
        "raw_text": raw_text,
    }

    _VISION_CACHE[cache_key] = res
    _vcache_put(cache_key, res)
    return res


def vision_describe_with_values(
    image_or_images: Union[str, List[str]],
    *,
    caption_hint: Optional[str] = None,
    ocr_hint: Optional[str] = None,
    lang: str = "ru",
    temperature: float = 0.0,
    max_tokens: int = 180,
) -> Dict[str, Any]:
    """
    –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º –¥–ª—è —Ä–∏—Å—É–Ω–∫–æ–≤ –í–ö–†:
      1) –¥–∞—ë—Ç —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (–∫–∞–∫ vision_describe);
      2) –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –¥–µ–ª–∞–µ—Ç –ø–æ–ø—ã—Ç–∫—É –≤—ã—Ç–∞—â–∏—Ç—å —á–∏—Å–ª–∞/–ø–æ–¥–ø–∏—Å–∏ —Å –∫–∞—Ä—Ç–∏–Ω–∫–∏.

    –í–ê–ñ–ù–û: –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ vision_extract_values —Å—á–∏—Ç–∞—é—Ç—Å—è –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ú–ò.
    –û—Å–Ω–æ–≤–Ω–∞—è ¬´–∏—Å—Ç–∏–Ω–∞¬ª –ø–æ —Ü–∏—Ñ—Ä–∞–º –¥–æ–ª–∂–Ω–∞ –ø—Ä–∏—Ö–æ–¥–∏—Ç—å –∏–∑ chart_data/—Ç–∞–±–ª–∏—Ü.
    –í—ã–∑—ã–≤–∞—é—â–∞—è —Å—Ç–æ—Ä–æ–Ω–∞ —Ä–µ—à–∞–µ—Ç, –¥–æ–≤–µ—Ä—è—Ç—å –ª–∏ —ç—Ç–∏–º —á–∏—Å–ª–∞–º –∏ –∫–∞–∫ –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å.
    """
    # 1) —Å–Ω–∞—á–∞–ª–∞ –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
    desc = vision_describe(
        image_or_images,
        lang=lang,
        temperature=temperature,
        max_tokens=max_tokens,
        system_hint=None,
    )

    # 2) –∑–∞—Ç–µ–º ‚Äî –ø–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    eff_caption = caption_hint or desc.get("description") or None
    values: Dict[str, Any] = {}
    try:
        values = vision_extract_values(
            image_or_images,
            caption_hint=eff_caption,
            ocr_hint=ocr_hint,
            temperature=0.0,  # –¥–ª—è —á–∏—Å–µ–ª –¥–µ—Ä–∂–∏–º –ø–æ –º–∞–∫—Å–∏–º—É–º—É –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ
            max_tokens=1400,
            lang=lang,
        )
    except Exception as e:
        logging.exception("vision_describe_with_values: vision_extract_values failed: %s", e)
        values = {
            "type": "other",
            "warnings": [
                "vision_extract_values failed; –¥–ª—è —Ç–æ—á–Ω—ã—Ö —Ü–∏—Ñ—Ä –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ chart_data/—Ç–∞–±–ª–∏—Ü."
            ],
        }

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É: –æ–ø–∏—Å–∞–Ω–∏–µ + ¬´vision-—á–∏—Å–ª–∞¬ª (–≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –±–ª–æ–∫–µ)
    return {
        "description": desc.get("description"),
        "tags": desc.get("tags") or [],
        "vision_values": values,
    }


def vision_describe_many(
    images: List[str],
    lang: str = "ru",
    *,
    per_image_limit: int = 4,  # –ø–∞—Ä–∞–º–µ—Ç—Ä —Å–æ—Ö—Ä–∞–Ω—ë–Ω –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
) -> List[Dict[str, Any]]:

    """
    One-in ‚Üí one-out: –Ω–∞ –∫–∞–∂–¥—ã–π –ø—É—Ç—å ‚Äî –æ–¥–∏–Ω —Å–ª–æ–≤–∞—Ä—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.
    –ü–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–µ—à–∏—Ä—É—é—Ç—Å—è (–ø–æ SHA256 –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –∏ –ø–æ URL-—Å—Ç—Ä–æ–∫–µ –¥–ª—è http/https).
    """
    if not Cfg.vision_active():
        return [{"description": "–º–æ–¥—É–ª—å –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ—Ç–∫–ª—é—á—ë–Ω (VISION_ENABLED=False).", "tags": []} for _ in (images or [])]

    out: List[Dict[str, Any]] = []
    for p in images or []:
        if not p or (not _path_is_url(p) and not os.path.exists(p)):
            out.append({"description": "—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω", "tags": []})
            continue
        try:
            out.append(vision_describe(p, lang=lang))
        except Exception as e:
            logging.exception("vision_describe_many: –æ—à–∏–±–∫–∞ –Ω–∞ —Ñ–∞–π–ª–µ %s: %s", p, e)
            out.append({"description": "–æ–ø–∏—Å–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏.", "tags": []})
    return out


# -----------------------------
# –ù–æ–≤–æ–µ: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π JSON)
# -----------------------------

def vision_extract_values(
    image_or_images: Union[str, List[str]],
    *,
    caption_hint: Optional[str] = None,
    ocr_hint: Optional[str] = None,
    temperature: float = 0.0,
    max_tokens: int = 1400,
    lang: str = "ru",
) -> Dict[str, Any]:
    """
    –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è –æ–±—ë—Ä—Ç–∫–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —á–∏—Å–µ–ª/–ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤/–ø–æ–¥–ø–∏—Å–µ–π/–µ–¥–∏–Ω–∏—Ü.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è:
      {
        "type": "pie|bar|line|diagram|table|other",
        "units": {"x":"...","y":"..."},
        "axes": {"x_labels":["..."],"y_labels":["..."]},
        "legend": ["..."],
        "data": [{"label":"...","series":"optional","value":"...","unit":"optional","conf":0.0..1.0}],
        "raw_text": ["..."],
        "warnings": ["..."]
      }
    –ï—Å–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –Ω–µ —É–¥–∞–ª–æ—Å—å ‚Äî –≤–µ—Ä–Ω—ë—Ç {"type":"other","warnings":[...]}.
    """
    if not Cfg.vision_active():
        return {"type": "other", "warnings": ["vision –æ—Ç–∫–ª—é—á—ë–Ω (VISION_ENABLED=False)."]}

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π
    paths: List[str] = [image_or_images] if isinstance(image_or_images, str) else list(image_or_images or [])
    orig_paths = list(paths)

    norm_paths: List[str] = []
    for p in paths:
        if not p:
            continue
        if _path_is_url(p) or os.path.exists(p):
            norm_paths.append(p)
        else:
            logging.warning(
                "vision_extract_values: image path is not accessible: %r "
                "(–≤–æ–∑–º–æ–∂–µ–Ω –±–∞–≥ –≤ figures/indexer ‚Äî –ø—É—Ç—å None –∏–ª–∏ —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)",
                p,
            )

    if not norm_paths:
        logging.error(
            "vision_extract_values: no accessible images. original_paths=%r",
            orig_paths,
        )
        return {"type": "other", "warnings": ["–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ."]}

    # –û–≥—Ä–∞–Ω–∏—á–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    norm_paths = norm_paths[: max(1, int(getattr(Cfg, "VISION_MAX_IMAGES_PER_REQUEST", 4) or 4))]

    # –ö—ç—à –ø–æ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è + –ø–æ–¥—Å–∫–∞–∑–∫–∏)
    sig_parts: List[str] = []
    for p in norm_paths:
        sig_parts.append(p if _path_is_url(p) else _sha256_file(p))
    if caption_hint:
        sig_parts.append("cap:" + caption_hint.strip())
    if ocr_hint:
        # –Ω–µ –≤–∫–ª—é—á–∞–µ–º –≤–µ—Å—å OCR-—Ç–µ–∫—Å—Ç —Ü–µ–ª–∏–∫–æ–º, —Ç–æ–ª—å–∫–æ –µ–≥–æ —Ö—ç—à
        sig_parts.append("ocr:" + hashlib.sha256(ocr_hint.encode("utf-8")).hexdigest())
    multi_key = hashlib.sha256(("|".join(sig_parts)).encode("utf-8")).hexdigest()
    cache_key = ("values|" + multi_key, (lang or "ru").lower(), Cfg.vision_model() or Cfg.POLZA_CHAT)

    # 1) –ø–∞–º—è—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–∞
    if cache_key in _VISION_CACHE:
        return _VISION_CACHE[cache_key]
    # 2) –¥–∏—Å–∫–æ–≤—ã–π –∫—ç—à
    disk = _vcache_get(cache_key)
    if disk:
        _VISION_CACHE[cache_key] = disk
        return disk

    # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è (—è–∑—ã–∫)
    lang_hint = {
        "ru": "–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º.",
        "en": "Answer in English.",
        "kk": "“ö–∞–∑–∞“õ —Ç—ñ–ª—ñ–Ω–¥–µ –∂–∞—É–∞–ø –±–µ—Ä.",
    }.get((lang or "ru").lower(), "–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º.")

    # –ö–æ–Ω—Ç–µ–Ω—Ç: —Ç–µ–∫—Å—Ç + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    # –ì–æ—Ç–æ–≤–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —à–∞–±–ª–æ–Ω–∞: –ø–æ–¥–ø–∏—Å—å + —É–∫–æ—Ä–æ—á–µ–Ω–Ω—ã–π OCR-—Ç–µ–∫—Å—Ç
    ctx_lines: List[str] = []
    if caption_hint:
        ctx_lines.append(f"Caption: {caption_hint}")
    if ocr_hint:
        cut = (ocr_hint[:2000] + "‚Ä¶") if len(ocr_hint or "") > 2000 else (ocr_hint or "")
        ctx_lines.append(f"OCR: {cut}")
    ctx_text = "\n".join(ctx_lines) if ctx_lines else None

    tmpl = build_extract_prompt(
        caption=caption_hint,
        context=ctx_text,
        lang=lang,
        max_items=Cfg.VISION_EXTRACT_MAX_ITEMS,
        conf_min=Cfg.VISION_EXTRACT_CONF_MIN,
        percent_decimals=Cfg.VISION_PERCENT_DECIMALS,
        require_json=Cfg.VISION_JSON_STRICT,
    )

    content_parts: List[Dict[str, Any]] = [{"type": "text", "text": tmpl["user"]}]
    for p in norm_paths:
        part = _image_part_for(p)
        if part:
            content_parts.append(part)

    raw = _vision_messages(
        content_parts,
        system_hint=tmpl["system"],
        temperature=temperature,
        max_tokens=max_tokens,
        want_tags=Cfg.VISION_JSON_STRICT,  # –≤—Å–µ–≥–¥–∞ —Ç—Ä–µ–±—É–µ–º JSON-–æ–±—ä–µ–∫—Ç
    )

    # –ü–∞—Ä—Å–∏–Ω–≥ JSON (—É—Å—Ç–æ–π—á–∏–≤—ã–π)
    def _parse_first_json(text: str) -> Optional[Dict[str, Any]]:
        if not text:
            return None
        try:
            return json.loads(text)
        except Exception:
            s = str(text)
            start = s.find("{")
            end = s.rfind("}")
            if start != -1 and end != -1 and end > start:
                try:
                    return json.loads(s[start:end + 1])
                except Exception:
                    return None
        return None

    obj = _parse_first_json(raw)
    if not obj or not isinstance(obj, dict):
        res = {"type": "other", "warnings": ["–Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏."], "raw_text": [raw or ""]}
        _VISION_CACHE[cache_key] = res
        _vcache_put(cache_key, res)
        return res

    # ----------------- –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –ò –ì–ê–†–ê–ù–¢–ò–ò –ü–û–õ–ï–ô -----------------
    try:
        obj.setdefault("type", "other")
        obj.setdefault("units", {})
        obj.setdefault("axes", {})
        obj.setdefault("legend", [])
        obj.setdefault("data", [])
        obj.setdefault("raw_text", [])
        obj.setdefault("warnings", [])

        # –õ–µ–≥–µ–Ω–¥–∞ ‚Äî –ø—Ä–æ—Å—Ç–æ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫
        if isinstance(obj.get("legend"), list):
            obj["legend"] = [str(x).strip() for x in obj["legend"] if str(x).strip()]

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –¥–∞–Ω–Ω—ã—Ö: label/series/value/unit/conf
        norm_rows: List[Dict[str, Any]] = []
        rows = obj.get("data") if isinstance(obj.get("data"), list) else []
        for it in rows:
            if not isinstance(it, dict):
                continue
            label = str(it.get("label") or "").strip()
            series = str(it.get("series")).strip() if it.get("series") is not None else ""
            value_raw = it.get("value")
            unit_raw = it.get("unit")
            conf_raw = it.get("conf", it.get("confidence", it.get("score", None)))

            # value –≤—Å–µ–≥–¥–∞ —Å—Ç—Ä–æ–∫–æ–π (–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–∞–º –ø–∞—Ä—Å–∏—Ç float/%, 0..1 –∏ –ø—Ä.)
            value = str(value_raw if value_raw is not None else "").strip()

            # unit: –µ—Å–ª–∏ –ø—É—Å—Ç–æ, –Ω–æ –≤ value –µ—Å—Ç—å %/‚Ä∞/–ø.–ø. ‚Äî –∏–∑–≤–ª–µ—á—ë–º
            unit = str(unit_raw or "").strip()
            if not unit:
                if re.search(r"%\s*$", value):
                    unit = "%"
                elif re.search(r"‚Ä∞\s*$", value):
                    unit = "‚Ä∞"
                elif re.search(r"(?:–ø\.–ø\.|–ø–ø)\s*$", value, flags=re.IGNORECASE):
                    unit = "–ø.–ø."
            unit = _norm_unit(unit)

            # conf ‚Üí float –≤ [0,1]; –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî 1.0
            try:
                conf = float(conf_raw) if conf_raw is not None else 1.0
            except Exception:
                conf = 1.0
            # –∫–ª–∏–ø
            if conf < 0.0:
                conf = 0.0
            if conf > 1.0:
                conf = 1.0

            norm_rows.append({
                "label": label,
                "series": series,
                "value": value,
                "unit": unit,
                "conf": conf,
            })
        obj["data"] = norm_rows

        # –û—á–∏—Å—Ç–∏–º axes (–µ—Å–ª–∏ –µ—Å—Ç—å)
        axes = obj.get("axes", {})
        if isinstance(axes, dict):
            if "x_labels" in axes and isinstance(axes["x_labels"], list):
                axes["x_labels"] = [str(x).strip() for x in axes["x_labels"] if str(x).strip()]
            if "y_labels" in axes and isinstance(axes["y_labels"], list):
                axes["y_labels"] = [str(x).strip() for x in axes["y_labels"] if str(x).strip()]
            obj["axes"] = axes

        # –î–æ–ø. –ø–æ–ª–µ units –º–æ–∂–Ω–æ –º—è–≥–∫–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –µ–≥–æ –∑–∞–ø–æ–ª–Ω–∏–ª–∞)
        units = obj.get("units", {})
        if isinstance(units, dict):
            for k in list(units.keys()):
                units[k] = _norm_unit(str(units[k]))
            obj["units"] = units

        # –¢–∏–ø ‚Äî –≤ –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ—Å—Ç–∏
        t = str(obj.get("type") or "other").strip().lower()
        obj["type"] = t

    except Exception as e:
        logging.warning("vision_extract_values: normalization failed: %s", e)

    _VISION_CACHE[cache_key] = obj
    _vcache_put(cache_key, obj)
    return obj


def vision_extract_table_values(
    image_or_images: Union[str, List[str]],
    *,
    caption_hint: Optional[str] = None,
    ocr_hint: Optional[str] = None,
    temperature: float = 0.0,
    max_tokens: int = 1400,
    lang: str = "ru",
) -> Dict[str, Any]:
    """
    –û–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ vision_extract_values, –∫–æ—Ç–æ—Ä—É—é –∂–¥—ë—Ç bot.py
    –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
    –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é –ª–æ–≥–∏–∫—É vision_extract_values.
    """
    return vision_extract_values(
        image_or_images=image_or_images,
        caption_hint=caption_hint,
        ocr_hint=ocr_hint,
        temperature=temperature,
        max_tokens=max_tokens,
        lang=lang,
    )

