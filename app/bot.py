# app/bot.py
import re
import os
import html
import json
import logging
import asyncio
import time
import math
from decimal import Decimal 
logger = logging.getLogger(__name__)
from typing import Iterable, AsyncIterable, Optional, List, Tuple
from .docs_handlers import register_docs_handlers
from aiogram import Bot, Dispatcher, F, types
from aiogram.filters import Command
from aiogram.exceptions import TelegramBadRequest
from app.planner import is_big_complex_query, plan_tasks_from_user_query, batch_tasks, TaskType
from aiogram.enums import ChatAction
from aiogram.types import FSInputFile, InputMediaPhoto
from .retrieval import (
    get_table_context_for_numbers,
    get_figure_context_for_numbers,
    get_section_context_for_hints,
    build_context as build_rag_context,
)
from .ooxml_lite import (
    build_index as oox_build_index,
    figure_lookup as oox_fig_lookup,
    table_lookup as oox_tbl_lookup,
)

# ---------- answer builder: –ø—ã—Ç–∞–µ–º—Å—è –≤–∑—è—Ç—å —Å—Ç—Ä–∏–º–æ–≤—É—é –≤–µ—Ä—Å–∏—é, —Ñ–æ–ª–±—ç–∫ –Ω–∞ –Ω–µ—Å—Ç—Ä–∏–º–æ–≤—É—é ----------
try:
    from .answer_builder import generate_answer, generate_answer_stream  # type: ignore
except Exception:
    from .answer_builder import generate_answer  # type: ignore
    generate_answer_stream = None  # —Å—Ç—Ä–∏–º–∞ –Ω–µ—Ç ‚Äî –±—É–¥–µ–º —Ñ–æ–ª–±—ç–∫–∞—Ç—å

from .config import Cfg, ProcessingState
from .db import (
    ensure_user, get_conn,
    set_document_indexer_version, get_document_indexer_version,
    CURRENT_INDEXER_VERSION,
    update_document_meta, delete_document_chunks,
    set_user_active_doc, get_user_active_doc,
    # ‚Üì –Ω–æ–≤–æ–µ –¥–ª—è FSM/–æ—á–µ—Ä–µ–¥–∏
    enqueue_pending_query, dequeue_all_pending_queries,
    get_processing_state, start_downloading,
    find_nearest_table_above
)
from .parsing import parse_docx, parse_doc, save_upload
from .indexing import index_document
from .retrieval import (
    retrieve, build_context, invalidate_cache,
    retrieve_coverage, build_context_coverage,
    describe_figures_by_numbers,
)
from .intents import detect_intents

# ---------- polza client: –ø—Ä–æ–±—É–µ–º —Å—Ç—Ä–∏–º, —Ñ–æ–ª–±—ç–∫ –Ω–∞ –æ–±—ã—á–Ω—ã–π —á–∞—Ç ----------
try:
    from .polza_client import (
        probe_embedding_dim,
        chat_with_gpt,
        chat_with_gpt_stream,
        vision_extract_values,
        vision_extract_table_values,      # ‚Üê –ù–û–í–û–ï: —Å–ø–µ—Ü-—Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–∞–±–ª–∏—Ü-–∫–∞—Ä—Ç–∏–Ω–æ–∫
        # NEW: –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –æ–±—ë—Ä—Ç–∫–∏ (—Ç–µ–∫—Å—Ç + –∫–∞—Ä—Ç–∏–Ω–∫–∏)
        chat_with_gpt_multimodal,
        chat_with_gpt_stream_multimodal,
    )  # type: ignore

    # NEW: –ø—Ä—è–º–æ–π –∏–Ω–¥–µ–∫—Å —Ä–∏—Å—É–Ω–∫–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞
    from .figures import (
        index_document as fig_index_document,
        load_index   as fig_load_index,
        find_figure  as fig_find,
        figure_display_name,
    )
except Exception:
    from .polza_client import probe_embedding_dim, chat_with_gpt  # type: ignore
    chat_with_gpt_stream = None
    vision_extract_values = None  # —Ñ–æ–ª–±—ç–∫: –µ—Å–ª–∏ –Ω–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏, –Ω–µ –ø–∞–¥–∞–µ–º

    # ‚Üê –ù–û–í–û–ï: –µ—Å–ª–∏ —Å–ø–µ—Ü-—Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ç–∞–±–ª–∏—Ü-–∫–∞—Ä—Ç–∏–Ω–æ–∫ –Ω–µ—Ç, –ø—Ä–æ—Å—Ç–æ –æ—Ç–∫–ª—é—á–∞–µ–º –µ—ë
    vision_extract_table_values = None  # type: ignore

    # NEW: –º—è–≥–∫–∏–µ —Ñ–æ–ª–±—ç–∫–∏
    chat_with_gpt_multimodal = None  # type: ignore
    chat_with_gpt_stream_multimodal = None  # type: ignore


    # –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∑–∞–≥–ª—É—à–∫–∏ –¥–ª—è figures, —á—Ç–æ–±—ã –æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –Ω–µ –ø–∞–¥–∞–ª
    fig_index_document = None       # type: ignore
    fig_load_index = None           # type: ignore

    def fig_find(*args, **kwargs):  # type: ignore
        return []

    def figure_display_name(rec):   # type: ignore
        rec = rec or {}
        return str(
            rec.get("title")
            or rec.get("caption")
            or rec.get("num")
            or "–†–∏—Å—É–Ω–æ–∫"
        )




# –ù–û–í–û–ï: –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –ø—Ä–∏—ë–º–∞/–æ–±–æ–≥–∞—â–µ–Ω–∏—è (OCR —Ç–∞–±–ª–∏—Ü-–∫–∞—Ä—Ç–∏–Ω–æ–∫, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–∏—Å–µ–ª)
from .ingest_orchestrator import enrich_sections, ingest_document
# –ù–û–í–û–ï: –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Ç–∞–±–ª–∏—Ü
from .analytics import analyze_table_by_num

# —É—Ç–∏–ª–∏—Ç—ã
from .utils import safe_filename, sha256_bytes, split_for_telegram, infer_doc_kind

# –≥–∏–±—Ä–∏–¥–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: —Å–µ–º–∞–Ω—Ç–∏–∫–∞ + FTS/LIKE
from .lexsearch import best_context

# —Å—Ä–∞–∑—É –ø–æ–¥ —Ç–µ–∫—É—â–∏–º–∏ import‚Äô–∞–º–∏
from .paywall_stub import setup_paywall

# –≥–¥–µ —É –≤–∞—Å —Å–æ–∑–¥–∞—é—Ç—Å—è –æ–±—ä–µ–∫—Ç—ã –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞:
bot = Bot(Cfg.TG_TOKEN)
dp = Dispatcher()
# –¥–æ–±–∞–≤—å—Ç–µ —ç—Ç—É —Å—Ç—Ä–æ–∫—É (–æ–¥–∏–Ω —Ä–∞–∑):
setup_paywall(dp, bot)

register_docs_handlers(dp)

# --------------------- –ü–ê–†–ê–ú–ï–¢–†–´ –°–¢–†–ò–ú–ò–ù–ì–ê (—Å –¥–µ—Ñ–æ–ª—Ç–∞–º–∏) ---------------------

STREAM_ENABLED: bool = getattr(Cfg, "STREAM_ENABLED", True)
STREAM_EDIT_INTERVAL_MS: int = getattr(Cfg, "STREAM_EDIT_INTERVAL_MS", 900)
STREAM_MIN_CHARS: int = getattr(Cfg, "STREAM_MIN_CHARS", 120)
STREAM_MODE: str = getattr(Cfg, "STREAM_MODE", "edit")
TG_MAX_CHARS: int = getattr(Cfg, "TG_MAX_CHARS", 3900)
FIG_MEDIA_LIMIT: int = getattr(Cfg, "FIG_MEDIA_LIMIT", 12)

TG_SPLIT_TARGET: int = getattr(Cfg, "TG_SPLIT_TARGET", 2000)
TG_SPLIT_MAX_PARTS: int = getattr(Cfg, "TG_SPLIT_MAX_PARTS", 6)

# ‚Üì –ù–û–í–û–ï: –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∫—É—Å–∫–∞–º–∏ –ø—Ä–∏ –Ω–µ—Å—Ç—Ä–∏–º–æ–≤–æ–π –æ—Ç–ø—Ä–∞–≤–∫–µ
MULTIPART_SLEEP_MS: int = getattr(Cfg, "MULTIPART_SLEEP_MS", 200)

_SPLIT_ANCHOR_RE = re.compile(
    r"(?m)^(?:### .+|## .+|\*\*[^\n]+?\*\*|\d+[).] .+|- .+)$"
)  # –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã (–∑–∞–≥–æ–ª–æ–≤–∫–∏/—Å–ø–∏—Å–∫–∏)
STREAM_HEAD_START_MS: int = getattr(Cfg, "STREAM_HEAD_START_MS", 250)        # –ø–µ—Ä–≤—ã–π –∞–ø–¥–µ–π—Ç –±—ã—Å—Ç—Ä–µ–µ
FINAL_MAX_TOKENS: int = getattr(Cfg, "FINAL_MAX_TOKENS", 5000)
TYPE_INDICATION_EVERY_MS: int = getattr(Cfg, "TYPE_INDICATION_EVERY_MS", 2000)
# NEW: —Å—Ç—Ä–æ–≥–∏–π —Ä–µ–∂–∏–º –¥–ª—è —Ä–∏—Å—É–Ω–∫–æ–≤ ‚Äî –Ω–µ –æ—Ç–¥–∞—ë–º —á–∏—Å–ª–∞ –±–µ–∑ –Ω–∞–¥—ë–∂–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
FIG_STRICT: bool = getattr(Cfg, "FIG_STRICT", True)
# ‚Üì –Ω–æ–≤–æ–µ: —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–Ω–æ–≥–æ—à–∞–≥–æ–≤–æ–π –ø–æ–¥–∞—á–µ–π
MULTI_STEP_SEND_ENABLED: bool = getattr(Cfg, "MULTI_STEP_SEND_ENABLED", True)
MULTI_STEP_MIN_ITEMS: int = getattr(Cfg, "MULTI_STEP_MIN_ITEMS", 2)
MULTI_STEP_MAX_ITEMS: int = getattr(Cfg, "MULTI_STEP_MAX_ITEMS", 8)
MULTI_STEP_FINAL_MERGE: bool = getattr(Cfg, "MULTI_STEP_FINAL_MERGE", True)
MULTI_STEP_PAUSE_MS: int = getattr(Cfg, "MULTI_STEP_PAUSE_MS", 120)  # –º/—É –±–ª–æ–∫–∞–º–∏
MULTI_PASS_SCORE: int = getattr(Cfg, "MULTI_PASS_SCORE", 85)         # –ø–æ—Ä–æ–≥ –∫—Ä–∏—Ç–∏–∫–∞ –≤ ace
# –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –≤–æ–ø—Ä–æ—Å–∞, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–π –≤–æ–æ–±—â–µ –µ—Å—Ç—å —Å–º—ã—Å–ª –≥–æ—Ä–æ–¥–∏—Ç—å –ø–æ–¥–ø—É–Ω–∫—Ç—ã
MULTI_STEP_MIN_QUESTION_LEN: int = getattr(Cfg, "MULTI_STEP_MIN_QUESTION_LEN", 200)


# --------------------- —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ ---------------------
# Markdown ‚Üí HTML (–º–∏–Ω–∏–º–∞–ª—å–Ω–æ-–Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ: –∑–∞–≥–æ–ª–æ–≤–∫–∏, **bold**, *italic*, `code`)
_MD_H_RE       = re.compile(r"(?m)^\s{0,3}#{1,6}\s+(.+?)\s*$")
_MD_BOLD_RE    = re.compile(r"\*\*(.+?)\*\*", re.DOTALL)
_MD_BOLD2_RE   = re.compile(r"__(.+?)__", re.DOTALL)
_MD_ITALIC_RE  = re.compile(r"(?<!\*)\*(?!\*)(.+?)(?<!\*)\*(?!\*)", re.DOTALL)
_MD_ITALIC2_RE = re.compile(r"(?<!_)_(?!_)(.+?)(?<!_)_(?!_)", re.DOTALL)
_MD_CODE_RE    = re.compile(r"`([^`]+)`")

def _to_html(text: str) -> str:
    if not text:
        return ""
    original = text

    # 0) –≤—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–º–µ–Ω–∏–º –∫–æ–¥–æ–≤—ã–µ —Å–ø–∞–Ω—ã –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–∞–º–∏
    code_buf = []
    def _stash(m):
        code_buf.append(m.group(1))
        return f"@@CODE{len(code_buf)-1}@@"

    txt = _MD_CODE_RE.sub(_stash, original)
    txt = html.escape(txt)

    # 1) –∑–∞–≥–æ–ª–æ–≤–∫–∏/–∂–∏—Ä–Ω—ã–π/–∫—É—Ä—Å–∏–≤
    txt = _MD_H_RE.sub(r"<b>\1</b>", txt)
    txt = _MD_BOLD_RE.sub(r"<b>\1</b>", txt)
    txt = _MD_BOLD2_RE.sub(r"<b>\1</b>", txt)
    txt = _MD_ITALIC_RE.sub(r"<i>\1</i>", txt)
    txt = _MD_ITALIC2_RE.sub(r"<i>\1</i>", txt)

    # 2) –∑–∞—á–∏—Å—Ç–∫–∞ ¬´–≤–∏—Å—è—á–∏—Ö¬ª ** ‚Äî —É–∂–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ (–≤ –∫–æ–¥–µ –∏—Ö –Ω–µ—Ç)
    txt = re.sub(r"(?<!\*)\*\*(?!\*)", "", txt)

    # 3) –≤–µ—Ä–Ω—É—Ç—å –∫–æ–¥–æ–≤—ã–µ —Å–ø–∞–Ω—ã, —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–≤ –∏—Ö –∫–æ–Ω—Ç–µ–Ω—Ç
    def _restore(m):
        i = int(m.group(1))
        return f"<code>{html.escape(code_buf[i])}</code>"
    txt = re.sub(r"@@CODE(\d+)@@", _restore, txt)

    return txt


# -------- –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ --------
_GREET_RE = re.compile(
    r"(?i)\b(–ø—Ä–∏–≤–µ—Ç|–∑–¥—Ä–∞–≤—Å—Ç–≤|–¥–æ–±—Ä—ã–π\s*(–¥–µ–Ω—å|–≤–µ—á–µ—Ä|—É—Ç—Ä–æ)|hello|hi|hey|—Ö–∞–π|—Å–∞–ª—é—Ç|–∫—É)\b"
)

def _is_greeting(text: str) -> bool:
    t = (text or "").strip()
    if not t:
        return False
    # –∫–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏–ª–∏ —Ñ—Ä–∞–∑—ã, –≥–¥–µ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
    return bool(_GREET_RE.search(t))

# --- —Ä–∞–∑–±–æ—Ä —Å—Å—ã–ª–æ–∫ –≤–∏–¥–∞ "—Ç–∞–±–ª–∏—Ü–∞ 1.2", "—Ä–∏—Å. 3", "–≥–ª–∞–≤–∞ 2" –≤ –≤–æ–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ---

# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –≤—Å–µ —Ä—É—Å—Å–∫–∏–µ –ø–∞–¥–µ–∂–∏ ("—Ç–∞–±–ª–∏—Ü—É", "—Ç–∞–±–ª–∏—Ü–µ", "–≥–ª–∞–≤—É" –∏ —Ç.–ø.),
# –∞ —Ç–∞–∫–∂–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å ‚Ññ –∏ –±—É–∫–≤–µ–Ω–Ω—ã–º –ø—Ä–µ—Ñ–∏–∫—Å–æ–º (A.1, –ü2.3).
_STRUCT_REF_RE = re.compile(
    r"(?i)\b("                       # –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
    r"—Ä–∏—Å\.?|—Ä–∏—Å—É–Ω[–∞-—è]*|figure|fig\.?|"
    r"—Ç–∞–±–ª\.?|—Ç–∞–±–ª–∏—Ü[–∞-—è]*|table|tbl\.?|"
    r"–≥–ª–∞–≤[–∞-—è]*|chapter|—Ä–∞–∑–¥–µ–ª[–∞-—è]*|section"
    r")\s*(?:‚Ññ\s*)?"                 # –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ "‚Ññ"
    r"((?:[A-Za-z–ê-–Ø–∞-—è](?=[\.\d]))?\s*\d+(?:[.,]\d+)*)"  # –Ω–æ–º–µ—Ä: 2, 2.1, A.1 –∏ —Ç.–ø.
)

def extract_struct_refs(question: str) -> list[dict]:
    """
    –ò—â–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–∞–±–ª–∏—Ü—ã/—Ä–∏—Å—É–Ω–∫–∏/–≥–ª–∞–≤—ã —Å –Ω–æ–º–µ—Ä–æ–º.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è –≤–∏–¥–∞:
      - "—Ä–∏—Å—É–Ω–∫–∏ 2.1 –∏ 2.2"
      - "—Ç–∞–±–ª–∏—Ü—ã 1.1, 1.2, 1.3"
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π:
      {"kind": "table"|"figure"|"chapter", "num": "2.1", "raw": "—Ç–∞–±–ª–∏—Ü—É 2.1, 2.2 –∏ 2.3"}
    """
    result: list[dict] = []
    if not question:
        return result

    # —á—Ç–æ–±—ã –Ω–µ –ø–ª–æ–¥–∏—Ç—å –¥—É–±–ª–∏
    seen: set[tuple[str, str]] = set()

    for m in _STRUCT_REF_RE.finditer(question):
        raw = m.group(0)
        kw = (m.group(1) or "").lower()
        first_num = (m.group(2) or "").strip()

        if kw.startswith(("—Ç–∞–±–ª", "table", "tbl")):
            kind = "table"
        elif kw.startswith(("—Ä–∏—Å", "fig", "figure")):
            kind = "figure"
        else:
            # –≥–ª–∞–≤–∞ / —Ä–∞–∑–¥–µ–ª / chapter / section
            kind = "chapter"

        def _add_num(num_str: str) -> None:
            n = (num_str or "").strip()
            if not n:
                return
            # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –∑–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É
            n = n.replace(" ", "").replace(",", ".")
            key = (kind, n)
            if not n or key in seen:
                return
            seen.add(key)
            result.append({"kind": kind, "num": n, "raw": raw})

        # 1) –ø–µ—Ä–≤—ã–π –Ω–æ–º–µ—Ä –∏–∑ —Å–∞–º–æ–≥–æ –º–∞—Ç—á–∞
        if first_num:
            _add_num(first_num)

        # 2) –≤—Å–µ –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ –Ω–æ–º–µ—Ä–∞ –ø–æ—Å–ª–µ –º–∞—Ç—á–∞:
        #    "—Ä–∏—Å—É–Ω–∫–∏ 2.2, 2.3 –∏ 2.4"
        tail = question[m.end():]
        for mm in re.finditer(
            r"\s*(?:,|;|\s+–∏\s+|\s+and\s+)\s*(\d+(?:[.,]\d+)*)",
            tail,
            flags=re.IGNORECASE,
        ):
            _add_num(mm.group(1))

    return result


async def _answer_structured_multi(
    m: types.Message,
    uid: int,
    doc_id: int,
    q_text: str,
    refs: list[dict],
) -> bool:
    """
    –ú—É–ª—å—Ç–∏—Ä–µ–∂–∏–º: –≤ –≤–æ–ø—Ä–æ—Å–µ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ —É–ø–æ–º—è–Ω—É—Ç—ã —Ç–∞–±–ª–∏—Ü—ã/—Ä–∏—Å—É–Ω–∫–∏/—Ä–∞–∑–¥–µ–ª—ã.

    –í –ù–û–í–û–ô –≤–µ—Ä—Å–∏–∏ –≤–º–µ—Å—Ç–æ –æ–¥–Ω–æ–≥–æ –±–æ–ª—å—à–æ–≥–æ –≤—ã–∑–æ–≤–∞ GPT –º—ã:
      * –ø–æ –∫–∞–∂–¥–æ–º—É –æ–±—ä–µ–∫—Ç—É –¥–µ–ª–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π GPT-—Ä–∞–∑–±–æ—Ä (–∫–∞–∫ –≤ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö);
      * —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫—É—Å–æ—á–∫–∏ –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç –∏ —à–ª—ë–º –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.
    """
    if not refs:
        return False

    # –±–µ–∑ GPT —ç—Ç–æ—Ç —Ä–µ–∂–∏–º –Ω–µ –∏–º–µ–µ—Ç —Å–º—ã—Å–ª–∞
    if "chat_with_gpt" not in globals() or chat_with_gpt is None:
        return False

    verbosity = _detect_verbosity(q_text)

    # –ø—Ä–æ–π–¥—ë–º—Å—è –ø–æ –æ–±—ä–µ–∫—Ç–∞–º –≤ –¢–û–ú –ñ–ï –ü–û–†–Ø–î–ö–ï, –∫–∞–∫ –æ–Ω–∏ –∏–¥—É—Ç –≤ –≤–æ–ø—Ä–æ—Å–µ
    parts: list[str] = []
    used_tables: set[str] = set()
    used_figs: set[str] = set()
    used_sections: set[str] = set()

    for r in refs:
        kind = (r.get("kind") or "").lower()
        raw_num = str(r.get("num") or "").strip()
        if not raw_num:
            continue

        norm_num = raw_num.replace(" ", "").replace(",", ".")
        # –ª–æ–∫–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –∏–º–µ–Ω–Ω–æ –ø—Ä–æ —ç—Ç–æ—Ç –æ–±—ä–µ–∫—Ç
        raw_ref = (r.get("raw") or "").strip()

        # --- —Ç–∞–±–ª–∏—Ü—ã ---
        if kind == "table":
            if norm_num in used_tables:
                continue
            used_tables.add(norm_num)

            # –≤–º–µ—Å—Ç–æ –≤—Å–µ–≥–æ q_text –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π —Å–∞–±-–≤–æ–ø—Ä–æ—Å
            local_q = raw_ref or f"–æ–ø–∏—à–∏ —Ç–∞–±–ª–∏—Ü—É {raw_num}"
            text = await _describe_table_for_multi(uid, doc_id, norm_num, local_q, verbosity)
            if not text:
                parts.append(f"- –¢–∞–±–ª–∏—Ü–∞ {raw_num}: –¥–∞–Ω–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –Ω–µ—Ç –≤ —Ä–∞–±–æ—Ç–µ.")
            else:
                parts.append(f"**–¢–∞–±–ª–∏—Ü–∞ {raw_num}**\n{text}")

        # --- —Ä–∏—Å—É–Ω–∫–∏ ---
        elif kind in ("figure", "fig"):
            if norm_num in used_figs:
                continue
            used_figs.add(norm_num)

            local_q = raw_ref or f"–æ–ø–∏—à–∏ —Ä–∏—Å—É–Ω–æ–∫ {raw_num}"
            text = await _describe_figure_for_multi(uid, doc_id, norm_num, local_q, verbosity)
            if not text:
                parts.append(f"- –†–∏—Å—É–Ω–æ–∫ {raw_num}: –¥–∞–Ω–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞ –Ω–µ—Ç –≤ —Ä–∞–±–æ—Ç–µ.")
            else:
                parts.append(f"**–†–∏—Å—É–Ω–æ–∫ {raw_num}**\n{text}")

        # --- —Ä–∞–∑–¥–µ–ª—ã/–≥–ª–∞–≤—ã ---
        elif kind in ("chapter", "section", "area"):
            if norm_num in used_sections:
                continue
            used_sections.add(norm_num)

            local_q = raw_ref or f"–æ–ø–∏—à–∏ –≥–ª–∞–≤—É {raw_num}"
            text = await _describe_section_for_multi(uid, doc_id, norm_num, local_q, verbosity)
            if not text:
                parts.append(f"- –ì–ª–∞–≤–∞/—Ä–∞–∑–¥–µ–ª {raw_num}: –¥–∞–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª –≤ —è–≤–Ω–æ–º –≤–∏–¥–µ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ä–∞–±–æ—Ç–µ.")
            else:
                parts.append(f"**–ì–ª–∞–≤–∞/—Ä–∞–∑–¥–µ–ª {raw_num}**\n{text}")


    if not parts:
        # –≤–æ–æ–±—â–µ –Ω–∏—á–µ–≥–æ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ —Å–æ–±—Ä–∞—Ç—å –Ω–µ —É–¥–∞–ª–æ—Å—å ‚Äî –ø—É—Å—Ç—å –¥–∞–ª—å—à–µ –æ—Ç—Ä–∞–±–æ—Ç–∞–µ—Ç –æ–±—ã—á–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω
        return False

    final_answer = "\n\n".join(parts)

    # –æ–±–Ω–æ–≤–∏–º "–ø–æ—Å–ª–µ–¥–Ω–∏–µ —É–ø–æ–º—è–Ω—É—Ç—ã–µ" –æ–±—ä–µ–∫—Ç—ã –¥–ª—è follow-up –≤–æ–ø—Ä–æ—Å–æ–≤
    try:
        if used_tables:
            LAST_REF.setdefault(uid, {})["table_nums"] = list(used_tables)
        if used_figs:
            LAST_REF.setdefault(uid, {})["figure_nums"] = list(used_figs)
        if used_sections:
            # –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π –∫–∞–∫ —Ç–µ–∫—É—â—É—é –æ–±–ª–∞—Å—Ç—å
            LAST_REF.setdefault(uid, {})["area"] = next(iter(used_sections))
    except Exception:
        pass

    await _send(m, final_answer)
    return True


async def _describe_table_for_multi(
    uid: int,
    doc_id: int,
    num: str,
    question: str,
    verbosity: str,
) -> str:
    """
    –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫: –¥–µ–ª–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π GPT-—Ä–∞–∑–±–æ—Ä –æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
    (–¥–ª—è –º—É–ª—å—Ç–∏—Ä–µ–∂–∏–º–∞), –Ω–æ –Ω–∏—á–µ–≥–æ –Ω–µ —à–ª—ë—Ç –≤ –¢–µ–ª–µ–≥—Ä–∞–º ‚Äî –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç.

    NEW: –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ —Ç–∞–±–ª–∏—Ü–µ –±–µ—Ä—ë–º —á–µ—Ä–µ–∑ retrieval.get_table_context_for_numbers,
    —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ—Ç –∂–µ –ø—É—Ç—å, —á—Ç–æ –∏ –≤ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö (–≤–∫–ª—é—á–∞—è –≤—Å–µ —Å—Ç—Ä–æ–∫–∏).
    """
    num = (num or "").strip()
    if not num:
        return ""

    # –ë–µ—Ä—ë–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã —á–µ—Ä–µ–∑ RAG-—Ö–µ–ª–ø–µ—Ä
    snippets = get_table_context_for_numbers(
        owner_id=uid,
        doc_id=doc_id,
        numbers=[num],
        include_all_values=True,
        rows_limit=None,
    )
    if not snippets:
        return ""

    full_ctx = build_rag_context(snippets, max_chars=4000)
    if not full_ctx:
        return ""

    system_prompt = (
        "–¢—ã —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ –¥–∏–ø–ª–æ–º–Ω—ã–º —Ä–∞–±–æ—Ç–∞–º. –ù–∏–∂–µ –¥–∞–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ –∏–∑ –¥–∏–ø–ª–æ–º–∞ –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º –≤–∏–¥–µ "
        "–∏, –≤–æ–∑–º–æ–∂–Ω–æ, —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞ —Ä—è–¥–æ–º —Å –Ω–µ–π. –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –ø–æ —ç—Ç–∏–º –¥–∞–Ω–Ω—ã–º: "
        "–Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏, —Å—Ç–æ–ª–±—Ü—ã –∏ –∑–Ω–∞—á–µ–Ω–∏—è, –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –ø—Ä–µ–¥–º–µ—Ç–Ω—É—é –æ–±–ª–∞—Å—Ç—å –∏ —Ç–µ—Ä–º–∏–Ω—ã, "
        "–µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö –∏–ª–∏ —Ç–µ–∫—Å—Ç–µ."
    )

    user_prompt = (
        f"–°–¥–µ–ª–∞–π –ø–æ–Ω—è—Ç–Ω–æ–µ —á–µ–ª–æ–≤–µ–∫—É –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ —Ç–∞–±–ª–∏—Ü–µ {num}: —á—Ç–æ –≤ –Ω–µ–π —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç—Å—è, "
        "–∫–∞–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—ã—à–µ/–Ω–∏–∂–µ –∏ –∫–∞–∫–∏–µ 2‚Äì3 –≤—ã–≤–æ–¥–∞ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å. "
        "–ù–µ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–π –ø—Ä–æ—Ü–µ–Ω—Ç—ã –∏ –Ω–µ –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—ã—Ö —á–∏—Å–µ–ª.\n\n"
        "[–¢–∞–±–ª–∏—Ü–∞ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞]\n"
        f"{full_ctx}"
        f"{_verbosity_addendum(verbosity, '–æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã')}"
    )

    try:
        answer = chat_with_gpt(
            [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.2,
            max_tokens=FINAL_MAX_TOKENS,
        )
    except Exception as e:
        logging.exception("describe_table_for_multi failed: %s", e)
        return ""

    answer = (answer or "").strip()
    if not answer:
        return ""
    return _strip_unwanted_sections(answer)


async def _describe_figure_for_multi(
    uid: int,
    doc_id: int,
    num: str,
    question: str,
    verbosity: str,
    rec: dict | None = None,   # ‚¨ÖÔ∏è –Ω–æ–≤—ã–π –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç
) -> str:
    """
    –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –º—É–ª—å—Ç–∏—Ä–µ–∂–∏–º–∞: –¥–µ–ª–∞–µ—Ç GPT-—Ä–∞–∑–±–æ—Ä –æ–¥–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞.

    –î–∞–Ω–Ω—ã–µ –ø–æ —Ä–∏—Å—É–Ω–∫—É –±–µ—Ä—ë–º –∏–∑ _build_figure_records, –∫–æ—Ç–æ—Ä—ã–π —É–∂–µ:
      - –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ—Ç –ø—É—Ç–∏ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º –∏ –ø–æ–¥–ø–∏—Å–∏;
      - –ø–æ–¥–º–µ—à–∏–≤–∞–µ—Ç —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–∏–∞–≥—Ä–∞–º–º—ã (chart_data/chart_matrix);
      - –ø—Ä–∏ –∏—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Ç–∞–±–ª–∏—Ü—ã-–∏—Å—Ç–æ—á–Ω–∏–∫–∞.

    –î–ª—è –Ω–µ—á–∏—Å–ª–æ–≤—ã—Ö —Å—Ö–µ–º (org_chart / flowchart / text_blocks / schema / ...),
    –≥–¥–µ –Ω–µ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤/–∑–Ω–∞—á–µ–Ω–∏–π, —Å—Ç–∞—Ä–∞–µ–º—Å—è –¥–∞–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–±—â–µ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
    –±–µ–∑ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π, —á—Ç–æ–±—ã –Ω–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É.
    """
    num = (num or "").strip()
    if not num:
        return ""

    # –ï—Å–ª–∏ –∫–∞—Ä—Ç–æ—á–∫–∞ —Ä–∏—Å—É–Ω–∫–∞ —É–∂–µ —Å–æ–±—Ä–∞–Ω–∞ —Å–Ω–∞—Ä—É–∂–∏ (–≤ _answer_figure_query),
    # –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë. –ò–Ω–∞—á–µ ‚Äî —Å—Ç–∞—Ä–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ: —Å–æ–±–∏—Ä–∞–µ–º –ø–æ –Ω–æ–º–µ—Ä—É.
    if rec is None:
        try:
            records = _build_figure_records(uid, doc_id, [num], need_values=True) or []
        except Exception as e:
            logging.exception("build_figure_records in _describe_figure_for_multi failed: %s", e)
            records = []

        if not records:
            return ""

        rec = records[0]

    parts: list[str] = []

    disp = rec.get("display") or f"–†–∏—Å—É–Ω–æ–∫ {rec.get('num') or ''}".strip()
    caption = (rec.get("caption") or "").strip()
    if caption:
        parts.append(f"–ü–æ–¥–ø–∏—Å—å: {caption}")

    near = rec.get("near_text") or []
    if near:
        joined = " ".join((t or "").strip() for t in near if t).strip()
        if joined:
            # —á—É—Ç—å –æ–≥—Ä–∞–Ω–∏—á–∏–º –¥–ª–∏–Ω—É, —á—Ç–æ–±—ã –Ω–µ —Ä–∞–∑–¥—É–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç
            joined = joined[:1200]
            parts.append("–¢–µ–∫—Å—Ç —Ä—è–¥–æ–º: " + joined)

    vision = (rec.get("vision_desc") or "").strip()
    if vision:
        parts.append("–û–ø–∏—Å–∞–Ω–∏–µ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é: " + vision)

    values_text = (rec.get("values_text") or rec.get("values") or "").strip()
    if values_text:
        # –í–ù–ò–ú–ê–ù–ò–ï: –∑–¥–µ—Å—å –∑–Ω–∞—á–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ GPT, –≤ –æ—Ç–≤–µ—Ç–µ –∏—Ö
        # –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª—è—Ç—å _fig_values_text_from_records.
        parts.append("–¢–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ):\n" + values_text[:1500])

    if not parts:
        return ""

    ctx = f"{disp}\n\n" + "\n\n".join(parts)

    has_near = bool(near)
    has_vision = bool(vision)
    has_values = bool(values_text)
    num_display = rec.get("num") or num

    # ---- –û–ü–†–ï–î–ï–õ–Ø–ï–ú –¢–ò–ü –†–ò–°–£–ù–ö–ê ----
    figure_kind = (rec.get("figure_kind") or "").strip().lower()

    textual_kinds = {
        "org_chart",
        "orgchart",
        "flowchart",
        "text_blocks",
        "schema",
        "scheme",
        "block_diagram",
        "structure",
    }
    is_textual_figure = (figure_kind in textual_kinds) or (not has_values and bool(vision))

    # üí° –ú–∏–Ω–∏-—Ñ–∏–∫—Å: –µ—Å–ª–∏ —É –Ω–∞—Å –ø–æ —Å—É—Ç–∏ —Ç–æ–ª—å–∫–æ –ø–æ–¥–ø–∏—Å—å –∏ –Ω–µ—Ç –Ω–∏ vision, –Ω–∏ —Ç–µ–∫—Å—Ç–∞ —Ä—è–¥–æ–º, –Ω–∏ —á–∏—Å–µ–ª ‚Äî
    # –Ω–µ –≥–æ–Ω—è–µ–º GPT —Å ¬´—É—á–µ–±–Ω–æ–π¬ª –ø—Ä–æ—Å—Ç—ã–Ω—ë–π, –∞ –¥–∞—ë–º –∫–æ—Ä–æ—Ç–∫–∏–π –ø–æ–Ω—è—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç.
    # –≠—Ç–æ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π fallback –∏ –¥–ª—è —Å—Ö–µ–º, –∏ –¥–ª—è –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö —Ä–∏—Å—É–Ω–∫–æ–≤.
    if not has_near and not has_vision and not has_values:
        if caption:
            return f"–ù–∞ —Ä–∏—Å—É–Ω–∫–µ {num_display} –ø–æ–∫–∞–∑–∞–Ω–æ: {caption}"
        return f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ä–∏—Å—É–Ω–∫–∞ {num_display} –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞."


    # ---- –í–ï–¢–ö–ê –î–õ–Ø –ß–ò–°–õ–û–í–´–• –î–ò–ê–ì–†–ê–ú–ú ----
    if not is_textual_figure:
        system_prompt = (
            "–¢—ã —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ –¥–∏–ø–ª–æ–º–Ω—ã–º —Ä–∞–±–æ—Ç–∞–º. –ù–∏–∂–µ –¥–∞–Ω—ã –ø–æ–¥–ø–∏—Å—å –∫ —Ä–∏—Å—É–Ω–∫—É, —Ç–µ–∫—Å—Ç —Ä—è–¥–æ–º —Å –Ω–∏–º "
            "–∏, –≤–æ–∑–º–æ–∂–Ω–æ, –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –∏–∑ –¥–∏–∞–≥—Ä–∞–º–º—ã –∑–Ω–∞—á–µ–Ω–∏—è. –ù–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö:\n"
            "1) –ö—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏, —á—Ç–æ –ø–æ–∫–∞–∑–∞–Ω–æ –Ω–∞ —Ä–∏—Å—É–Ω–∫–µ.\n"
            "2) –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π 2‚Äì3 –≤—ã–≤–æ–¥–∞ –ø–æ –¥–∏–Ω–∞–º–∏–∫–µ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è.\n\n"
            "–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ —Å—Ç—Ä–æ–≥–æ —Ç–∞–∫–æ–π:\n"
            "–ß—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ:\n"
            "- ...\n"
            "- ...\n\n"
            "–í—ã–≤–æ–¥—ã:\n"
            "- ...\n"
            "- ...\n"
            "- ...\n\n"
            "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã—Ö —á–∏—Å–µ–ª –∏ –Ω–µ –≤–≤–æ–¥–∏ –ø—Ä–µ–¥–º–µ—Ç–Ω—É—é –æ–±–ª–∞—Å—Ç—å, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç –≤ –ø–æ–¥–ø–∏—Å–∏/—Ç–µ–∫—Å—Ç–µ. "
            "–ù–µ –¥–æ–±–∞–≤–ª—è–π –±–ª–æ–∫ —Å —Ç–æ—á–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ ‚Äî –æ–Ω –±—É–¥–µ—Ç –ø–æ–¥—Å—Ç–∞–≤–ª–µ–Ω –æ—Ç–¥–µ–ª—å–Ω–æ. "
            "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–∏—à–∏, —á—Ç–æ ¬´—Ä–∏—Å—É–Ω–∫–∞ —Å —Ç–∞–∫–∏–º –Ω–æ–º–µ—Ä–æ–º –Ω–µ—Ç¬ª –∏–ª–∏ —á—Ç–æ ¬´–µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –¥—Ä—É–≥–æ–π —Ä–∏—Å—É–Ω–æ–∫¬ª ‚Äî "
            "–¥–∞–≤–∞–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≤–æ–∑–º–æ–∂–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–æ —Ç–µ–º –¥–∞–Ω–Ω—ã–º, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã, –∏ –µ—Å–ª–∏ –∏—Ö –º–∞–ª–æ, "
            "–ø—Ä–æ—Å—Ç–æ —É–∫–∞–∂–∏, —á—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞."
        )


        # ‚¨áÔ∏è –í–∞–∂–Ω–æ–µ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ: —è–≤–Ω–æ –≥–æ–≤–æ—Ä–∏–º –º–æ–¥–µ–ª–∏ —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è –¢–û–õ–¨–ö–û –Ω–∞ —ç—Ç–æ–º –Ω–æ–º–µ—Ä–µ,
        # –¥–∞–∂–µ –µ—Å–ª–∏ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –≤–æ–ø—Ä–æ—Å–µ —É–ø–æ–º–∏–Ω–∞–ª–∏—Å—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∏—Å—É–Ω–∫–æ–≤.
        num_display = rec.get("num") or num

        user_prompt = (
            f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å: {question}\n\n"
            f"–°–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Å—è –¢–û–õ–¨–ö–û –Ω–∞ —Ä–∏—Å—É–Ω–∫–µ {num_display}, "
            "–¥—Ä—É–≥–∏–µ —Ä–∏—Å—É–Ω–∫–∏ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞ –∏–≥–Ω–æ—Ä–∏—Ä—É–π.\n\n"
            f"–°–¥–µ–ª–∞–π –ø–æ–Ω—è—Ç–Ω–æ–µ –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø–æ —Ä–∏—Å—É–Ω–∫—É {num_display}: —á—Ç–æ –Ω–∞ –Ω—ë–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ "
            "–∏ –∫–∞–∫–∏–µ 2‚Äì3 –≤—ã–≤–æ–¥–∞ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å.\n\n"
            "[–î–∞–Ω–Ω—ã–µ –ø–æ —Ä–∏—Å—É–Ω–∫—É]\n"
            f"{ctx}"
            f"{_verbosity_addendum(verbosity, '–æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–∏—Å—É–Ω–∫–∞')}"
        )


    # ---- –í–ï–¢–ö–ê –î–õ–Ø –¢–ï–ö–°–¢–û–í–´–• –°–•–ï–ú / –û–†–ì–°–¢–†–£–ö–¢–£–† ----
    else:
        system_prompt = (
            "–¢—ã —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ –¥–∏–ø–ª–æ–º–Ω—ã–º —Ä–∞–±–æ—Ç–∞–º. –ù–∏–∂–µ –¥–∞–Ω—ã –ø–æ–¥–ø–∏—Å—å –∫ —Ä–∏—Å—É–Ω–∫—É, —Ç–µ–∫—Å—Ç —Ä—è–¥–æ–º —Å –Ω–∏–º "
            "–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–≤–∫–ª—é—á–∞—è —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å —Ä–∏—Å—É–Ω–∫–∞, "
            "–µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å). –≠—Ç–æ –Ω–µ —á–∏—Å–ª–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞, –∞ —Å—Ö–µ–º–∞/—Å—Ç—Ä—É–∫—Ç—É—Ä–∞/–æ—Ä–≥—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏–ª–∏ –¥—Ä—É–≥–æ–π —Ä–∏—Å—É–Ω–æ–∫, "
            "–≥–¥–µ –≥–ª–∞–≤–Ω–æ–µ ‚Äî —ç–ª–µ–º–µ–Ω—Ç—ã –∏ —Å–≤—è–∑–∏ –º–µ–∂–¥—É –Ω–∏–º–∏.\n\n"
            "–ï—Å–ª–∏ –≤ –¥–∞–Ω–Ω—ã—Ö –Ø–í–ù–û —É–∫–∞–∑–∞–Ω—ã —ç–ª–µ–º–µ–Ω—Ç—ã —Å—Ö–µ–º—ã (–Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π, –±–ª–æ–∫–æ–≤, —Ä–æ–ª–µ–π, "
            "–ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–æ–º –≤ –ø–æ–¥–ø–∏—Å–∏, —Ç–µ–∫—Å—Ç–µ —Ä—è–¥–æ–º –∏–ª–∏ –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è) ‚Äî –º–æ–∂–µ—à—å "
            "–Ω–∞ –Ω–∏—Ö –æ–ø–∏—Ä–∞—Ç—å—Å—è –∏ –∫—Ä–∞—Ç–∫–æ –ø–µ—Ä–µ—á–∏—Å–ª–∏—Ç—å.\n"
            "–ï—Å–ª–∏ —Ç–∞–∫–∏—Ö —è–≤–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç, –¥–∞–π —Ç–æ–ª—å–∫–æ –û–ë–©–ï–ï –æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ö–µ–º—ã –≤ 2‚Äì4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö "
            "–±–µ–∑ –≤—ã–¥—É–º—ã–≤–∞–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π –æ—Ç–¥–µ–ª–æ–≤, —Ä–æ–ª–µ–π –∏ –±–ª–æ–∫–æ–≤.\n\n"
            "–°—Ç—Ä–æ–≥–æ —Å–æ–±–ª—é–¥–∞–π –ø—Ä–∞–≤–∏–ª–æ: –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–∏ –æ–¥–Ω–æ–≥–æ –Ω–æ–≤–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–∞, –∫–æ—Ç–æ—Ä–æ–≥–æ "
            "–Ω–µ—Ç –≤ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –º–∞–ª–æ, –ª—É—á—à–µ –Ω–∞–ø–∏—à–∏ –æ–± —ç—Ç–æ–º —è–≤–Ω–æ, —á–µ–º –¥–æ–º—ã—Å–ª–∏–≤–∞—Ç—å. "
            "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–∏—à–∏, —á—Ç–æ ¬´—Ä–∏—Å—É–Ω–∫–∞ —Å —Ç–∞–∫–∏–º –Ω–æ–º–µ—Ä–æ–º –Ω–µ—Ç¬ª –∏–ª–∏ —á—Ç–æ ¬´–µ—Å—Ç—å —Ç–æ–ª—å–∫–æ —Ä–∏—Å—É–Ω–æ–∫ —Å –¥—Ä—É–≥–∏–º –Ω–æ–º–µ—Ä–æ–º¬ª ‚Äî "
            "–≤—Å–µ–≥–¥–∞ –¥–∞–≤–∞–π –æ–ø–∏—Å–∞–Ω–∏–µ –ø–æ —Ç–µ–º –¥–∞–Ω–Ω—ã–º, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å, –∏ –ø—Ä–∏ –Ω–µ—Ö–≤–∞—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Å—Ç–æ —É–∫–∞–∂–∏ –Ω–∞ —ç—Ç–æ."
        )


        num_display = rec.get("num") or num

        user_prompt = (
            f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å: {question}\n\n"
            f"–°–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Å—è –¢–û–õ–¨–ö–û –Ω–∞ —Ä–∏—Å—É–Ω–∫–µ {num_display}, "
            "–¥—Ä—É–≥–∏–µ —Ä–∏—Å—É–Ω–∫–∏ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞ –∏–≥–Ω–æ—Ä–∏—Ä—É–π.\n\n"
            f"–°–¥–µ–ª–∞–π –ø–æ–Ω—è—Ç–Ω–æ–µ –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø–æ —Ä–∏—Å—É–Ω–∫—É {num_display}: —á—Ç–æ –Ω–∞ –Ω—ë–º –≤ —Ü–µ–ª–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ, "
            "–∫–∞–∫—É—é –∏–¥–µ—é –∏–ª–ª—é—Å—Ç—Ä–∏—Ä—É–µ—Ç —Å—Ö–µ–º–∞ –∏ –∫–∞–∫–∏–µ 2‚Äì3 –≤—ã–≤–æ–¥–∞ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å.\n\n"
            "–ï—Å–ª–∏ –≤ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç —è–≤–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å—Ö–µ–º—ã, –ù–ï –ø–µ—Ä–µ—á–∏—Å–ª—è–π –≤—ã–¥—É–º–∞–Ω–Ω—ã–µ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è "
            "–∏–ª–∏ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ ‚Äî –ø—Ä–æ—Å—Ç–æ –æ–ø–∏—à–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è, —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∏ —Ç.–ø.).\n\n"
            "[–î–∞–Ω–Ω—ã–µ –ø–æ —Ä–∏—Å—É–Ω–∫—É]\n"
            f"{ctx}"
            f"{_verbosity_addendum(verbosity, '–æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Å—Ö–µ–º—ã')}"
        )


    try:
        answer = chat_with_gpt(
            [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.2,
            max_tokens=FINAL_MAX_TOKENS,
        )
    except Exception as e:
        logging.exception("describe_figure_for_multi failed: %s", e)
        return ""

    answer = (answer or "").strip()

    if not answer:
        if caption:
            return f"–û–ø–∏—Å–∞–Ω–∏–µ —Ä–∏—Å—É–Ω–∫–∞ {num_display}.\n\n–ù–∞ —Ä–∏—Å—É–Ω–∫–µ –ø–æ–∫–∞–∑–∞–Ω–æ: {caption}"
        return ""

    # –ø–æ–¥—á–∏—Å—Ç–∏–º —Ö–≤–æ—Å—Ç—ã
    answer = _strip_unwanted_sections(answer)

    # –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
    header = f"–û–ø–∏—Å–∞–Ω–∏–µ —Ä–∏—Å—É–Ω–∫–∞ {num_display}.\n\n"

    # —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç–≤–µ—á–∞–µ—Ç —Ç–æ–ª—å–∫–æ –∑–∞ "—á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ",
    # –±–ª–æ–∫ —Å —Ç–æ—á–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è —Å–Ω–∞—Ä—É–∂–∏ (_fig_values_text_from_records)
    return header + answer


async def _describe_section_for_multi(
    uid: int,
    doc_id: int,
    num: str,
    question: str,
    verbosity: str,
) -> str:
    """
    –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫: GPT-—Ä–∞–∑–±–æ—Ä –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞/–≥–ª–∞–≤—ã.

    NEW: –≤–º–µ—Å—Ç–æ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ _section_context –∏—Å–ø–æ–ª—å–∑—É–µ–º RAG-—Ö–µ–ª–ø–µ—Ä
    get_section_context_for_hints, –∫–æ—Ç–æ—Ä—ã–π –∏—â–µ—Ç –≤—Å–µ —á–∞–Ω–∫–∏ —Å section_path,
    –Ω–∞—á–∏–Ω–∞—é—â–∏–º—Å—è –Ω–∞ –Ω—É–∂–Ω—É—é ¬´–≥–æ–ª–æ–≤—É¬ª (–Ω–∞–ø—Ä–∏–º–µ—Ä, '3', '3.1', '3.2').
    """
    sec = (num or "").strip()
    if not sec:
        return ""

    # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–∫ —Ä–∞–Ω—å—à–µ
    sec = re.sub(r"^[A-Za-z–ê-–Ø–∞-—è]\s+(?=\d)", "", sec)
    sec = sec.replace(" ", "").replace(",", ".")

    snippets = get_section_context_for_hints(
        owner_id=uid,
        doc_id=doc_id,
        section_hints=[sec],
        per_section_k=6,
    )
    if not snippets:
        return ""

    ctx = build_rag_context(snippets, max_chars=4000)
    if not ctx:
        return ""

    system_prompt = (
        "–¢—ã —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ –í–ö–†. –ù–∏–∂–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –æ–¥–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞/–≥–ª–∞–≤—ã –¥–∏–ø–ª–æ–º–∞. "
        "–ö—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É –ø–µ—Ä–µ—Å–∫–∞–∂–∏ –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º: –æ —á—ë–º —Ä–µ—á—å, –∫–∞–∫–∏–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –∏–¥–µ–∏, "
        "–∫–∞–∫–∏–µ –≤—ã–≤–æ–¥—ã –¥–µ–ª–∞–µ—Ç –∞–≤—Ç–æ—Ä. –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—ã—Ö —Ñ–∞–∫—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ."
    )

    user_prompt = (
        f"–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ, –ø–æ–Ω—è—Ç–Ω–æ–µ –ø–æ—è—Å–Ω–µ–Ω–∏–µ –ø–æ —Ä–∞–∑–¥–µ–ª—É/–≥–ª–∞–≤–µ {sec}.\n\n"
        "[–§—Ä–∞–≥–º–µ–Ω—Ç—ã —Ä–∞–∑–¥–µ–ª–∞]\n"
        f"{ctx}"
        f"{_verbosity_addendum(verbosity, '–æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–∞–∑–¥–µ–ª–∞')}"
    )

    try:
        answer = chat_with_gpt(
            [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.2,
            max_tokens=FINAL_MAX_TOKENS,
        )
    except Exception as e:
        logging.exception("describe_section_for_multi failed: %s", e)
        return ""

    answer = (answer or "").strip()
    if not answer:
        return ""
    return _strip_unwanted_sections(answer)




def _split_multipart(text: str,
                     *,
                     target: int = TG_SPLIT_TARGET,
                     max_parts: int = TG_SPLIT_MAX_PARTS,  # –ø–∞—Ä–∞–º–µ—Ç—Ä –æ—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
                     hard: int = TG_MAX_CHARS) -> list[str]:
    s = text or ""
    if not s:
        return []
    parts: list[str] = []
    rest = s

    # —Ä–µ–∂–µ–º –ø–æ ¬´–∫—Ä–∞—Å–∏–≤—ã–º¬ª –≥—Ä–∞–Ω–∏—Ü–∞–º —Å—Ç–æ–ª—å–∫–æ —Ä–∞–∑, —Å–∫–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ
    while len(rest) > target:
        cut = -1
        for m in _SPLIT_ANCHOR_RE.finditer(rest[: min(len(rest), hard)]):
            if m.start() < target:
                cut = m.start()
        if cut <= 0:
            cut = _smart_cut_point(rest, min(hard, target))
        parts.append(rest[:cut].rstrip())
        rest = rest[cut:].lstrip()

    # —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ö–≤–æ—Å—Ç –∏ —Å–≤–µ—Ä—Ö–∂—ë—Å—Ç–∫–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ –ª–∏–º–∏—Ç—É Telegram
    while rest:
        parts.append(rest[:hard])
        rest = rest[hard:]
    return parts


async def _send(m: types.Message, text: str):
    """–ë–µ—Ä–µ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —á–∞—Å—Ç—è–º–∏ –≤ HTML-—Ä–µ–∂–∏–º–µ (–Ω–µ—Å—Ç—Ä–∏–º–æ–≤—ã–π —Ñ–æ–ª–±—ç–∫)."""
    chunks = _split_multipart(text or "")
    logger.info(
        "SEND: %d chunk(s) to chat_id=%s (message_id=%s), total_len=%d",
        len(chunks),
        m.chat.id,
        getattr(m, "message_id", None),
        len(text or ""),
    )
    for i, chunk in enumerate(chunks):
        # –Ω–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Å–ø–∞–º–∏—Ç—å —á–∞—Ç
        if i > 0 and MULTIPART_SLEEP_MS > 0:
            await asyncio.sleep(MULTIPART_SLEEP_MS / 1000)

        try:
            await m.answer(
                _to_html(chunk),
                parse_mode="HTML",
                disable_web_page_preview=True,
            )
            logger.debug(
                "SEND: chunk %d/%d sent, len=%d",
                i + 1,
                len(chunks),
                len(chunk),
            )
        except Exception:
            logger.exception(
                "SEND: failed to send chunk %d/%d (len=%d)",
                i + 1,
                len(chunks),
                len(chunk),
            )


# ---- Verbosity helpers ----
def _detect_verbosity(text: str) -> str:
    t = (text or "").lower()
    detailed = re.search(r"\b(–ø–æ–¥—Ä–æ–±–Ω|–¥–µ—Ç–∞–ª|—Ä–∞–∑–≤—ë—Ä–Ω—É—Ç|—Ä–∞–∑–≤–µ—Ä–Ω—É—Ç|—Ä–∞–∑–±–æ—Ä|explain in detail|detailed)\b", t)
    brief    = re.search(r"\b(–∫—Ä–∞—Ç–∫|–≤\s*–¥–≤—É—Ö\s*—Å–ª–æ–≤|–∫–æ—Ä–æ—Ç–∫|–≤—ã–∂–∏–º–∫|summary|brief)\b", t)
    if detailed:
        return "detailed"
    if brief:
        return "brief"
    # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî —Å–∫–æ—Ä–µ–µ –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç–≤–µ—Ç
    if len(t) > 600:
        return "detailed"
    return "normal"


def _verbosity_addendum(verbosity: str, what: str = "–æ—Ç–≤–µ—Ç") -> str:
    """
    –ù–µ–±–æ–ª—å—à–∞—è –ø—Ä–∏–ø–∏—Å–∫–∞ –∫ –ø—Ä–æ–º–ø—Ç—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç—Ä–µ–±—É–µ–º–æ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏.
    `what` ‚Äî —á—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω—É–∂–Ω–æ –æ–ø–∏—Å—ã–≤–∞—Ç—å: '–æ—Ç–≤–µ—Ç', '–æ–ø–∏—Å–∞–Ω–∏—è —Ä–∏—Å—É–Ω–∫–æ–≤' –∏ —Ç.–ø.
    """
    what = (what or "–æ—Ç–≤–µ—Ç").strip()

    if verbosity in ("short", "brief"):
        # –ø—Ä–∏–º–µ—Ä: "–û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ (–ø–æ –æ–ø–∏—Å–∞–Ω–∏—é —Ä–∏—Å—É–Ω–∫–æ–≤)."
        return f" –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ (–ø–æ {what})."

    if verbosity == "detailed":
        # –ø—Ä–∏–º–µ—Ä: "–î–∞–π —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç–æ–µ, –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∏—Å—É–Ω–∫–æ–≤."
        return f" –î–∞–π —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç–æ–µ, –ø–æ–¥—Ä–æ–±–Ω–æ–µ {what}."

    # default ‚Äî –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —É–∫–∞–∑–∞–Ω–∏–π
    return ""

# --------------------- STREAM: –≤—Å–ø–æ–º–æ–≥–∞–ª–∫–∏ ---------------------

def _now_ms() -> int:
    return int(time.time() * 1000)

async def _typing_loop(chat_id: int, stop_event: asyncio.Event):
    try:
        while not stop_event.is_set():
            await bot.send_chat_action(chat_id, ChatAction.TYPING)
            try:
                await asyncio.wait_for(stop_event.wait(), timeout=TYPE_INDICATION_EVERY_MS / 1000)
            except asyncio.TimeoutError:
                # –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ü–∏–∫–ª, —á—Ç–æ–±—ã –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ —Å–ª–∞—Ç—å "typing"
                pass
    except Exception:
        # –≥–ª—É—à–∏–º –ª—é–±—ã–µ –Ω–µ—Ç–∏–ø–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏, —á—Ç–æ–±—ã –Ω–µ —Ä–æ–Ω—è—Ç—å —Å—Ç—Ä–∏–º
        pass



def _section_context(owner_id: int, doc_id: int, sec: str, *, max_chars: int = 9000) -> str:
    # 1) –≥–µ–Ω–µ—Ä–∏–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –∑–∞–ø–∏—Å–∏ –Ω–æ–º–µ—Ä–∞
    base = (sec or "").strip()
    variants = {
        base,
        base.replace(" ", ""),
        base.replace(" ", "").replace(",", "."),
        base.replace(" ", "").replace(".", ","),
    }
    prefixes = ["", "–†–∞–∑–¥–µ–ª ", "–ü—É–Ω–∫—Ç ", "–ì–ª–∞–≤–∞ ", "–ü–æ–¥—Ä–∞–∑–¥–µ–ª "]
    patterns = set()

    # 1Ô∏è‚É£ –¢–æ—á–Ω—ã–µ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
    for v in variants:
        patterns.add(f"%{v}%")
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –≤–∏–¥–∞: "3." "3.1", "3.2" ‚Äî –≤—Å—ë, —á—Ç–æ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –Ω—É–∂–Ω–æ–π –≥–ª–∞–≤—ã
        patterns.add(f"{v}.%")

    # 2Ô∏è‚É£ –õ—é–±—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ "–ì–ª–∞–≤–∞", "–†–∞–∑–¥–µ–ª", "–ü—É–Ω–∫—Ç"
    prefixes = ["–ì–ª–∞–≤–∞", "–†–∞–∑–¥–µ–ª", "–ü—É–Ω–∫—Ç", "Chapter", "Section"]
    for p in prefixes:
        patterns.add(f"%{p} {base}%")
        patterns.add(f"%{p}{base}%")   # –±–µ–∑ –ø—Ä–æ–±–µ–ª–∞ —Ç–æ–∂–µ –ª–æ–≤–∏–º

    # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å–ø–∏—Å–æ–∫
    patterns = list(patterns)[:12]  # –æ—Å—Ç–∞–≤–∏–º –Ω–µ–±–æ–ª—å—à–æ–π –ª–∏–º–∏—Ç


    con = get_conn()
    cur = con.cursor()

    rows = []
    if patterns:
        placeholders = " OR ".join(["section_path LIKE ?"] * len(patterns))
        cur.execute(
            f"""
            SELECT page, section_path, text
            FROM chunks
            WHERE owner_id=? AND doc_id=? AND ({placeholders})
            ORDER BY page ASC, id ASC
            """,
            (owner_id, doc_id, *patterns),
        )
        rows = cur.fetchall() or []

    # 2) —Ñ–æ–ª–±—ç–∫: –Ω–∞–π–¥—ë–º heading —Å –Ω–æ–º–µ—Ä–æ–º –∏ –≤–æ–∑—å–º—ë–º –µ–≥–æ —Å–µ–∫—Ü–∏—é
    if not rows:
        has_et = _table_has_columns(con, "chunks", ["element_type"])
        if has_et:
            cur.execute(
                """
                SELECT section_path
                FROM chunks
                WHERE owner_id=? AND doc_id=?
                AND (element_type='heading' OR element_type IS NULL)
                AND (section_path LIKE ? OR text LIKE ?)
                ORDER BY page ASC, id ASC LIMIT 1
                """,
                (owner_id, doc_id, f"%{base}%", f"%{base}%"),
            )
        else:
            # —Å—Ç–∞—Ä–∞—è —Å—Ö–µ–º–∞ ‚Äî –±–µ–∑ —É—Å–ª–æ–≤–∏—è –ø–æ element_type
            cur.execute(
                """
                SELECT section_path
                FROM chunks
                WHERE owner_id=? AND doc_id=?
                AND (section_path LIKE ? OR text LIKE ?)
                ORDER BY page ASC, id ASC LIMIT 1
                """,
                (owner_id, doc_id, f"%{base}%", f"%{base}%"),
            )
        h = cur.fetchone()
        if h and h["section_path"]:
            cur.execute(
                """
                SELECT page, section_path, text
                FROM chunks
                WHERE owner_id=? AND doc_id=? AND section_path=?
                ORDER BY page ASC, id ASC
                """,
                (owner_id, doc_id, h["section_path"]),
            )
            rows = cur.fetchall() or []

    con.close()
    if not rows:
        return ""

    parts, total = [], 0
    header_inserted = False
    for r in rows:
        secpath = (r["section_path"] or "").strip()
        t = (r["text"] or "").strip()
        if not t:
            continue
        chunk = (f"[{secpath}]\n{t}") if not header_inserted else t
        header_inserted = True
        if total + len(chunk) > max_chars:
            parts.append(chunk[: max_chars - total])
            break
        parts.append(chunk)
        total += len(chunk)
    return "\n\n".join(parts)


def _ensure_iterable(stream_obj) -> Iterable[str]:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ (a)—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∏—Ç–µ—Ä–∞—Ç–æ—Ä —Å—Ç—Ä–æ–∫; –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Å–ª—É—á–∞–π, –∫–æ–≥–¥–∞ –ø—Ä–∏–ª–µ—Ç–µ–ª–∞ –∫–æ—Ä—É—Ç–∏–Ω–∞."""
    import inspect

    # –ï—Å–ª–∏ —ç—Ç–æ –∫–æ—Ä—É—Ç–∏–Ω–∞ ‚Äî –æ–±–µ—Ä–Ω—ë–º –≤ async-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä, –∫–æ—Ç–æ—Ä—ã–π —Å–Ω–∞—á–∞–ª–∞ –µ—ë await-–∏—Ç,
    # –∞ –ø–æ—Ç–æ–º —É–∂–µ –∏—Ç–µ—Ä–∏—Ä—É–µ—Ç—Å—è –ø–æ —Ä–µ–∞–ª—å–Ω–æ–º—É —Å—Ç—Ä–∏–º—É.
    if inspect.iscoroutine(stream_obj):
        async def _await_then_iter():
            real = await stream_obj
            if hasattr(real, "__aiter__"):
                async for chunk in real:
                    yield chunk
            else:
                for chunk in real:
                    yield chunk
        return _await_then_iter()

    if hasattr(stream_obj, "__aiter__"):
        async def _drain_to_queue(q: asyncio.Queue):
            try:
                async for chunk in stream_obj:  # type: ignore
                    await q.put(chunk or "")
            except Exception:
                pass
            finally:
                await q.put(None)

        queue: asyncio.Queue = asyncio.Queue()

        async def _producer():
            await _drain_to_queue(queue)

        asyncio.create_task(_producer())

        async def _async_iter():
            while True:
                item = await queue.get()
                if item is None:
                    break
                yield item
        return _async_iter()

    return stream_obj

async def _iterate_chunks(stream_obj) -> AsyncIterable[str]:
    """–ï–¥–∏–Ω—ã–π –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ —á–∞–Ω–∫–æ–≤ (—É–º–µ–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∏ —Å sync-, –∏ —Å async-–∏—Ç–µ—Ä–∞—Ç–æ—Ä–∞–º–∏)."""
    if hasattr(stream_obj, "__aiter__"):
        async for ch in stream_obj:
            if ch:
                yield str(ch)
        return
    for ch in stream_obj:
        if ch:
            yield str(ch)

def _smart_cut_point(s: str, limit: int) -> int:
    """–ò—â–µ–º ¬´–∫—Ä–∞—Å–∏–≤–æ–µ¬ª –º–µ—Å—Ç–æ —Ä–∞–∑—Ä–µ–∑–∞ <= limit (–ø–æ –ø–µ—Ä–µ–Ω–æ—Å—É/—Ç–æ—á–∫–µ/–ø—Ä–æ–±–µ–ª—É)."""
    if len(s) <= limit:
        return len(s)
    cut = s.rfind("\n", 0, limit)
    if cut == -1:
        cut = s.rfind(". ", 0, limit)
    if cut == -1:
        cut = s.rfind(" ", 0, limit)
    if cut == -1:
        cut = limit
    return max(1, cut)

# --- [VISION] helpers: –≤—ã–±—Ä–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏ –ø—Ä–∏–≤–µ—Å—Ç–∏ –ø–∞—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π ---
def _pick_images_from_hits(hits: list[dict], limit: int = 3) -> list[str]:
    acc: list[str] = []
    for h in hits or []:
        attrs = (h.get("attrs") or {})

        # 1) —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—É—Ç—å: attrs.images
        for p in (attrs.get("images") or []):
            if p and os.path.exists(p) and p not in acc:
                acc.append(p)
            if len(acc) >= limit:
                return acc

        # 2) —Ñ–æ–ª–±—ç–∫: –∏–Ω–æ–≥–¥–∞ –ø—É—Ç—å –ª–µ–∂–∏—Ç –ø—Ä—è–º–æ –≤ —Å–∞–º–æ–º —Ö–∏—Ç–µ
        for p in (
            h.get("image_path"),
            h.get("image"),
        ):
            if p and os.path.exists(p) and p not in acc:
                acc.append(p)
            if len(acc) >= limit:
                return acc

    return acc


def _pairs_to_bullets(pairs: list[dict]) -> str:
    """
    –ê–∫–∫—É—Ä–∞—Ç–Ω–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø–∞—Ä—ã (label, value, unit):
    - 0.25 –ø—Ä–∏ unit='%‚Äô ‚Üí 25%;
    - —á–∏—Å–ª–∞ –æ–∫—Ä—É–≥–ª—è–µ–º –¥–æ —Ü–µ–ª—ã—Ö –∏–ª–∏ 2 –∑–Ω–∞–∫–æ–≤;
    - —É–±–∏—Ä–∞–µ–º —Ö–≤–æ—Å—Ç—ã –≤–∏–¥–∞ 0.42000000000000004.
    """
    def _fmt(value, unit: str) -> str:
        unit = (unit or "").strip()
        sval = ""
        v_num: float | None = None

        # –ø—Ä–æ–±—É–µ–º –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —á–∏—Å–ª—É
        if isinstance(value, (int, float, Decimal)):
            v_num = float(value)
        else:
            try:
                v_num = float(str(value).replace(",", "."))
            except Exception:
                sval = str(value) if value is not None else ""

        if v_num is not None:
            # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –¥–æ–ª–∏ —Å unit='%' ‚Üí –ø—Ä–æ—Ü–µ–Ω—Ç—ã
            if unit and "%" in unit and 0.0 <= v_num <= 1.2:
                v_num *= 100.0

            if abs(v_num - round(v_num)) < 0.05:
                sval = str(int(round(v_num)))
            else:
                sval = f"{v_num:.2f}".rstrip("0").rstrip(".")

        # –¥–æ–±–∞–≤–ª—è–µ–º –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
        if unit:
            if "%" in unit and not sval.endswith("%"):
                sval += "%"
            else:
                sval += f" {unit}"
        return sval

    lines: list[str] = []
    for r in (pairs or []):
        lab = (str(r.get("label") or "")).strip()
        unit = (str(r.get("unit") or "")).strip()
        raw_val = r.get("value")
        val = _fmt(raw_val, unit)

        if not lab and not val:
            continue
        if lab and val:
            lines.append(f"‚Äî {lab}: {val}")
        elif lab:
            lines.append(f"‚Äî {lab}")
        else:
            lines.append(f"‚Äî {val}")
    return "\n".join(lines)


async def _stream_to_telegram(m: types.Message, stream, head_text: str = "‚åõÔ∏è –ü–µ—á–∞—Ç–∞—é –æ—Ç–≤–µ—Ç‚Ä¶") -> None:
    logger.info(
        "STREAM: start for chat_id=%s message_id=%s",
        m.chat.id,
        getattr(m, "message_id", None),
    )
    current_text = ""
    sent_parts = 0
    initial = await m.answer(
        _to_html(head_text),
        parse_mode="HTML",
        disable_web_page_preview=True,
    )
    last_edit_at = _now_ms() - STREAM_HEAD_START_MS
    stop_typer = asyncio.Event()
    typer_task = asyncio.create_task(_typing_loop(m.chat.id, stop_event=stop_typer))

    # üîß –Ω–æ–≤–æ–µ: –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏ –≤ multi –±–æ–ª—å—à–µ –Ω–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º initial
    freeze_initial = False

    try:
        async for delta in _iterate_chunks(_ensure_iterable(stream)):
            current_text += delta

            # 3.a) –º—É–ª—å—Ç–∏-—Ä–µ–∂–∏–º: —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–æ—Ä—Ü–∏—è–º–∏
            if STREAM_MODE == "multi" and len(current_text) >= TG_SPLIT_TARGET:
                cut = -1
                for mm in _SPLIT_ANCHOR_RE.finditer(current_text[: min(len(current_text), TG_MAX_CHARS)]):
                    if mm.start() < TG_SPLIT_TARGET:
                        cut = mm.start()
                if cut <= 0:
                    cut = _smart_cut_point(current_text, min(TG_MAX_CHARS, TG_SPLIT_TARGET))

                part = current_text[:cut].rstrip()
                try:
                    if sent_parts == 0:
                        await initial.edit_text(
                            _to_html(part),
                            parse_mode="HTML",
                            disable_web_page_preview=True,
                        )
                        freeze_initial = True  # <- –±–æ–ª—å—à–µ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º initial
                    else:
                        await m.answer(
                            _to_html(part),
                            parse_mode="HTML",
                            disable_web_page_preview=True,
                        )
                except TelegramBadRequest:
                    await m.answer(
                        _to_html(part),
                        parse_mode="HTML",
                        disable_web_page_preview=True,
                    )

                sent_parts += 1  # ### –î–û–ë–ê–í–õ–ï–ù–û: —Å—á–∏—Ç–∞–µ–º –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —á–∞—Å—Ç–∏
                current_text = current_text[cut:].lstrip()
                last_edit_at = _now_ms()
                continue

            # 3.b) –∑–∞—â–∏—Ç–∞ –æ—Ç –ª–∏–º–∏—Ç–∞
            if len(current_text) >= TG_MAX_CHARS:
                cut = _smart_cut_point(current_text, TG_MAX_CHARS)
                final_part = current_text[:cut]

                if STREAM_MODE == "multi" and (freeze_initial or sent_parts > 0):
                    # üîß –≤ multi –Ω–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º initial –ø–æ—Å–ª–µ 1-–π —á–∞—Å—Ç–∏
                    await m.answer(
                        _to_html(final_part),
                        parse_mode="HTML",
                        disable_web_page_preview=True,
                    )
                else:
                    try:
                        await initial.edit_text(
                            _to_html(final_part),
                            parse_mode="HTML",
                            disable_web_page_preview=True,
                        )
                    except TelegramBadRequest:
                        await m.answer(
                            _to_html(final_part),
                            parse_mode="HTML",
                            disable_web_page_preview=True,
                        )

                sent_parts += 1  # ### –î–û–ë–ê–í–õ–ï–ù–û: —ç—Ç–∞ —á–∞—Å—Ç—å —Ç–æ–∂–µ —Å—á–∏—Ç–∞–µ—Ç—Å—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π
                current_text = current_text[cut:].lstrip()
                # üîß –Ω–æ–≤—ã–π –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ –≤ edit-—Ä–µ–∂–∏–º–µ
                if STREAM_MODE == "edit":
                    initial = await m.answer(
                        _to_html("‚Ä¶"),
                        parse_mode="HTML",
                        disable_web_page_preview=True,
                    )
                last_edit_at = _now_ms()
                continue

            # 3.c) –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –ø—Ä–∞–≤–∫–∏ ‚Äî üîß –¢–û–õ–¨–ö–û –≤ —Ä–µ–∂–∏–º–µ edit
            now = _now_ms()
            if (
                STREAM_MODE == "edit"
                and (now - last_edit_at) >= STREAM_EDIT_INTERVAL_MS
                and len(current_text) >= STREAM_MIN_CHARS
            ):
                try:
                    await initial.edit_text(
                        _to_html(current_text),
                        parse_mode="HTML",
                        disable_web_page_preview=True,
                    )
                    last_edit_at = now
                except TelegramBadRequest:
                    pass

        # —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ö–≤–æ—Å—Ç
        if current_text:
            logger.info(
                "STREAM: finishing with tail, len=%d, sent_parts=%d",
                len(current_text),
                sent_parts,
            )
            # –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Ä–µ–∂–µ–º –æ—Å—Ç–∞—Ç–æ–∫ —Ç–∞–∫ –∂–µ, –∫–∞–∫ –≤ –Ω–µ—Å—Ç—Ä–∏–º–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
            tail_parts = _split_multipart(current_text or "")

            if STREAM_MODE == "multi" and sent_parts > 0:
                # –≤ multi-—Ä–µ–∂–∏–º–µ –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏ –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
                for part in tail_parts:
                    html_part = _to_html(part)
                    try:  # ### –î–û–ë–ê–í–õ–ï–ù–û: –Ω–µ –¥–∞—ë–º –∏—Å–∫–ª—é—á–µ–Ω–∏—é —É–±–∏—Ç—å –≤–µ—Å—å —Ö–≤–æ—Å—Ç
                        await m.answer(
                            html_part,
                            parse_mode="HTML",
                            disable_web_page_preview=True,
                        )
                    except TelegramBadRequest:
                        # –µ—Å–ª–∏ HTML/–¥–ª–∏–Ω–∞ —Å–ª–æ–º–∞–ª–∏ —Ä–∞–∑–º–µ—Ç–∫—É ‚Äî —à–ª—ë–º –∫–∞–∫ –µ—Å—Ç—å
                        await m.answer(part)
            else:
                # –≤ edit-—Ä–µ–∂–∏–º–µ (–∏–ª–∏ –∫–æ–≥–¥–∞ –µ—â—ë –Ω–µ –±—ã–ª–æ —á–∞—Å—Ç–µ–π) –ø–µ—Ä–≤—ã–π –∫—É—Å–æ–∫ –ø—ã—Ç–∞–µ–º—Å—è
                # –ø–æ–ª–æ–∂–∏—Ç—å –≤ initial, –∞ –æ—Å—Ç–∞–ª—å–Ω–æ–µ ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
                first = True
                for part in tail_parts:
                    html_part = _to_html(part)
                    if first:
                        try:
                            await initial.edit_text(
                                html_part,
                                parse_mode="HTML",
                                disable_web_page_preview=True,
                            )
                        except TelegramBadRequest:
                            # –µ—Å–ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å ‚Äî —à–ª—ë–º –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
                            try:
                                await m.answer(
                                    html_part,
                                    parse_mode="HTML",
                                    disable_web_page_preview=True,
                                )
                            except TelegramBadRequest:
                                await m.answer(part)
                        first = False
                    else:
                        try:
                            await m.answer(
                                html_part,
                                parse_mode="HTML",
                                disable_web_page_preview=True,
                            )
                        except TelegramBadRequest:
                            await m.answer(part)

    except Exception:
        logger.exception(
            "STREAM: unexpected error for chat_id=%s",
            m.chat.id,
        )
    finally:
        stop_typer.set()
        try:
            await typer_task
        except Exception:
            pass
        logger.info(
            "STREAM: stop for chat_id=%s message_id=%s",
            m.chat.id,
            getattr(m, "message_id", None),
        )


def _plan_subtasks_via_gpt(question: str, max_items: int = 8) -> list[dict]:
    """
    –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤ –±–µ–∑ ACE.
    –ë–µ—Ä—ë—Ç –∏—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å –∏ –ø—Ä–æ—Å–∏—Ç GPT —Ä–∞–∑–±–∏—Ç—å –µ–≥–æ –Ω–∞ 2‚ÄìN –ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ dict: {"id": int, "ask": str}.
    """
    question = (question or "").strip()
    if not question:
        return []

    if "chat_with_gpt" not in globals() or chat_with_gpt is None:
        return []

    system_prompt = (
        "–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å —Å—Ç—É–¥–µ–Ω—Ç—É —Å –¥–∏–ø–ª–æ–º–æ–º. –ü–æ–ª—É—á–∏–≤ —Å–ª–æ–∂–Ω—ã–π –∏–ª–∏ –º–Ω–æ–≥–æ—á–∞—Å—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å, "
        "—Ä–∞–∑–±–µ–π –µ–≥–æ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—ã—Ö –ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–æ–±—Ä–∞—Ç—å. "
        "–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON-–º–∞—Å—Å–∏–≤ –±–µ–∑ —Ç–µ–∫—Å—Ç–∞ –≤–æ–∫—Ä—É–≥, —Ñ–æ—Ä–º–∞—Ç–∞:\n"
        "[{\"id\": 1, \"ask\": \"...\"}, {\"id\": 2, \"ask\": \"...\"}, ...].\n"
        "–ù–µ –¥–æ–±–∞–≤–ª—è–π –ø–æ—è—Å–Ω–µ–Ω–∏–π, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏ —Ç–µ–∫—Å—Ç–∞ –≤–Ω–µ JSON."
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": question},
    ]

    try:
        raw = chat_with_gpt(messages, temperature=0.0, max_tokens=400) or ""
    except Exception as e:
        logging.exception("plan_subtasks_via_gpt failed: %s", e)
        return []

    raw = raw.strip()

    # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã–¥–µ—Ä–Ω—É—Ç—å JSON-–º–∞—Å—Å–∏–≤
    data = None
    try:
        data = json.loads(raw)
    except Exception:
        m = re.search(r"\[[\s\S]*\]", raw)
        if not m:
            return []
        try:
            data = json.loads(m.group(0))
        except Exception:
            return []

    if not isinstance(data, list):
        return []

    items: list[dict] = []
    for i, it in enumerate(data, start=1):
        if isinstance(it, str):
            ask = it.strip()
            if not ask:
                continue
            items.append({"id": i, "ask": ask})
        elif isinstance(it, dict):
            ask = str(it.get("ask") or it.get("question") or it.get("text") or "").strip()
            if not ask:
                continue
            iid = it.get("id") or i
            items.append({"id": iid, "ask": ask})
        if len(items) >= max_items:
            break

    return items


def _answer_subpoint_via_gpt(
    ask: str,
    ctx_text: str,
    base_question: str,
    *,
    verbosity: str = "normal",
) -> str:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –ø–æ –æ–¥–Ω–æ–º—É –ø–æ–¥–ø—É–Ω–∫—Ç—É —á–µ—Ä–µ–∑ GPT (–±–µ–∑ ACE).
    """
    ask = (ask or "").strip()
    if not ask:
        return ""

    if "chat_with_gpt" not in globals() or chat_with_gpt is None:
        return ""

    ctx = (ctx_text or "").strip()

    system_prompt = (
        "–¢—ã —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ –¥–∏–ø–ª–æ–º–Ω—ã–º —Ä–∞–±–æ—Ç–∞–º. –¢–µ–±–µ –¥–∞–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞ –¥–∏–ø–ª–æ–º–∞ "
        "–∏ –æ–¥–∏–Ω –ø–æ–¥–ø—É–Ω–∫—Ç –≤–æ–ø—Ä–æ—Å–∞.\n"
        "–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –ø–æ —ç—Ç–æ–º—É —Ñ—Ä–∞–≥–º–µ–Ω—Ç—É. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç–æ–≤, —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏ –ø—Ä–µ–¥–º–µ—Ç–Ω—É—é –æ–±–ª–∞—Å—Ç—å, "
        "–∫–æ—Ç–æ—Ä—ã—Ö –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–µ —É–ø–æ–º–∏–Ω–∞–π –ø—Ä–æ–¥–∞–∂–∏, –∫–ª–∏–µ–Ω—Ç–æ–≤, –≤—ã—Ä—É—á–∫—É, –º–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ —Ç.–ø., "
        "–µ—Å–ª–∏ —ç—Ç–∏—Ö —Å–ª–æ–≤ –Ω–µ—Ç –≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ). –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —É–≤–µ—Ä–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞, "
        "—á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º –∏ –ø—Ä—è–º–æ –Ω–∞–ø–∏—à–∏, —á—Ç–æ –≤ —ç—Ç–æ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ –æ–± —ç—Ç–æ–º –Ω–µ —Å–∫–∞–∑–∞–Ω–æ.\n"
        "–ù–µ –¥–æ–±–∞–≤–ª—è–π —Ä–∞–∑–¥–µ–ª—ã –≤–∏–¥–∞ ¬´—á–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç¬ª."
    )


    if ctx:
        assistant_ctx = f"[–§—Ä–∞–≥–º–µ–Ω—Ç –¥–∏–ø–ª–æ–º–∞]\n{ctx}"
    else:
        assistant_ctx = "[–§—Ä–∞–≥–º–µ–Ω—Ç –ø–æ —ç—Ç–æ–º—É –ø–æ–¥–ø—É–Ω–∫—Ç—É –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–µ–∫—Å—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞]"

    user_prompt = (
        f"–ò—Å—Ö–æ–¥–Ω—ã–π –æ–±—â–∏–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n{base_question}\n\n"
        f"–¢–µ–∫—É—â–∏–π –ø–æ–¥–ø—É–Ω–∫—Ç (–ø–æ–¥–≤–æ–ø—Ä–æ—Å): {ask}\n\n"
        "–û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ —ç—Ç–æ–º—É –ø–æ–¥–ø—É–Ω–∫—Ç—É, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–∏–ø–ª–æ–º–∞."
        f"{_verbosity_addendum(verbosity)}"
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "assistant", "content": assistant_ctx},
        {"role": "user", "content": user_prompt},
    ]

    try:
        ans = chat_with_gpt(messages, temperature=0.2, max_tokens=FINAL_MAX_TOKENS) or ""
    except Exception as e:
        logging.exception("answer_subpoint_via_gpt failed: %s", e)
        return ""

    return ans.strip()


def _merge_subanswers_via_gpt(
    base_question: str,
    items: list[dict],
    subanswers: list[str],
    *,
    verbosity: str = "normal",
) -> str:
    """
    –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–≤–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ –≤—Å–µ–º –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º –±–µ–∑ ACE.
    """
    if not subanswers:
        return ""

    if "chat_with_gpt" not in globals() or chat_with_gpt is None:
        return ""

    blocks: list[str] = []
    for i, ans in enumerate(subanswers, start=1):
        it = items[i - 1] if i - 1 < len(items) else {}
        ask = (isinstance(it, dict) and (it.get("ask") or "")) or ""
        ask = str(ask).strip()
        header = f"[–ü–æ–¥–ø—É–Ω–∫—Ç {i}" + (f": {ask}]" if ask else "]")
        blocks.append(f"{header}\n{ans}")

    ctx = "\n\n".join(blocks)

    system_prompt = (
        "–¢—ã —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ –¥–∏–ø–ª–æ–º–Ω—ã–º —Ä–∞–±–æ—Ç–∞–º. –ù–∏–∂–µ —Å–æ–±—Ä–∞–Ω—ã –æ—Ç–≤–µ—Ç—ã –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º "
        "–æ–¥–Ω–æ–≥–æ –±–æ–ª—å—à–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–¥–µ–ª–∞—Ç—å –æ–¥–∏–Ω —Å–≤—è–∑–Ω—ã–π –æ–±—â–∏–π –æ—Ç–≤–µ—Ç.\n"
        "–ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –¥–æ—Å–ª–æ–≤–Ω–æ –≤—Å–µ –ø–æ–¥–ø—É–Ω–∫—Ç—ã, –∞ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –∏—Ö –æ–±—ä–µ–¥–∏–Ω—è–π. "
        "–ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—ã—Ö —Ñ–∞–∫—Ç–æ–≤, —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏ –ø—Ä–µ–¥–º–µ—Ç–Ω—É—é –æ–±–ª–∞—Å—Ç—å, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –ø–æ–¥–ø—É–Ω–∫—Ç–∞—Ö "
        "(–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –ø—Ä–æ–¥–∞–∂–∏, –∫–ª–∏–µ–Ω—Ç–æ–≤, –≤—ã—Ä—É—á–∫—É, –º–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ —Ç.–ø., –µ—Å–ª–∏ —ç—Ç–æ–≥–æ –Ω–µ—Ç "
        "–≤ —Å–∞–º–∏—Ö –ø–æ–¥–ø—É–Ω–∫—Ç–∞—Ö).\n"
        "–ù–µ –ø–∏—à–∏ —Ä–∞–∑–¥–µ–ª—ã –≤–∏–¥–∞ ¬´—á–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç¬ª."
    )


    user_prompt = (
        f"–ò—Å—Ö–æ–¥–Ω—ã–π –æ–±—â–∏–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n{base_question}\n\n"
        "–ù–∞ –Ω–µ–≥–æ —É–∂–µ –µ—Å—Ç—å –æ—Ç–≤–µ—Ç—ã –ø–æ –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º (—Å–º. –Ω–∏–∂–µ). "
        "–°–æ–±–µ—Ä–∏ –∏–∑ –Ω–∏—Ö –æ–¥–∏–Ω —Ü–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."
        f"{_verbosity_addendum(verbosity)}\n\n"
        "[–û—Ç–≤–µ—Ç—ã –ø–æ –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º]\n"
        f"{ctx}"
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]

    try:
        merged = chat_with_gpt(messages, temperature=0.2, max_tokens=FINAL_MAX_TOKENS) or ""
    except Exception as e:
        logging.exception("merge_subanswers_via_gpt failed: %s", e)
        return ""

    return merged.strip()


async def _run_multistep_answer(
    m: types.Message,
    uid: int,
    doc_id: int,
    q_text: str,
    *,
    discovered_items: list[dict] | None = None,
) -> bool:
    """
    –ú–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ ACE:
    1) –ü–ª–∞–Ω –ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤ ‚Äî —á–µ—Ä–µ–∑ _plan_subtasks_via_gpt –∏–ª–∏ coverage.
    2) –ü–æ –∫–∞–∂–¥–æ–º—É –ø–æ–¥–ø—É–Ω–∫—Ç—É ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ GPT —Å –∂—ë—Å—Ç–∫–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º.
    3) (–æ–ø—Ü.) —Ñ–∏–Ω–∞–ª—å–Ω—ã–π merge —á–µ—Ä–µ–∑ _merge_subanswers_via_gpt.
    """
    if not MULTI_STEP_SEND_ENABLED:
        return False

    # GPT –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è —ç—Ç–æ–≥–æ —Ä–µ–∂–∏–º–∞
    if "chat_with_gpt" not in globals() or chat_with_gpt is None:
        return False

    verbosity = _detect_verbosity(q_text)

    # 1) –ø–ª–∞–Ω –∏–∑ coverage/discovered_items –∏–ª–∏ —Å—Ç—Ä–æ–∏–º —á–µ—Ä–µ–∑ GPT
    items = (discovered_items or [])
    if not items:
        items = _plan_subtasks_via_gpt(q_text, max_items=MULTI_STEP_MAX_ITEMS)

    # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –∏ dict, –∏ str
    norm_items: list[dict] = []
    for idx, it in enumerate(items, start=1):
        if isinstance(it, str):
            ask = it.strip()
            if ask:
                norm_items.append({"id": idx, "ask": ask})
        elif isinstance(it, dict):
            ask = (it.get("ask") or it.get("text") or it.get("q") or "").strip()
            if ask:
                norm_items.append({"id": it.get("id") or idx, "ask": ask})

    items = [it for it in norm_items if (it.get("ask") or "").strip()]
    if len(items) < MULTI_STEP_MIN_ITEMS:
        return False

    # –æ—Ç—Å–µ—á—ë–º —Ö–≤–æ—Å—Ç –ø–æ –ª–∏–º–∏—Ç—É
    items = items[:MULTI_STEP_MAX_ITEMS]

    # –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–æ–Ω—Å
    preview = "\n".join([f"{i+1}) {(it['ask'] or '').strip()}" for i, it in enumerate(items)])
    await _send(
        m,
        f"–í–æ–ø—Ä–æ—Å –º–Ω–æ–≥–æ—á–∞—Å—Ç–Ω—ã–π. –û—Ç–≤–µ—á–∞—é –ø–æ –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º ({len(items)} —à—Ç.):\n\n{preview}",
    )

    subanswers: list[str] = []

    # coverage-aware —Ä–∞–∑–¥–∞—á–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤: —Ä–∞–∑–ª–æ–∂–∏–º –≤—ã–∂–∏–º–∫–∏ –ø–æ –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º
    cov = None
    try:
        cov = retrieve_coverage(owner_id=uid, doc_id=doc_id, question=q_text)
    except Exception:
        cov = None
    cov_map = (cov or {}).get("by_item") or {}

    # –ø–æ –æ—á–µ—Ä–µ–¥–∏: A ‚Üí send, B ‚Üí send, ...
    for i, it in enumerate(items, start=1):
        ask = (it.get("ask") or "").strip()
        if not ask:
            continue

        # –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–¥–ø—É–Ω–∫—Ç–∞
        ctx_text = ""
        try:
            # –µ—Å–ª–∏ –µ—Å—Ç—å coverage-–±–∞–∫–µ—Ç ‚Äî —Å–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä—è–º–æ –∏–∑ —á–∞–Ω–∫–æ–≤ –ø–æ–¥–ø—É–Ω–∫—Ç–∞
            bucket = cov_map.get(str(it.get("id") or i)) or []
            if bucket:
                ctx_text = build_context_coverage(bucket, items_count=1)
        except Exception:
            ctx_text = ""

        # —Ñ–æ–ª–±—ç–∫–∏ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
        if not ctx_text:
            ctx_text = best_context(uid, doc_id, ask, max_chars=6000) or ""
        if not ctx_text:
            hits = retrieve(uid, doc_id, ask, top_k=8)
            if hits:
                ctx_text = build_context(hits)
        if not ctx_text:
            ctx_text = _first_chunks_context(uid, doc_id, n=12, max_chars=6000)

        # –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ –ø–æ–¥–ø—É–Ω–∫—Ç—É —á–µ—Ä–µ–∑ GPT (–±–µ–∑ ACE)
        try:
            part = _answer_subpoint_via_gpt(
                ask=ask,
                ctx_text=ctx_text,
                base_question=q_text,
                verbosity=verbosity,
            )
        except Exception as e:
            logging.exception("answer_subpoint_via_gpt failed: %s", e)
            part = ""

        # –æ—Ç–ø—Ä–∞–≤–∫–∞ –±–ª–æ–∫–∞
        header = f"**{i}. {ask}**\n\n"
        await _send(m, header + (part or "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –ø–æ —ç—Ç–æ–º—É –ø–æ–¥–ø—É–Ω–∫—Ç—É."))
        subanswers.append(f"{header}{part}")

        # –º–∏–∫—Ä–æ–ø–∞—É–∑a, —á—Ç–æ–±—ã –Ω–µ —É–ø–µ—Ä–µ—Ç—å—Å—è –≤ rate/—á–∞—Ç—ã
        await asyncio.sleep(MULTI_STEP_PAUSE_MS / 1000)

    # (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–≤–æ–¥–Ω—ã–π –±–ª–æ–∫
    if MULTI_STEP_FINAL_MERGE and subanswers:
        try:
            merged = _merge_subanswers_via_gpt(
                base_question=q_text,
                items=items,
                subanswers=subanswers,
                verbosity=verbosity,
            ).strip()
            if merged:
                await _send(m, "**–ò—Ç–æ–≥–æ–≤—ã–π —Å–≤–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç**\n\n" + merged)
        except Exception as e:
            logging.exception("merge_subanswers_via_gpt failed: %s", e)

    return True

def _should_use_multistep(q_text: str, discovered_items: list[dict] | None) -> bool:
    """
    –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –≤–∫–ª—é—á–∞–µ–º –º–Ω–æ–≥–æ—à–∞–≥–æ–≤—ã–π —Ä–µ–∂–∏–º, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏:
      ‚Äî –º—É–ª—å—Ç–∏–æ—Ç–≤–µ—Ç –≤–æ–æ–±—â–µ —Ä–∞–∑—Ä–µ—à—ë–Ω –∫–æ–Ω—Ñ–∏–≥–æ–º;
      ‚Äî –µ—Å—Ç—å –ø–æ–¥–ø—É–Ω–∫—Ç—ã –∏–∑ coverage/general_subitems;
      ‚Äî –ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤ –Ω–µ –º–µ–Ω—å—à–µ MULTI_STEP_MIN_ITEMS;
      ‚Äî –≤–æ–ø—Ä–æ—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–π (—á—Ç–æ–±—ã —Å—Ç–æ–∏–ª–æ –≥–æ—Ä–æ–¥–∏—Ç—å –ø–æ–¥–ø—É–Ω–∫—Ç—ã).
    """
    if not MULTI_STEP_SEND_ENABLED:
        return False

    if not discovered_items:
        return False

    if len(discovered_items) < MULTI_STEP_MIN_ITEMS:
        return False

    if len((q_text or "").strip()) < MULTI_STEP_MIN_QUESTION_LEN:
        return False

    return True


# summarizer (–º—è–≥–∫–∏–π –∏–º–ø–æ—Ä—Ç)
try:
    from .summarizer import is_summary_intent, overview_context  # –º–æ–≥—É—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å ‚Äî –µ—Å—Ç—å —Ñ–æ–ª–±—ç–∫–∏ –Ω–∏–∂–µ
except Exception:
    def is_summary_intent(text: str) -> bool:
        return bool(re.search(
            r"\b(—Å—É—Ç—å|–∫—Ä–∞—Ç–∫–æ|–æ—Å–Ω–æ–≤–Ω|–≥–ª–∞–≤–Ω|summary|overview|–∏—Ç–æ–≥|–≤—ã–≤–æ–¥)\w*\b",
            text or "",
            re.IGNORECASE,
        ))

    def overview_context(owner_id: int, doc_id: int, max_chars: int = 6000) -> str:
        con = get_conn()
        cur = con.cursor()
        cur.execute(
            """
            SELECT page, section_path, text
            FROM chunks
            WHERE owner_id=? AND doc_id=?
              AND (text LIKE '[–ó–∞–≥–æ–ª–æ–≤–æ–∫]%%'
                   OR text LIKE '%%–¶–µ–ª—å%%'
                   OR text LIKE '%%–ó–∞–¥–∞—á%%'
                   OR text LIKE '%%–í–≤–µ–¥–µ–Ω%%'
                   OR text LIKE '%%–ó–∞–∫–ª—é—á–µ–Ω%%'
                   OR text LIKE '%%–í—ã–≤–æ–¥%%')
            ORDER BY page ASC, id ASC
            LIMIT 14
            """,
            (owner_id, doc_id),
        )
        rows = cur.fetchall()
        con.close()
        if not rows:
            return ""
        parts, total = [], 0
        for r in rows:
            block = f"{(r['text'] or '').strip()}"
            if total + len(block) > max_chars:
                break
            parts.append(block)
            total += len(block)
        return "\n\n".join(parts)

# NEW: —Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞ (—á–µ—Ä–µ–∑ vision-–∞–Ω–∞–ª–∏–∑ –≤ summarizer.py)
try:
    from .summarizer import extract_figure_value as summ_extract_figure_value  # type: ignore
except Exception:
    # –µ—Å–ª–∏ summarizer –∏–ª–∏ —Å–∞–º–∞ —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã ‚Äî –ø—Ä–æ—Å—Ç–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ–ª–±—ç–∫ –ø–æ –∫–∞—Ä—Ç–∏–Ω–∫–∞–º
    summ_extract_figure_value = None  # type: ignore

# vision-–æ–ø–∏—Å–∞–Ω–∏–µ —Ä–∏—Å—É–Ω–∫–æ–≤ (–º—è–≥–∫–∏–π –∏–º–ø–æ—Ä—Ç; –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –æ—Ç–≤–µ—á–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–º —Ñ–æ–ª–±—ç–∫–æ–º)
try:
    from .summarizer import describe_figures as vision_describe_figures
except Exception:
    def vision_describe_figures(owner_id: int, doc_id: int, numbers: list[str]) -> str:
        if not numbers:
            return "–ù–µ —É–∫–∞–∑–∞–Ω—ã –Ω–æ–º–µ—Ä–∞ —Ä–∏—Å—É–Ω–∫–æ–≤."
        return "–û–ø–∏—Å–∞–Ω–∏—è —Ä–∏—Å—É–Ω–∫–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã (vision-–º–æ–¥—É–ª—å –Ω–µ –ø–æ–¥–∫–ª—é—á—ë–Ω)."


# NEW: —Ç–æ—á–µ—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–∏ (—Å–≤—è–∑–Ω—ã–π —Ç–µ–∫—Å—Ç + —á–∏—Å–ª–∞)
try:
    from .vision_analyzer import analyze_figure as va_analyze_figure
    logger.info("vision_analyzer loaded OK: %r", va_analyze_figure)  # type: ignore
except Exception as e:
    logger.exception("vision_analyzer import failed: %s", e)
    va_analyze_figure = None  # type: ignore

# –ì–û–°–¢-–≤–∞–ª–∏–¥–∞—Ç–æ—Ä (–º—è–≥–∫–∏–π –∏–º–ø–æ—Ä—Ç)
try:
    from .validators_gost import validate_gost, render_report
except Exception:
    validate_gost = None
    render_report = None


# ¬´–ê–∫—Ç–∏–≤–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç¬ª –≤ –ø–∞–º—è—Ç–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞
ACTIVE_DOC: dict[int, int] = {}  # user_id -> doc_id
# NEW: –∫–æ—Ä–æ—Ç–∫–∞—è ¬´–ø–∞–º—è—Ç—å¬ª –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —É–ø–æ–º—è–Ω—É—Ç–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
LAST_REF: dict[int, dict] = {}   # {uid: {"figure_nums": list[str], "area": "3.2"}}
FIG_INDEX: dict[int, dict] = {}
OOXML_INDEX: dict[int, dict] = {}
# NEW: –∫–µ—à –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö ¬´—Ç–∞–±–ª–∏—Ü-–∫–∞—Ä—Ç–∏–Ω–æ–∫¬ª (doc_id, num) -> —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫
_OCR_TABLE_CACHE: dict[tuple[int, str], str] = {}

# NEW: –∂–¥—ë–º –ª–∏ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ¬´–¥–∞/–Ω–µ—Ç¬ª –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç [–º–æ–¥–µ–ª—å]
MODEL_EXTRA_PENDING: dict[int, dict] = {}   # {uid: {...}}

# --- helpers –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ "–¥–∞/–Ω–µ—Ç" –Ω–∞ —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å –ø—Ä–æ [–º–æ–¥–µ–ª—å] ---
_YES_RE = re.compile(r"(?i)^(–¥–∞|–∞–≥–∞|—É–≥—É|yes|yep|ok|–æ–∫–µ–π|–ª–∞–¥–Ω–æ|—Ö–æ—Ä–æ—à–æ)\b")
_NO_RE  = re.compile(r"(?i)^(–Ω–µ—Ç|–Ω–µ–∞|no|nope)\b")

def _is_yes_answer(text: str) -> bool:
    return bool(_YES_RE.search((text or "").strip()))

def _is_no_answer(text: str) -> bool:
    return bool(_NO_RE.search((text or "").strip()))

# NEW: –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–æ–º–µ—Ä–∞ —Ä–∞–∑–¥–µ–ª–∞ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞ –∏ –¥–ª—è –∞–Ω–∞—Ñ–æ—Ä—ã ¬´—ç—Ç–æ—Ç –ø—É–Ω–∫—Ç/—Ä–∏—Å—É–Ω–æ–∫¬ª
# NEW: –¥–ª—è –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–æ–º–µ—Ä–∞ —Ä–∞–∑–¥–µ–ª–∞ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞ –∏ –¥–ª—è –∞–Ω–∞—Ñ–æ—Ä—ã ¬´—ç—Ç–æ—Ç –ø—É–Ω–∫—Ç/—Ä–∏—Å—É–Ω–æ–∫¬ª
_SECTION_NUM_RE = re.compile(
    r"(?i)\b(?:–≥–ª–∞–≤–∞\w*|—Ä–∞–∑–¥–µ–ª\w*|–ø—É–Ω–∫—Ç\w*|–ø–æ–¥—Ä–∞–∑–¥–µ–ª\w*|sec(?:tion)?\.?|chapter)"
    r"\s*(?:‚Ññ\s*)?((?:[A-Za-z–ê-–Ø–∞-—è](?=[\.\d]))?\s*\d+(?:[.,]\d+)*)"
)
_ANAPH_HINT_RE = re.compile(r"(?i)\b(—ç—Ç–æ—Ç|—ç—Ç–∞|—ç—Ç–æ|–¥–∞–Ω–Ω\w+|–ø—Ä–æ –Ω–µ–≥–æ|–ø—Ä–æ –Ω–µ—ë|–ø—Ä–æ –Ω–µ–µ)\b")

# —Å—á–∏—Ç–∞–µ–º "—É—Ç–æ—á–Ω—è—é—â–∏–º" –ª—é–±–æ–π –∑–∞–ø—Ä–æ—Å, –≥–¥–µ –µ—Å—Ç—å –≥–ª–∞–≥–æ–ª + —Å–ª–æ–≤–æ "–ø–æ–¥—Ä–æ–±–Ω–µ–µ" –≤ –æ–¥–Ω–æ–π —Ñ—Ä–∞–∑–µ
_FOLLOWUP_MORE_RE = re.compile(
    r"(?i)\b(–æ–ø–∏—à–∏|—Ä–∞—Å–ø–∏—à–∏|–æ–±—ä—è—Å–Ω–∏|—Ä–∞—Å—Å–∫–∞–∂–∏)\b.*\b–ø–æ–¥—Ä–æ–±–Ω–µ–µ\b|\b–ø–æ–¥—Ä–æ–±–Ω–µ–µ\b.*\b(–æ–ø–∏—à–∏|—Ä–∞—Å–ø–∏—à–∏|–æ–±—ä—è—Å–Ω–∏|—Ä–∞—Å—Å–∫–∞–∂–∏)\b"
)

def _expand_with_last_referent(uid: int, text: str) -> str:
    """
    –ü–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ–±—ä–µ–∫—Ç (—Ç–∞–±–ª–∏—Ü–∞/—Ä–∏—Å—É–Ω–æ–∫/–ø—É–Ω–∫—Ç) –¥–ª—è —Ä–µ–ø–ª–∏–∫ –≤–∏–¥–∞:
      - ¬´–æ–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ¬ª
      - ¬´—Ä–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ –Ω–µ–≥–æ¬ª
      - ¬´–æ–ø–∏—à–∏ –µ—ë –ø–æ–¥—Ä–æ–±–Ω–µ–µ¬ª
    —á—Ç–æ–±—ã –æ–Ω–∏ –ø—Ä–µ–≤—Ä–∞—Ç–∏–ª–∏—Å—å, –Ω–∞–ø—Ä–∏–º–µ—Ä, –≤
      - ¬´–æ–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ (–∏–º–µ–µ—Ç—Å—è –≤ –≤–∏–¥—É —Ç–∞–±–ª–∏—Ü–∞ 4)¬ª.
    """
    t = (text or "").strip()
    if not t:
        return text

    # –µ—Å–ª–∏ —É–∂–µ —è–≤–Ω–æ —É–∫–∞–∑–∞–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞/—Ä–∏—Å—É–Ω–æ–∫/–ø—É–Ω–∫—Ç ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ –º–µ–Ω—è–µ–º
    if _TABLE_NUM_IN_TEXT_RE.search(t) or FIG_NUM_RE.search(t) or _SECTION_NUM_RE.search(t):
        return text

    # –Ω–µ—Ç –Ω–∏ –∞–Ω–∞—Ñ–æ—Ä—ã (¬´—ç—Ç–æ—Ç/–ø—Ä–æ –Ω–µ—ë¬ª), –Ω–∏ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Ñ–æ–ª–ª–æ—É-–∞–ø–∞ ¬´–æ–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ¬ª ‚Äî –≤—ã—Ö–æ–¥–∏–º
    if not (_ANAPH_HINT_RE.search(t) or _FOLLOWUP_MORE_RE.search(t)):
        return text

    last = LAST_REF.get(uid) or {}

    # 1) –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç ‚Äî –ø–æ—Å–ª–µ–¥–Ω—è—è —Ç–∞–±–ª–∏—Ü–∞
    tables = last.get("table_nums") or []
    if tables:
        num = str(tables[0])
        return f"{text} (–∏–º–µ–µ—Ç—Å—è –≤ –≤–∏–¥—É —Ç–∞–±–ª–∏—Ü–∞ {num})"

    # 2) –∑–∞—Ç–µ–º ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∏—Å—É–Ω–æ–∫
    figs = last.get("figure_nums") or []
    if figs:
        num = str(figs[0])
        return f"{text} (–∏–º–µ–µ—Ç—Å—è –≤ –≤–∏–¥—É —Ä–∏—Å—É–Ω–æ–∫ {num})"

    # 3) –∑–∞—Ç–µ–º ‚Äî –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—É–Ω–∫—Ç/—Ä–∞–∑–¥–µ–ª
    area = (last.get("area") or "").strip()
    if area:
        if not re.search(r"(?i)\b(–≥–ª–∞–≤–∞|—Ä–∞–∑–¥–µ–ª|–ø—É–Ω–∫—Ç|–ø–æ–¥—Ä–∞–∑–¥–µ–ª)\b", t):
            return f"{text} (–∏–º–µ–µ—Ç—Å—è –≤ –≤–∏–¥—É –ø—É–Ω–∫—Ç {area})"
        return f"{text} ({area})"

    return text


# ------------------------ –ì–∞—Ä–¥—Ä–µ–π–ª—ã ------------------------

_BANNED_PATTERNS = [
    r"jail ?break|system\s*prompt|developer\s*mode|dan\b|ignore (all|previous) (rules|instructions)",
    r"\b–≤–∑–ª–æ–º|—Ö–∞–∫–∏?|–∫–µ–π–≥–µ–Ω|–∫—Ä—è–∫|—Å–æ—Ü–∏–∞–ª—å–Ω(–∞—è|—ã–µ) –∏–Ω–∂–µ–Ω–µ—Ä–∏—è",
    r"\b–≤–∏—Ä—É—Å|–≤—Ä–µ–¥–æ–Ω–æ—Å|—ç–∫—Å–ø–ª–æ–π—Ç|–±–æ—Ç–Ω–µ—Ç|ddos\b",
    r"\b–æ—Ä—É–∂–∏|–≤–∑—Ä—ã–≤—á–∞—Ç|–±–æ–º–±|–Ω–∞—Ä–∫–æ—Ç|–ø–æ—Ä–Ω–æ|—ç—Ä–æ—Ç–∏–∫|18\+",
    r"\b–ø–∞—Å–ø–æ—Ä—Ç|—Å–Ω–∏–ª—Å|–∏–Ω–Ω\b.*(—Å–≥–µ–Ω–µ—Ä|–ø–æ–¥–¥–µ–ª)",
    r"\b–æ–±–æ–π(–¥|—Ç–∏)\b.*–∞–Ω—Ç–∏–ø–ª–∞–≥|–∞–Ω—Ç–∏–ø–ª–∞–≥–∏–∞—Ç|antiplagiat",
    r"sql.?–∏–Ω—ä–µ–∫|–∏–Ω—ä–µ–∫—Ü–∏(—è|–∏) sql",
]

def safety_check(text: str) -> str | None:
    t = (text or "").lower()
    for p in _BANNED_PATTERNS:
        if re.search(p, t, flags=re.IGNORECASE):
            return ("–ó–∞–ø—Ä–æ—Å –Ω–∞—Ä—É—à–∞–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ "
                    "(–≤–∑–ª–æ–º/–≤—Ä–µ–¥–æ–Ω–æ—Å/–æ–±—Ö–æ–¥ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π/NSFW/–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ).")
    return None

_ALLOWED_HINT_WORDS = [
    "–≤–∫—Ä", "–¥–∏–ø–ª–æ–º", "–∫—É—Ä—Å–æ–≤", "–º–µ—Ç–æ–¥–æ–ª–æ–≥", "–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä", "–ª–∏—Ç–æ–±–∑–æ—Ä",
    "–≥–∏–ø–æ—Ç–µ–∑", "—Ü–µ–ª—å", "–∑–∞–¥–∞—á", "–≤–≤–µ–¥–µ–Ω–∏–µ", "–∑–∞–∫–ª—é—á–µ–Ω", "–æ–±–∑–æ—Ä",
    "–æ—Ñ–æ—Ä–º–ª–µ–Ω", "–≥–æ—Å—Ç", "—Ç–∞–±–ª–∏—Ü", "—Ä–∏—Å—É–Ω–∫", "–∞–Ω—Ç–∏–ø–ª–∞–≥", "–ø–ª–∞–≥–∏–∞—Ç",
    "–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü", "–∑–∞—â–∏—Ç—É", "–æ–ø—Ä–æ—Å", "–∞–Ω–∫–µ—Ç–∞", "–º–µ—Ç–æ–¥—ã", "—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫",
]

def topical_check(text: str) -> str | None:
    """
    –ú—è–≥–∫–æ–µ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –¢–û–õ–¨–ö–û –∫–∞–∫ –ø–æ–¥—Å–∫–∞–∑–∫—É,
    –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
    """
    t = (text or "").lower()
    if not any(w in t for w in _ALLOWED_HINT_WORDS):
        return ("–ü–æ–¥—Å–∫–∞–∑–∫–∞: —Å–∏–ª—å–Ω–µ–µ –≤—Å–µ–≥–æ –æ—Ç–≤–µ—á–∞—é –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é –í–ö–† (–≥–ª–∞–≤—ã, —Ç–∞–±–ª–∏—Ü—ã, —Ä–∏—Å—É–Ω–∫–∏, –≤—ã–≤–æ–¥—ã). "
                "–ï—Å–ª–∏ –ø—Ä–∏—à–ª—ë—Ç–µ —Ñ–∞–π–ª –¥–∏–ø–ª–æ–º–∞ ‚Äî —Å–º–æ–≥—É –æ–±—ä—è—Å–Ω—è—Ç—å –ø—Ä—è–º–æ –ø–æ –≤–∞—à–µ–º—É —Ç–µ–∫—Å—Ç—É.")
    return None

# --------------------- –ë–î / —É—Ç–∏–ª–∏—Ç—ã ---------------------

def _table_has_columns(con, table: str, cols: list[str]) -> bool:
    cur = con.cursor()
    cur.execute(f"PRAGMA table_info({table})")
    have = {row[1] for row in cur.fetchall()}
    return all(c in have for c in cols)


def _current_embedding_profile() -> str:
    """
    –¢–µ–∫—É—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, –∫–æ—Ç–æ—Ä—ã–π –ø–∏—à–µ–º –≤ layout_profile.
    –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ñ–∏–≥–µ –Ω–∏—á–µ–≥–æ –Ω–µ –∑–∞–¥–∞–Ω–æ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º 'default'.
    """
    return getattr(Cfg, "EMBEDDING_PROFILE", "default")


# --------------------- –¢–∞–±–ª–∏—Ü—ã: –ø–∞—Ä—Å–∏–Ω–≥/–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è ---------------------

_TABLE_ANY = re.compile(r"\b—Ç–∞–±–ª–∏—Ü\w*|\b—Ç–∞–±–ª\.\b|\b—Ç–∞–±–ª–∏—Ü–∞\w*|(?:^|\s)table(s)?\b", re.IGNORECASE)
# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º: 2.1, 3, A.1, –ê.1, –ü1.2
_TABLE_TITLE_RE = re.compile(r"(?i)\b—Ç–∞–±–ª–∏—Ü–∞\s+(\d+(?:[.,]\d+)*|[a-z–∞-—è]\.?\s*\d+(?:[.,]\d+)*)\b(?:\s*[‚Äî\-‚Äì]\s*(.+))?")
_COUNT_HINT = re.compile(r"\b—Å–∫–æ–ª—å–∫–æ\b|how many", re.IGNORECASE)
_WHICH_HINT = re.compile(r"\b–∫–∞–∫–∏(–µ|—Ö)\b|\b—Å–ø–∏—Å–æ–∫\b|\b–ø–µ—Ä–µ—á–∏—Å–ª\w*\b|\b–Ω–∞–∑–æ–≤\w*\b", re.IGNORECASE)

# –ù–û–í–û–ï: –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º "—Ç–∞–±–ª–∏—Ü–∞ 6", "—Ç–∞–±–ª. 6", "table 6.1" –∏ —Ç.–ø.
_TABLE_NUM_IN_TEXT_RE = re.compile(
    r"(?i)\b(?:—Ç–∞–±–ª–∏—Ü[–∞-—è]*|—Ç–∞–±–ª\.?|table)\s*([A-Za-z–ê-–Ø–∞-—è]?\s*\d+(?:[.,]\d+)*)"
)


def _extract_table_nums(text: str) -> list[str]:
    """–î–æ—Å—Ç–∞—ë–º –≤—Å–µ –Ω–æ–º–µ—Ä–∞ —Ç–∞–±–ª–∏—Ü –∏–∑ —Ñ—Ä–∞–∑—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    nums: list[str] = []
    for m in _TABLE_NUM_IN_TEXT_RE.finditer(text or ""):
        raw = (m.group(1) or "").strip()
        #  " 4 , 1 " -> "4.1"
        norm = raw.replace(" ", "").replace(",", ".")
        if norm:
            nums.append(norm)
    return nums

def _is_pure_table_request(text: str) -> bool:
    """
    –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –∑–∞–ø—Ä–æ—Å –¢–û–õ–¨–ö–û –ø—Ä–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã
    (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–æ–ø–∏—à–∏ —Ç–∞–±–ª–∏—Ü—É 4", "—á—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–∞–±–ª–∏—Ü–∞ 2.3"),
    –±–µ–∑ —Ä–∏—Å—É–Ω–∫–æ–≤, —Ä–∞–∑–¥–µ–ª–æ–≤ –∏ –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.
    """
    t = (text or "").strip()
    if not t:
        return False

    # –Ω–µ—Ç —Å–ª–æ–≤–∞ "—Ç–∞–±–ª–∏—Ü–∞" ‚Äî —Ç–æ—á–Ω–æ –Ω–µ –Ω–∞—à —Å–ª—É—á–∞–π
    if not _TABLE_ANY.search(t):
        return False

    # –Ω–µ—Ç –Ω–æ–º–µ—Ä–∞ –ø–æ—Å–ª–µ "—Ç–∞–±–ª–∏—Ü—ã" ‚Äî —Ç–æ–∂–µ –Ω–µ —á–∏—Å—Ç—ã–π –∑–∞–ø—Ä–æ—Å
    if not _TABLE_NUM_IN_TEXT_RE.search(t):
        return False

    # –µ—Å–ª–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –ø—Ä–æ —Ä–∏—Å—É–Ω–∫–∏ –∏–ª–∏ —Ä–∞–∑–¥–µ–ª—ã ‚Äî —ç—Ç–æ —É–∂–µ —Å–º–µ—à–∞–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å
    if FIG_NUM_RE.search(t) or _SECTION_NUM_RE.search(t):
        return False

    return True

def _plural_tables(n: int) -> str:
    n_abs = abs(n) % 100
    n1 = n_abs % 10
    if 11 <= n_abs <= 14:
        return "—Ç–∞–±–ª–∏—Ü"
    if n1 == 1:
        return "—Ç–∞–±–ª–∏—Ü–∞"
    if 2 <= n1 <= 4:
        return "—Ç–∞–±–ª–∏—Ü—ã"
    return "—Ç–∞–±–ª–∏—Ü"

def _strip_table_prefix(s: str) -> str:
    return re.sub(r"^\[\s*—Ç–∞–±–ª–∏—Ü–∞\s*\]\s*", "", s or "", flags=re.IGNORECASE)

def _last_segment(name: str) -> str:
    s = (name or "").strip()
    if "/" in s:
        s = s.split("/")[-1].strip()
    s = _strip_table_prefix(s)
    s = re.sub(r"\s*[-‚Äì‚Äî]\s*", " ‚Äî ", s)
    s = re.sub(r"\s+", " ", s).strip(" .")
    return s

def _parse_table_title(text: str) -> tuple[str | None, str | None]:
    t = (text or "").strip()
    m = _TABLE_TITLE_RE.search(t)
    if not m:
        return (None, None)
    num = (m.group(1) or "").strip() or None
    title = (m.group(2) or "").strip() or None
    return (num, title)

def _table_num_variants(num: str) -> list[str]:
    """
    –î–µ–ª–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–∞–ø–∏—Å–∞–Ω–∏—è –Ω–æ–º–µ—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã:
    6.1 ‚Üî 6,1; —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã.
    –ù—É–∂–Ω—ã, —á—Ç–æ–±—ã –Ω–∞—Ö–æ–¥–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É –¥–∞–∂–µ –µ—Å–ª–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ —Ç–æ—á–∫–∞,
    –∞ –≤ —Ç–µ–∫—Å—Ç–µ –∑–∞–ø—è—Ç–∞—è (–∏–ª–∏ –Ω–∞–æ–±–æ—Ä–æ—Ç).
    """
    raw = (str(num) or "").strip()
    if not raw:
        return []
    base = raw.replace(" ", "")
    dot = base.replace(",", ".")
    comma = base.replace(".", ",")
    variants = {base, dot, comma}
    return [v for v in variants if v]


def _shorten(s: str, limit: int = 120) -> str:
    """
    –ê–∫–∫—É—Ä–∞—Ç–Ω–æ –æ–±—Ä–µ–∑–∞–µ–º —Å—Ç—Ä–æ–∫—É –¥–æ limit —Å–∏–º–≤–æ–ª–æ–≤ —Å —Ç—Ä–æ–µ—Ç–æ—á–∏–µ–º.
    –°—Ç–∞—Ä–∞–µ–º—Å—è —Ä–µ–∑–∞—Ç—å –ø–æ –≥—Ä–∞–Ω–∏—Ü–µ —Å–ª–æ–≤–∞.
    """
    s = (s or "").strip()
    if len(s) <= limit:
        return s

    # –ø—ã—Ç–∞–µ–º—Å—è —Ä–µ–∑–∞—Ç—å –ø–æ –ø—Ä–æ–±–µ–ª—É, —á—Ç–æ–±—ã –Ω–µ —Ä—É–±–∏—Ç—å —Å–ª–æ–≤–æ –ø–æ–ø–æ–ª–∞–º
    cut = s.rfind(" ", 0, limit)
    # –µ—Å–ª–∏ –ø—Ä–æ–±–µ–ª —Å–ª–∏—à–∫–æ–º —Ä–∞–Ω–æ (–∏–ª–∏ –≤–æ–æ–±—â–µ –Ω–µ –Ω–∞–π–¥–µ–Ω) ‚Äî —Ä–µ–∂–µ–º —Ä–æ–≤–Ω–æ –ø–æ –ª–∏–º–∏—Ç—É
    if cut < max(10, limit // 2):
        cut = limit

    return s[:cut].rstrip(" .,;:‚Äì-") + "‚Ä¶"




# -------- –¢–∞–±–ª–∏—Ü—ã: –ø–æ–¥—Å—á—ë—Ç –∏ —Å–ø–∏—Å–æ–∫ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å–æ —Å—Ç–∞—Ä—ã–º–∏ –ë–î) --------

def _distinct_table_basenames(uid: int, doc_id: int) -> list[str]:
    """
    –°–æ–±–∏—Ä–∞–µ–º ¬´–±–∞–∑–æ–≤—ã–µ¬ª –∏–º–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü (section_path –±–µ–∑ —Ö–≤–æ—Å—Ç–∞ ' [row ‚Ä¶]').
    –†–∞–±–æ—Ç–∞–µ—Ç –∏ —Å –Ω–æ–≤—ã–º–∏ –∏–Ω–¥–µ–∫—Å–∞–º–∏ (table_row) –∏ —Å–æ —Å—Ç–∞—Ä—ã–º–∏.

    –ù–û–í–û–ï:
    - –µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ attrs –∏ –ø–∞—Ä—Å–µ—Ä –ø—Ä–æ—Å—Ç–∞–≤–∏–ª is_table=true,
      —Å—á–∏—Ç–∞–µ–º ¬´–∂–∏–≤—ã–º–∏¬ª —Ç–æ–ª—å–∫–æ —Ç–∞–∫–∏–µ —Ç–∞–±–ª–∏—Ü—ã;
    - —Å—Ç–∞—Ä—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –±–µ–∑ attrs / –±–µ–∑ is_table –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç —É—á–∏—Ç—ã–≤–∞—Ç—å—Å—è –∫–∞–∫ —Ä–∞–Ω—å—à–µ.
    """
    con = get_conn()
    cur = con.cursor()

    has_et    = _table_has_columns(con, "chunks", ["element_type"])
    has_attrs = _table_has_columns(con, "chunks", ["attrs"])

    # —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –æ–ø–µ—Ä–µ—Ç—å—Å—è –Ω–∞ —Ç–∏–ø—ã
    if has_et:
        if has_attrs:
            # —Ç–æ–ª—å–∫–æ "–Ω–∞—Å—Ç–æ—è—â–∏–µ" DOCX-—Ç–∞–±–ª–∏—Ü—ã (–∏–ª–∏ —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –±–µ–∑ attrs)
            cur.execute(
                """
                SELECT DISTINCT
                    CASE
                        WHEN instr(section_path, ' [row ')>0
                            THEN substr(section_path, 1, instr(section_path,' [row ')-1)
                        ELSE section_path
                    END AS base_name
                FROM chunks
                WHERE doc_id=? AND owner_id=?
                  AND element_type IN ('table','table_row')
                  AND (attrs IS NULL OR attrs LIKE '%"is_table": true%')
                """,
                (doc_id, uid),
            )
        else:
            # –æ—á–µ–Ω—å —Å—Ç–∞—Ä—ã–π –∏–Ω–¥–µ–∫—Å –±–µ–∑ attrs ‚Äî –ø–æ–≤–µ–¥–µ–Ω–∏–µ –∫–∞–∫ —Ä–∞–Ω—å—à–µ
            cur.execute(
                """
                SELECT DISTINCT
                    CASE
                        WHEN instr(section_path, ' [row ')>0
                            THEN substr(section_path, 1, instr(section_path,' [row ')-1)
                        ELSE section_path
                    END AS base_name
                FROM chunks
                WHERE doc_id=? AND owner_id=? AND element_type IN ('table','table_row')
                """,
                (doc_id, uid),
            )
    else:
        # –æ—á–µ–Ω—å —Å—Ç–∞—Ä—ã–π –∏–Ω–¥–µ–∫—Å ‚Äî —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–µ–∫—Å—Ç—É/section_path
        cur.execute(
            """
            SELECT DISTINCT
                CASE
                    WHEN instr(section_path, ' [row ')>0
                        THEN substr(section_path, 1, instr(section_path,' [row ')-1)
                    ELSE section_path
                END AS base_name
            FROM chunks
            WHERE doc_id=? AND owner_id=? AND (
                  lower(section_path) LIKE '%—Ç–∞–±–ª–∏—Ü–∞%'
               OR lower(text)        LIKE '%—Ç–∞–±–ª–∏—Ü–∞%'
               OR section_path LIKE '–¢–∞–±–ª–∏—Ü–∞ %' COLLATE NOCASE
               OR text        LIKE '[–¢–∞–±–ª–∏—Ü–∞]%' COLLATE NOCASE
               OR lower(section_path) LIKE '%table %'
               OR lower(text)        LIKE '%table %'
            )
            """,
            (doc_id, uid),
        )

    base_items = [r["base_name"] for r in cur.fetchall() if r["base_name"]]
    con.close()
    base_items = sorted(set(base_items), key=lambda s: s.lower())
    return base_items

def _count_tables(uid: int, doc_id: int) -> int:
    return len(_distinct_table_basenames(uid, doc_id))

def _compose_display_from_attrs(attrs_json: str | None, base: str, first_row_text: str | None) -> str:
    """
    –ü—Ä–∞–≤–∏–ª–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è:
      1) –µ—Å—Ç—å caption_num ‚Üí '–¢–∞–±–ª–∏—Ü–∞ N ‚Äî tail/header/firstrow' (–≤—Å–µ–≥–¥–∞ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º, –µ—Å–ª–∏ –µ—Å—Ç—å).
      2) –Ω–µ—Ç –Ω–æ–º–µ—Ä–∞ ‚Üí –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –æ–ø–∏—Å–∞–Ω–∏–µ: caption_tail/ header_preview/ first_row.
      3) —Ñ–æ–ª–±—ç–∫: –ø–∞—Ä—Å–∏–º –Ω–æ–º–µ—Ä –∏ —Ö–≤–æ—Å—Ç –∏–∑ base ('–¢–∞–±–ª–∏—Ü–∞ N ‚Äî ...') –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å –Ω–æ–º–µ—Ä–æ–º.
      4) –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã—à–ª–æ ‚Äî –±–µ—Ä—ë–º –∫–æ—Ä–æ—Ç–∫–∏–π base –±–µ–∑ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Å–ª–æ–≤.
    """
    num = None
    tail = None
    header_preview = None
    if attrs_json:
        try:
            a = json.loads(attrs_json or "{}")
            num = a.get("caption_num") or a.get("label")
            tail = a.get("caption_tail") or a.get("title")
            header_preview = a.get("header_preview")
        except Exception:
            pass

    if num:
        num = str(num).replace(",", ".").strip()
        tail_like = (tail or header_preview or first_row_text or "").strip()
        return f"–¢–∞–±–ª–∏—Ü–∞ {num}" + (f" ‚Äî {_shorten(tail_like, 160)}" if tail_like else "")

    # –±–µ–∑ –Ω–æ–º–µ—Ä–∞ –≤ attrs ‚Äî –ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∏–∑ base –∏ –ø–æ–∫–∞–∑–∞—Ç—å –° –Ω–æ–º–µ—Ä–æ–º
    num_b, title_b = _parse_table_title(_last_segment(base))
    if num_b:
        text_tail = title_b or first_row_text or header_preview
        return f"–¢–∞–±–ª–∏—Ü–∞ {num_b}" + (f" ‚Äî {_shorten(text_tail, 160)}" if text_tail else "")

    # –±–µ–∑ –Ω–æ–º–µ—Ä–∞ ‚Äî —Ç–æ–ª—å–∫–æ –æ–ø–∏—Å–∞–Ω–∏–µ
    if tail:
        return _shorten(str(tail), 160)
    if header_preview:
        return _shorten(str(header_preview), 160)
    if first_row_text:
        return _shorten(first_row_text, 160)

    s = _last_segment(base)
    s = re.sub(r"(?i)^\s*—Ç–∞–±–ª–∏—Ü–∞\s+\d+(?:\.\d+)*\s*", "", s).strip(" ‚Äî‚Äì-")
    return _shorten(s or "–¢–∞–±–ª–∏—Ü–∞", 160)


# ------------------------------ –ò—Å—Ç–æ—á–Ω–∏–∫–∏ ------------------------------

_SOURCES_HINT = re.compile(
    r"\b(–∏—Å—Ç–æ—á–Ω–∏–∫(?:–∏|–æ–≤)?|—Å–ø–∏—Å–æ–∫\s+–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã|—Å–ø–∏—Å–æ–∫\s+–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤|–±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ\w*|references?|bibliograph\w*)\b",
    re.IGNORECASE
)
_REF_LINE_RE = re.compile(r"^\s*(?:\[\d+\]|\d+[.)])\s+.+", re.MULTILINE)

def _count_sources(uid: int, doc_id: int) -> int:
    """
    –ü–æ–¥—Å—á—ë—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
      1) –µ—Å–ª–∏ –≤ –ë–î –µ—Å—Ç—å element_type='reference' ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ;
      2) –∏–Ω–∞—á–µ —Å–æ–±–∏—Ä–∞–µ–º –ª—é–±—ã–µ –Ω–µ–ø—É—Å—Ç—ã–µ –∞–±–∑–∞—Ü—ã –≤–Ω—É—Ç—Ä–∏ —Å–µ–∫—Ü–∏–π ¬´–∏—Å—Ç–æ—á–Ω–∏–∫–∏/–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞/‚Ä¶¬ª
         (–±–µ–∑ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, —á—Ç–æ–±—ã —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–ª–∞—Å—å —Å –Ω–æ–º–µ—Ä–∞).
    """
    con = get_conn()
    cur = con.cursor()
    has_type = _table_has_columns(con, "chunks", ["element_type"])

    total = 0
    if has_type:
        cur.execute(
            "SELECT COUNT(*) AS c FROM chunks WHERE owner_id=? AND doc_id=? AND element_type='reference'",
            (uid, doc_id),
        )
        row = cur.fetchone()
        total = int(row["c"] or 0)

    if total == 0:
        items = set()
        cur.execute(
            """
            SELECT element_type, section_path, text
            FROM chunks
            WHERE owner_id=? AND doc_id=?
            ORDER BY page ASC, id ASC
            """,
            (uid, doc_id),
        )
        raw_rows = cur.fetchall()
        for r in raw_rows:
            sec = (r["section_path"] or "").lower()
            if not any(k in sec for k in ("–∏—Å—Ç–æ—á–Ω–∏–∫", "–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä", "–±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ", "reference", "bibliograph")):
                continue
            et = (r["element_type"] or "").lower()
            if et in ("heading", "table", "figure", "table_row"):
                continue
            t = (r["text"] or "").strip()
            if not t:
                continue
            k = re.sub(r"\s+", " ", t).strip().rstrip(".").lower()
            if len(k) >= 5:
                items.add(k)
        total = len(items)

    con.close()
    return total


# --------- –±—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç: –Ω–∞–ª–∏—á–∏–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —á–∞—Å—Ç–∏ ---------
_PRACTICAL_Q = re.compile(r"(–µ—Å—Ç—å –ª–∏|–Ω–∞–ª–∏—á–∏–µ|–ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ª–∏|–∏–º–µ–µ—Ç—Å—è –ª–∏).{0,40}–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫", re.IGNORECASE)

def _has_practical_part(uid: int, doc_id: int) -> bool:
    con = get_conn()
    cur = con.cursor()
    cur.execute(
        """
        SELECT 1
        FROM chunks
        WHERE owner_id=? AND doc_id=? AND (
            lower(section_path) LIKE '%–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫%' OR
            lower(text)         LIKE '%–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫%'
        )
        LIMIT 1
        """,
        (uid, doc_id),
    )
    row = cur.fetchone()
    con.close()
    return row is not None


# ------------- –ì–û–°–¢-–∏–Ω—Ç–µ–Ω—Ç –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ -------------

_GOST_HINT = re.compile(r"\b(–≥–æ—Å—Ç|–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏|—à—Ä–∏—Ñ—Ç|–º–µ–∂—Å—Ç—Ä–æ—á|–∫–µ–≥–ª|–≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏|–ø–æ–ª—è|–æ—Ñ–æ—Ä–º–∏—Ç—å)\w*\b", re.IGNORECASE)

async def _maybe_run_gost(m: types.Message, uid: int, doc_id: int, text: str) -> bool:
    """–ï—Å–ª–∏ –ø–æ—Ö–æ–∂–µ, —á—Ç–æ –ø—Ä–æ—Å—è—Ç –ø—Ä–æ–≤–µ—Ä–∫—É –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è ‚Äî –∑–∞–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –ì–û–°–¢. –í–æ–∑–≤—Ä–∞—â–∞–µ–º True, –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç–∏–ª–∏."""
    if not validate_gost or not render_report:
        return False
    if not _GOST_HINT.search(text or ""):
        return False

    con = get_conn()
    cur = con.cursor()
    cur.execute("SELECT path FROM documents WHERE id=? AND owner_id=?", (doc_id, uid))
    row = cur.fetchone()
    con.close()
    if not row:
        return False

    path = row["path"]
    try:
        sections = _parse_by_ext(path)
    except Exception:
        return False

    report = validate_gost(sections)
    text_rep = render_report(report, max_issues=25)
    await _send(m, text_rep)
    return True

def _cap(s: str, limit: int = 950) -> str:
    """–û–±—Ä–µ–∑–∞–µ–º caption –¥–ª—è media (—É TG –ª–∏–º–∏—Ç ~1024 —Å–∏–º–≤–æ–ª–∞)."""
    s = (s or "").strip()
    if len(s) <= limit:
        return s
    return s[:limit - 1].rstrip() + "‚Ä¶"

def _safe_fs_input(path: str) -> FSInputFile | None:
    try:
        p = os.path.abspath(path or "")
        if not os.path.isfile(p):
            return None
        return FSInputFile(p)
    except Exception:
        return None

def _media_groups_from_cards(cards: list[dict], *, per_group: int = 10, per_figure: int = 4) -> list[list[InputMediaPhoto]]:
    """
    –°–æ–±–∏—Ä–∞–µ–º InputMediaPhoto –∏–∑ –∫–∞—Ä—Ç–æ—á–µ–∫ describe_figures_by_numbers.
    –ù–µ –±–æ–ª—å—à–µ FIG_MEDIA_LIMIT –≤—Å–µ–≥–æ, per_group ‚Äî –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ Telegram (10).
    """
    media: list[InputMediaPhoto] = []
    total = 0
    for c in cards or []:
        disp = c.get("display") or f"–†–∏—Å—É–Ω–æ–∫ {c.get('num') or ''}".strip()
        imgs = (c.get("images") or [])[:per_figure]
        if not imgs:
            continue
        cap = _cap(disp)
        first = True
        for img in imgs:
            if total >= FIG_MEDIA_LIMIT:
                break
            fh = _safe_fs_input(img)
            if not fh:
                continue
            # caption —Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ –Ω–∞ –ø–µ—Ä–≤–æ–µ —Ñ–æ—Ç–æ —Ä–∏—Å—É–Ω–∫–∞ (TG best-practice)
            media.append(InputMediaPhoto(media=fh, caption=cap if first else None))
            total += 1
            first = False
        if total >= FIG_MEDIA_LIMIT:
            break

    # —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ 10 —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ –≥—Ä—É–ø–ø—É
    groups: list[list[InputMediaPhoto]] = []
    for i in range(0, len(media), per_group):
        groups.append(media[i:i + per_group])
    return groups

async def _send_media_from_cards(m: types.Message, cards: list[dict]) -> bool:
    """
    –ü—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –º–µ–¥–∏–∞–≥—Ä—É–ø–ø—ã –ø–æ –∫–∞—Ä—Ç–æ—á–∫–∞–º. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –æ—Ç–ø—Ä–∞–≤–∏–ª–∏.
    """
    groups = _media_groups_from_cards(cards)
    sent_any = False
    for g in groups:
        if not g:
            continue
        try:
            await m.answer_media_group(g)
            sent_any = True
        except TelegramBadRequest:
            # –µ—Å–ª–∏ –º–µ–¥–∏–∞-–≥—Ä—É–ø–ø–∞ –Ω–µ –∑–∞—à–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–¥–Ω–æ —Ñ–æ—Ç–æ) ‚Äî –æ—Ç–ø—Ä–∞–≤–∏–º –ø–æ—à—Ç—É—á–Ω–æ
            for item in g:
                try:
                    await m.answer_photo(item.media, caption=item.caption)
                    sent_any = True
                except Exception:
                    pass
        except Exception:
            pass
    return sent_any

# ------------------------------ helpers ------------------------------

def _parse_by_ext(path: str) -> list[dict]:
    fname = (os.path.basename(path) or "").lower()
    if fname.endswith(".docx"):
        return parse_docx(path)
    if fname.endswith(".doc"):
        return parse_doc(path)
    raise RuntimeError("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é —Ç–æ–ª—å–∫–æ .doc –∏ .docx.")

def _first_chunks_context(owner_id: int, doc_id: int, n: int = 10, max_chars: int = 6000) -> str:
    con = get_conn()
    cur = con.cursor()
    cur.execute(
        "SELECT page, section_path, text FROM chunks "
        "WHERE owner_id=? AND doc_id=? "
        "ORDER BY page ASC, id ASC LIMIT ?",
        (owner_id, doc_id, n)
    )
    rows = cur.fetchall()
    con.close()
    if not rows:
        return ""
    parts, total = [], 0
    for r in rows:
        block = f"{(r['text'] or '').strip()}"
        if total + len(block) > max_chars:
            break
        parts.append(block)
        total += len(block)
    return "\n\n".join(parts)


def _ooxml_get_index(doc_id: int) -> dict | None:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç OOXML-–∏–Ω–¥–µ–∫—Å –∏–∑ –ø–∞–º—è—Ç–∏ –∏–ª–∏ —Å –¥–∏—Å–∫–∞. –°–Ω–∞—á–∞–ª–∞ runtime/indexes/<doc_id>.json,
    –∑–∞—Ç–µ–º —Ñ–æ–ª–±—ç–∫ ‚Äî –∏—â–µ–º json —Å —Å–æ–≤–ø–∞–¥–∞—é—â–∏–º meta.file (–ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É)."""
    idx = OOXML_INDEX.get(doc_id)
    if idx:
        return idx

    p = os.path.join("runtime", "indexes", f"{doc_id}.json")
    if os.path.isfile(p):
        try:
            with open(p, "r", encoding="utf-8") as f:
                idx = json.load(f)
            OOXML_INDEX[doc_id] = idx
            return idx
        except Exception:
            pass

    # —Ñ–æ–ª–±—ç–∫: –ø–æ–¥–æ–±—Ä–∞—Ç—å –∏–Ω–¥–µ–∫—Å –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –ø—É—Ç–∏ —Ñ–∞–π–ª–∞
    try:
        con = get_conn()
        cur = con.cursor()
        cur.execute("SELECT path FROM documents WHERE id=?", (doc_id,))
        row = cur.fetchone()
        con.close()
        doc_path = os.path.abspath(row["path"]) if row else None
        if doc_path:
            idx_dir = os.path.join("runtime", "indexes")
            if os.path.isdir(idx_dir):
                for name in os.listdir(idx_dir):
                    if not name.endswith(".json"):
                        continue
                    try:
                        with open(os.path.join(idx_dir, name), "r", encoding="utf-8") as f:
                            cand = json.load(f)
                        if (cand.get("meta") or {}).get("file") == doc_path:
                            OOXML_INDEX[doc_id] = cand
                            return cand
                    except Exception:
                        continue
    except Exception:
        pass
    return None


# –ù–µ–±–æ–ª—å—à–æ–π —Ö–µ–ª–ø–µ—Ä: –ø–æ–Ω—è—Ç—å, —á—Ç–æ –ø–æ–¥–ø–∏—Å—å –±–æ–ª—å—à–µ –ø–æ—Ö–æ–∂–∞ –Ω–∞ ¬´—Ç–∞–±–ª–∏—Ü—É¬ª, –∞ –Ω–µ –Ω–∞ –æ–±—ã—á–Ω—ã–π —Ä–∏—Å—É–Ω–æ–∫
_TABLE_CAPTION_HINT_RE = re.compile(
    r"(?i)\b—Ç–∞–±–ª–∏—Ü\w*|\b—Ç–∞–±–ª\.\b|\b—Ç–∞–±–ª–∏—Ü–∞\w*|(?:^|\s)table(s)?\b"
)

def _looks_like_table_caption(rec: dict) -> bool:
    """
    –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –∑–∞–ø–∏—Å—å –ø–æ—Ö–æ–∂–∞ –Ω–∞ —Ç–∞–±–ª–∏—Ü—É, –µ—Å–ª–∏:
      ‚Äî —è–≤–Ω–æ —É–∫–∞–∑–∞–Ω—ã —Ç–∏–ø/–≤–∏–¥ 'table/—Ç–∞–±–ª–∏—Ü–∞' –ò–õ–ò
      ‚Äî –≤ caption/title/name –µ—Å—Ç—å —Å–ª–æ–≤–æ ¬´—Ç–∞–±–ª–∏—Ü–∞¬ª/¬´table¬ª.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–±–æ—Ä–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –≤ _ooxml_find_table_image.
    """
    if not isinstance(rec, dict):
        return False

    kind = str(rec.get("kind") or rec.get("type") or "").lower()
    if "table" in kind or "—Ç–∞–±–ª–∏—Ü" in kind:
        return True

    cap = (rec.get("caption") or rec.get("title") or rec.get("name") or "").strip()
    if not cap:
        return False

    return bool(_TABLE_CAPTION_HINT_RE.search(cap))


def _ooxml_find_figure_by_label(idx: dict, num_str: str) -> dict | None:
    """
    –ò—â–µ–º –∑–∞–ø–∏—Å—å –æ —Ä–∏—Å—É–Ω–∫–µ –ø–æ –Ω–æ–º–µ—Ä—É –≤–∏–¥–∞ '2.3' –∏–∑ –ø–æ–¥–ø–∏—Å–∏.
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏–º–µ–Ω–Ω–æ —Ç–µ–∫—Å—Ç –≤ caption/title, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ —Ü–µ–ª—É—é —á–∞—Å—Ç—å.
    """
    target = _num_norm_fig(num_str)
    if not target:
        return None
    figs = (idx or {}).get("figures") or []
    for f in figs:
        cap = (f.get("caption") or f.get("title") or "").strip()
        m = _FIG_TITLE_RE.search(cap)
        if not m:
            continue
        cap_num = _num_norm_fig(m.group(2))
        if cap_num == target:
            return f
    return None


# NEW: –ø–æ–∏—Å–∫ ¬´—Ç–∞–±–ª–∏—Ü—ã-–∫–∞—Ä—Ç–∏–Ω–∫–∏¬ª –ø–æ –ø–æ–¥–ø–∏—Å–∏ "–¢–∞–±–ª–∏—Ü–∞ N ..."
# NEW: –ø–æ–∏—Å–∫ ¬´—Ç–∞–±–ª–∏—Ü—ã-–∫–∞—Ä—Ç–∏–Ω–∫–∏¬ª –ø–æ –ø–æ–¥–ø–∏—Å–∏ "–¢–∞–±–ª–∏—Ü–∞ N ..."
def _ooxml_find_table_image(idx: dict, num: str) -> dict | None:
    """
    –ò—â–µ–º –∑–∞–ø–∏—Å—å, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —Ç–∞–±–ª–∏—Ü–µ {num}, –∫–æ—Ç–æ—Ä–∞—è –≤—Å—Ç–∞–≤–ª–µ–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–æ–π.
    –°–º–æ—Ç—Ä–∏–º –∏ –≤ figures, –∏ –≤ tables (–µ—Å–ª–∏ —Ç–∞–º –µ—Å—Ç—å image_path).

    –í–ê–ñ–ù–û:
      ‚Äî –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ tables –±–µ—Ä—ë–º –≤—Å—ë;
      ‚Äî –∏–∑ figures –±–µ—Ä—ë–º –¢–û–õ–¨–ö–û –∑–∞–ø–∏—Å–∏, –ø–æ–¥–ø–∏—Å—å –∫–æ—Ç–æ—Ä—ã—Ö –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ —Ç–∞–±–ª–∏—Ü–∞
        (_looks_like_table_caption), —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–ø—É—Ç–∞—Ç—å —Å ¬´–†–∏—Å—É–Ω–æ–∫ 6¬ª.

    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
      1) —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ —á–∏—Å–ª–æ–≤—ã–º –ø–æ–ª—è–º (caption_num/label/num/n)
         –¢–û–õ–¨–ö–û —Å—Ä–µ–¥–∏ ¬´—Ç–∞–±–ª–∏—á–Ω—ã—Ö¬ª –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤;
      2) —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –ø–æ–¥–ø–∏—Å–∏ '–¢–∞–±–ª–∏—Ü–∞ {num} ...'.
    """
    if not idx:
        return None

    target = str(num).replace(" ", "").replace(",", ".")

    def _iter_candidates():
        """
        –î–∞—ë–º (kind, rec):
          kind == 'tables'  ‚Üí –≤—Å–µ–≥–¥–∞ —Å—á–∏—Ç–∞–µ–º —Ç–∞–±–ª–∏—Ü–µ–π;
          kind == 'figures' ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–æ–¥–ø–∏—Å—å –ø–æ—Ö–æ–∂–∞ –Ω–∞ —Ç–∞–±–ª–∏—Ü—É.
        """
        for kind in ("figures", "tables"):
            coll = (idx.get(kind) or [])
            if isinstance(coll, dict):
                coll = list(coll.values())
            if not isinstance(coll, list):
                continue
            for rec in coll:
                if not isinstance(rec, dict):
                    continue
                # –≤—Å—ë –∏–∑ tables –±–µ—Ä—ë–º –±–µ–∑ —É—Å–ª–æ–≤–∏–π,
                # –∞ –∏–∑ figures ‚Äî —Ç–æ–ª—å–∫–æ ¬´—Ç–∞–±–ª–∏—á–Ω—ã–µ¬ª –ø–æ–¥–ø–∏—Å–∏
                if kind == "figures" and not _looks_like_table_caption(rec):
                    continue
                yield kind, rec

    # 1) –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–æ —á–∏—Å–ª–æ–≤—ã–º –ø–æ–ª—è–º (caption_num/label/num/n)
    for _kind, rec in _iter_candidates():
        for fld in ("caption_num", "label", "num", "n"):
            raw = rec.get(fld)
            if not raw:
                continue
            cand = str(raw).replace(" ", "").replace(",", ".")
            if cand == target:
                return rec

    # 2) –§–æ–ª–±—ç–∫ ‚Äî –ø–æ —Ç–µ–∫—Å—Ç—É –ø–æ–¥–ø–∏—Å–∏
    for _kind, rec in _iter_candidates():
        cap = (rec.get("caption") or rec.get("title") or rec.get("name") or "").strip()
        if not cap:
            continue
        # "–¢–∞–±–ª–∏—Ü–∞ 6", "—Ç–∞–±–ª–∏—Ü–∞ 6 ‚Äì ...", "–¢–∞–±–ª–∏—Ü–∞ 6. ..."
        m = re.search(r"(?i)\b—Ç–∞–±–ª–∏—Ü\w*\s+(\d+(?:[.,]\d+)*)", cap)
        if not m:
            continue
        cap_num = (m.group(1) or "").replace(" ", "").replace(",", ".")
        if cap_num == target:
            return rec

    return None


# NEW: OCR-—Ñ–æ–ª–±—ç–∫ –¥–ª—è —Ç–∞–±–ª–∏—Ü, –≤—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –∫–∞—Ä—Ç–∏–Ω–∫–æ–π
def _ocr_table_block_from_image(uid: int, doc_id: int, num: str) -> str | None:
    key = (doc_id, str(num))
    cached = _OCR_TABLE_CACHE.get(key)
    if cached is not None:
        logging.info("TAB[img] cache hit for doc=%s, table=%s", doc_id, num)
        return cached

    # 1) —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º OOXML-–∏–Ω–¥–µ–∫—Å
    idx = _ooxml_get_index(doc_id)
    if not idx:
        logging.info("TAB[img] no OOXML index for doc=%s", doc_id)
    rec = _ooxml_find_table_image(idx, num) if idx else None

    img_path: str | None = None
    if rec:
        # 1) —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ–ª—è
        img_path = rec.get("image_path") or rec.get("image")

        # 2) –∏–Ω–æ–≥–¥–∞ ooxml_lite –∫–ª–∞–¥—ë—Ç —Å–ø–∏—Å–æ–∫ –∫–∞—Ä—Ç–∏–Ω–æ–∫
        if not img_path:
            imgs = rec.get("images") or rec.get("imgs") or []
            if isinstance(imgs, (list, tuple)) and imgs:
                img_path = imgs[0]

        logging.info(
            "TAB[img] OOXML candidate for table %s: image_path=%r",
            num,
            img_path,
        )


    # 2) –µ—Å–ª–∏ –∏–∑ OOXML –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å ‚Äî –ø—Ä–æ–±—É–µ–º –¥–æ—Å—Ç–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É —á–µ—Ä–µ–∑ retrieve(...)
    if not img_path:
        try:
            logging.info("TAB[img] fallback retrieve() for table %s", num)
            hits = retrieve(uid, doc_id, f"–¢–∞–±–ª–∏—Ü–∞ {num}", top_k=6)
        except Exception as e:
            logging.exception("TAB[img] retrieve() failed for table %s: %s", num, e)
            hits = []

        if hits:
            paths = _pick_images_from_hits(hits, limit=1)
            logging.info("TAB[img] retrieve() returned image paths=%r", paths)
            if paths:
                img_path = paths[0]

    if not img_path or not os.path.isfile(img_path):
        logging.info(
            "TAB[img] no image found on disk for table %s (img_path=%r)",
            num,
            img_path,
        )
        return None

    # –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∞—Ä –∑–Ω–∞—á–µ–Ω–∏–π
    all_pairs: list[dict] = []
    # –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∫—É—Å–∫–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–≤ —Ç.—á. ¬´–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ¬ª)
    extra_text_parts: list[str] = []

    def _add_pairs(pairs: list[dict] | None) -> None:
        """–ê–∫–∫—É—Ä–∞—Ç–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä—ã –±–µ–∑ –≥—Ä—É–±—ã—Ö –¥—É–±–ª–µ–π –ø–æ (label, value, unit)."""
        nonlocal all_pairs
        if not pairs:
            return
        seen = {(str(p.get("label") or "").strip(),
                 str(p.get("value") or "").strip(),
                 str(p.get("unit") or "").strip())
                for p in all_pairs}
        for p in pairs:
            key_p = (
                str(p.get("label") or "").strip(),
                str(p.get("value") or "").strip(),
                str(p.get("unit") or "").strip(),
            )
            if key_p in seen:
                continue
            seen.add(key_p)
            all_pairs.append(p)

    # 3.a) —Å–ø–µ—Ü-—Ñ—É–Ω–∫—Ü–∏—è –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º-–∫–∞—Ä—Ç–∏–Ω–∫–∞–º
    if vision_extract_table_values is not None:
        try:
            pairs1 = vision_extract_table_values(img_path, lang="ru") or []
            _add_pairs(pairs1)
        except Exception as e:
            logging.exception(
                "ocr_table_block_from_image: vision_extract_table_values failed for %s (table %s): %s",
                img_path,
                num,
                e,
            )

    # 3.b) –æ–±—â–∏–π vision-–∞–Ω–∞–ª–∏–∑: –∏ –ø–∞—Ä—ã, –∏ —Ç–µ–∫—Å—Ç (—á–∞—Å—Ç–æ —Å–æ–¥–µ—Ä–∂–∏—Ç ¬´–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ¬ª)
    if va_analyze_figure is not None:
        try:
            try:
                res = va_analyze_figure(
                    img_path,
                    caption_hint=f"–¢–∞–±–ª–∏—Ü–∞ {num}",
                    lang="ru",
                )
            except TypeError:
                res = va_analyze_figure(img_path, lang="ru")  # type: ignore

            if isinstance(res, dict):
                pairs2 = res.get("data") or []
                _add_pairs(pairs2)
                txt2 = (res.get("text") or "").strip()
                if txt2:
                    extra_text_parts.append(txt2)
            else:
                txt2 = (str(res) or "").strip()
                if txt2:
                    extra_text_parts.append(txt2)
        except Exception as e:
            logging.exception(
                "ocr_table_block_from_image: va_analyze_figure failed for %s (table %s): %s",
                img_path,
                num,
                e,
            )

    # 3.c) –æ–±—â–∏–π extractor –ø–∞—Ä label/value
    if vision_extract_values is not None:
        try:
            pairs3 = vision_extract_values(img_path, lang="ru") or []
            _add_pairs(pairs3)
        except Exception as e:
            logging.exception(
                "ocr_table_block_from_image: vision_extract_values failed for %s (table %s): %s",
                img_path,
                num,
                e,
            )



    values_block = _pairs_to_bullets(all_pairs) if all_pairs else ""
    values_block = (values_block or "").strip()
    extra_text = "\n".join(
        t.strip() for t in extra_text_parts if t and t.strip()
    )

    if not values_block and not extra_text:
        return None

    lines: list[str] = [f"–¢–∞–±–ª–∏—Ü–∞ {num} (—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é):"]
    if values_block:
        lines.append(values_block)
    if extra_text:
        lines.append("")  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        lines.append("[–¢–µ–∫—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è]")
        lines.append(extra_text)

    out = "\n".join(lines).strip()
    _OCR_TABLE_CACHE[key] = out
    return out


# ---------- verbatim fallback –ø–æ —Ü–∏—Ç–∞—Ç–µ (—à–∏–Ω–≥–ª—ã + LIKE/NOCASE) ----------

def _normalize_for_like(s: str) -> str:
    s = (s or "")
    s = s.replace("\u00A0", " ")  # NBSP -> –ø—Ä–æ–±–µ–ª
    s = s.replace("¬´", '"').replace("¬ª", '"').replace("‚Äú", '"').replace("‚Äù", '"')
    s = s.replace("‚Äô", "'").replace("‚Äò", "'")
    s = re.sub(r"\s+", " ", s).strip()
    return s

def _make_shingles(s: str, min_len: int = 30, max_len: int = 90, step: int = 25) -> list[str]:
    s = _normalize_for_like(s)
    if not s:
        return []
    if len(s) <= max_len:
        return [s]
    out = []
    i = 0
    while i < len(s):
        chunk = s[i:i + max_len]
        if len(chunk) >= min_len:
            out.append(chunk)
        i += step
    return out[:6]

def verbatim_find(owner_id: int, doc_id: int, q_text: str, max_hits: int = 3) -> list[dict]:
    shingles = _make_shingles(q_text)
    if not shingles:
        return []
    con = get_conn()
    cur = con.cursor()
    hits: list[dict] = []
    for sh in shingles:
        pattern = f"%{sh}%"
        cur.execute(
            """
            SELECT page, section_path, text FROM chunks
            WHERE owner_id=? AND doc_id=? AND
                  replace(text, char(160), ' ') LIKE ? COLLATE NOCASE
            ORDER BY page ASC, id ASC
            LIMIT ?
            """,
            (owner_id, doc_id, pattern, max_hits - len(hits)),
        )
        for r in cur.fetchall():
            t = (r["text"] or "")
            t_norm = _normalize_for_like(t)
            pos = t_norm.lower().find(_normalize_for_like(sh).lower())
            if pos >= 0:
                s = max(pos - 120, 0)
                e = min(pos + len(sh) + 120, len(t_norm))
                hits.append({
                    "page": r["page"],
                    "section_path": r["section_path"],
                    "snippet": t_norm[s:e].strip(),
                })
            if len(hits) >= max_hits:
                con.close()
                return hits
    con.close()
    return hits


# ------------------------------ /start ------------------------------

@dp.message(Command("start"))
async def start(m: types.Message):
    ensure_user(str(m.from_user.id))
    await _send(m,
        "–ü—Ä–∏–≤–µ—Ç! –Ø —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ —Ç–≤–æ–µ–π –í–ö–†. –ü—Ä–∏—à–ª–∏ —Ñ–∞–π–ª –í–ö–† ‚Äî —è –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä—É—é –∏ –±—É–¥—É –æ–±—ä—è—Å–Ω—è—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: –≥–ª–∞–≤—ã –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º, —Å–º—ã—Å–ª —Ç–∞–±–ª–∏—Ü/—Ä–∏—Å—É–Ω–∫–æ–≤, –∫–æ–Ω—Å–ø–µ–∫—Ç—ã –∫ –∑–∞—â–∏—Ç–µ. –ú–æ–∂–µ—à—å –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å –≤–æ–ø—Ä–æ—Å –∫ —Ñ–∞–π–ª—É –∏–ª–∏ –Ω–∞–ø–∏—Å–∞—Ç—å –µ–≥–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º."
    )


# ------------------------------ /diag ------------------------------

@dp.message(Command("diag"))
async def cmd_diag(m: types.Message):
    uid = ensure_user(str(m.from_user.id))
    doc_id = ACTIVE_DOC.get(uid) or get_user_active_doc(uid)
    if not doc_id:
        await _send(m, "–ê–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–µ—Ç. –ü—Ä–∏—à–ª–∏—Ç–µ —Ñ–∞–π–ª –í–ö–† —Å–Ω–∞—á–∞–ª–∞.")
        return

    # –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –ë–î
    con = get_conn()
    cur = con.cursor()
    cur.execute("SELECT path FROM documents WHERE id=? AND owner_id=?", (doc_id, uid))
    row = cur.fetchone()
    path = row["path"] if row else "‚Äî"

    cur.execute("SELECT COUNT(*) AS c FROM chunks WHERE owner_id=? AND doc_id=?", (uid, doc_id))
    chunks_cnt = int(cur.fetchone()["c"])

    con.close()

    tables_cnt = _count_tables(uid, doc_id)
    figures_cnt = _list_figures_db(uid, doc_id, limit=999999)["count"]
    # NEW: –µ—Å–ª–∏ –≤ –ë–î 0 ‚Äî –≤–æ–∑—å–º—ë–º —á–∏—Å–ª–æ —Ä–∏—Å—É–Ω–∫–æ–≤ –∏–∑ OOXML-–∏–Ω–¥–µ–∫—Å–∞
    if figures_cnt == 0:
        idx_oox = _ooxml_get_index(doc_id)
        if idx_oox:
            figures_cnt = len(idx_oox.get("figures", []))
    sources_cnt = _count_sources(uid, doc_id)

    indexer_ver = get_document_indexer_version(doc_id) or 0

    txt = (
        f"–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ #{doc_id}\n"
        f"‚Äî –ü—É—Ç—å: {path}\n"
        f"‚Äî –ß–∞–Ω–∫–æ–≤: {chunks_cnt}\n"
        f"‚Äî –¢–∞–±–ª–∏—Ü: {tables_cnt}\n"
        f"‚Äî –†–∏—Å—É–Ω–∫–æ–≤: {figures_cnt}\n"
        f"‚Äî –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {sources_cnt}\n"
        f"‚Äî –í–µ—Ä—Å–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞: {indexer_ver} (—Ç–µ–∫—É—â–∞—è {CURRENT_INDEXER_VERSION})\n"
    )
    await _send(m, txt)


# ------------------------------ /reindex ------------------------------

@dp.message(Command("reindex"))
async def cmd_reindex(m: types.Message):
    uid = ensure_user(str(m.from_user.id))
    doc_id = ACTIVE_DOC.get(uid) or get_user_active_doc(uid)
    if not doc_id:
        await _send(m, "–ê–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–µ—Ç. –ü—Ä–∏—à–ª–∏—Ç–µ —Ñ–∞–π–ª —Å–Ω–∞—á–∞–ª–∞.")
        return

    con = get_conn()
    cur = con.cursor()
    cur.execute("SELECT path FROM documents WHERE id=? AND owner_id=?", (doc_id, uid))
    row = cur.fetchone()
    con.close()

    if not row:
        await _send(m, "–ù–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç –∑–∞–Ω–æ–≤–æ.")
        return

    path = row["path"]
    try:
        sections = _parse_by_ext(path)
        # –æ–±–æ–≥–∞—â–∞–µ–º —Å–µ–∫—Ü–∏–∏ –ø–µ—Ä–µ–¥ –∏–Ω–¥–µ–∫—Å–æ–º
        sections = enrich_sections(sections, doc_kind=os.path.splitext(path)[1].lower().strip("."))
        delete_document_chunks(doc_id, uid)
        index_document(uid, doc_id, sections)
        invalidate_cache(uid, doc_id)
        set_document_indexer_version(doc_id, CURRENT_INDEXER_VERSION)
        update_document_meta(doc_id, layout_profile=_current_embedding_profile())
        await _send(m, f"–î–æ–∫—É–º–µ–Ω—Ç #{doc_id} –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω.")
    except Exception as e:
        logging.exception("reindex failed: %s", e)
        await _send(m, f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç: {e}")



# ---------- –†–∏—Å—É–Ω–∫–∏: –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (–ª–æ–∫–∞–ª—å–Ω—ã–µ, –±–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –æ—Ç retrieval.py) ----------

_FIG_TITLE_RE = re.compile(
    r"(?i)\b(—Ä–∏—Å(?:\.|—É–Ω–æ–∫)?|—Å—Ö–µ–º(?:–∞|—ã)?|–∫–∞—Ä—Ç–∏–Ω(?:–∫–∞|–∫–∏)?|figure|fig\.?|picture|pic\.?)"
    r"\s*(?:‚Ññ\s*)?(\d+(?:[.,]\d+)*)\b(?:\s*[‚Äî\-‚Äì:\u2013\u2014]\s*(.+))?"
)

# –í–∫–ª—é—á–∞—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Å –∫–∞—Ä—Ç–∏–Ω–æ–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
FIG_VALUES_DEFAULT: bool = getattr(Cfg, "FIG_VALUES_DEFAULT", True)

def _compose_figure_display(attrs_json: str | None, section_path: str, title_text: str | None) -> str:
    """–î–µ–ª–∞–µ–º –∫—Ä–∞—Å–∏–≤—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ä–∏—Å—É–Ω–∫–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º."""
    num = None
    tail = None
    if attrs_json:
        try:
            a = json.loads(attrs_json or "{}")
            num  = str(a.get("caption_num") or a.get("label") or "").strip()
            tail = str(a.get("caption_tail") or a.get("title") or "").strip()
        except Exception:
            pass

    if not num or not num.strip():
        cand = title_text or section_path or ""
        m = _FIG_TITLE_RE.search(cand)
        if m:
            num = (m.group(2) or "").replace(",", ".").strip()
            if not tail:
                tail = (m.group(3) or "").strip()

    if num:
        return f"–†–∏—Å—É–Ω–æ–∫ {num}" + (f" ‚Äî {_shorten(tail, 160)}" if tail else "")
    base = title_text or _last_segment(section_path or "")
    base = re.sub(
    r"(?i)^\s*(—Ä–∏—Å(?:\.|—É–Ω–æ–∫)?|—Å—Ö–µ–º(?:–∞|—ã)?|–∫–∞—Ä—Ç–∏–Ω(?:–∫–∞|–∫–∏)?|figure|fig\.?|picture|pic\.?)\s*",
        "", base
    ).strip(" ‚Äî‚Äì-")
    return _shorten(base or "–†–∏—Å—É–Ω–æ–∫", 160)

# ---------- NEW: —Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ DOCX-–≥—Ä–∞—Ñ–∏–∫–æ–≤ (chart_data) ----------

def _fetch_figure_row_by_num(uid: int, doc_id: int, num: str):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É chunks –¥–ª—è —Ä–∏—Å—É–Ω–∫–∞ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º –Ω–æ–º–µ—Ä–æ–º (–µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–∞),
    –æ—Ä–∏–µ–Ω—Ç–∏—Ä—É—è—Å—å –Ω–∞ caption_num –≤ attrs.
    –î–æ–±–∞–≤–ª–µ–Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–º–µ—Ä–∞ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤.
    """
    con = get_conn()
    cur = con.cursor()

    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–æ–º–µ—Ä –≤–∏–¥–∞ "2. 2." -> "2.2"
    n = (
        (num or "")
        .strip()
        .replace(" ", "")
        .replace(" ", "")  # –∏–Ω–æ–≥–¥–∞ –±—ã–≤–∞—é—Ç —É–∑–∫–∏–µ –ø—Ä–æ–±–µ–ª—ã
        .rstrip(".,")      # —É–±–∏—Ä–∞–µ–º —Ç–æ—á–∫—É/–∑–∞–ø—è—Ç—É—é –≤ –∫–æ–Ω—Ü–µ
    )

    row = None

    # 1) –ø–æ caption_num –≤–Ω—É—Ç—Ä–∏ attrs (–Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∑–∞–ø–∏—Å–∏)
    like_variants = [
        f'%\\"caption_num\\": \\"{n}\\"%',
        f'%\\"caption_num\\": \\"{n}.\\"%',
        f'%\\"caption_num\\": \\"–†–∏—Å.{n}\\"%',
        f'%\\"caption_num\\": \\"–†–∏—Å. {n}\\"%',
        f'%\\"caption_num\\": \\"–†–∏—Å—É–Ω–æ–∫ {n}\\"%',
    ]

    for like_val in like_variants:
        try:
            cur.execute(
                """
                SELECT id, page, section_path, attrs, text
                FROM chunks
                WHERE owner_id=? AND doc_id=? AND element_type='figure'
                  AND attrs LIKE ? ESCAPE '\\'
                ORDER BY id ASC LIMIT 1
                """,
                (uid, doc_id, like_val),
            )
            row = cur.fetchone()
            if row:
                break
        except Exception:
            pass

    # 2) fallback ‚Äî –∏—â–µ–º –≤ section_path (–ø–æ–¥–ø–∏—Å–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –¥—Ä—É–≥–∏–µ)
    if not row:
        section_like_variants = [
            f'%–†–∏—Å—É–Ω–æ–∫ {num}%',
            f'%–†–∏—Å. {num}%',
            f'%–†–∏—Å.{num}%',
            f'%{n}%',  # –ø—Ä–æ—Å—Ç–æ –Ω–æ–º–µ—Ä
        ]
        for pat in section_like_variants:
            try:
                cur.execute(
                    """
                    SELECT id, page, section_path, attrs, text
                    FROM chunks
                    WHERE owner_id=? AND doc_id=? AND element_type='figure'
                      AND section_path LIKE ? COLLATE NOCASE
                    ORDER BY id ASC LIMIT 1
                    """,
                    (uid, doc_id, pat),
                )
                row = cur.fetchone()
                if row:
                    break
            except Exception:
                pass

    con.close()
    return row

def _figure_fallback_from_caption(
    uid: int,
    doc_id: int,
    num: str,
    max_paragraphs: int = 3,
    max_chars: int = 1500,
) -> dict | None:
    """
    –§–æ–ª–±—ç–∫ –¥–ª—è ¬´–Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö¬ª —Ä–∏—Å—É–Ω–∫–æ–≤ (SmartArt, –≤—Ä–µ–∑–∫–∏ –∏ —Ç.–ø.),
    –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –ø–æ–ø–∞–ª–∏ –≤ element_type='figure' –∏ –Ω–µ –∏–º–µ—é—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ
    figure-chunk'–∞ –≤ –ë–î.

    –ò—â–µ–º –ø–æ —Ç–µ–∫—Å—Ç—É –ø–æ–¥–ø–∏—Å–∏ –≤–∏–¥–∞:
      - "–†–∏—Å—É–Ω–æ–∫ 1.2 ..."
      - "–†–∏—Å. 1.2 ..."
      - "–†–∏—Å.1.2 ..."
    –∏, –µ—Å–ª–∏ –Ω–∞—à–ª–∏, –∑–∞–±–∏—Ä–∞–µ–º:
      - caption: —Å–∞–º —Ç–µ–∫—Å—Ç —Å—Ç—Ä–æ–∫–∏;
      - near_text: 1‚Äì3 —Å–ª–µ–¥—É—é—â–∏—Ö –∞–±–∑–∞—Ü–∞ –≤ —Ç–æ–º –∂–µ section_path.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict:
      {
        "caption": str | None,
        "near_text": list[str],
        "section_path": str | None,
      }
    –∏–ª–∏ None, –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.
    """
    num_norm = _num_norm_fig(num)
    if not num_norm:
        return None

    con = get_conn()
    cur = con.cursor()

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –∏—â–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –Ω–∞ –ø–æ–¥–ø–∏—Å—å.
    like_variants = [
        f"%–†–∏—Å—É–Ω–æ–∫ {num_norm}%",
        f"%–†–∏—Å. {num_norm}%",
        f"%–†–∏—Å.{num_norm}%",
        f"%—Ä–∏—Å—É–Ω–æ–∫ {num_norm}%",
        f"%—Ä–∏—Å. {num_norm}%",
        f"%—Ä–∏—Å.{num_norm}%",
    ]

    row = None

    # 1) –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –ø–æ text LIKE "–†–∏—Å—É–Ω–æ–∫ 1.2 ..."
    for pat in like_variants:
        try:
            cur.execute(
                """
                SELECT id, page, section_path, text
                FROM chunks
                WHERE owner_id=? AND doc_id=? AND text LIKE ? COLLATE NOCASE
                ORDER BY id ASC
                LIMIT 20
                """,
                (uid, doc_id, pat),
            )
            candidates = cur.fetchall() or []
        except Exception:
            candidates = []

        for r in candidates:
            t = (r["text"] or "").strip()
            if not t:
                continue
            m = re.search(
                r"(?:–†–∏—Å\.?|–†–∏—Å—É–Ω–æ–∫)\s+(\d+(?:\.\d+)*)",
                t,
                flags=re.IGNORECASE,
            )
            if not m:
                continue
            found_num = _num_norm_fig(m.group(1))
            if found_num == num_norm:
                row = r
                break

        if row:
            break

    # 2) –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ text, –ø—Ä–æ–±—É–µ–º –∏—Å–∫–∞—Ç—å –ø–æ section_path –∏ –ø—Ä–æ—Å—Ç–æ –ø–æ —á–∏—Å–ª—É "1.2"
    if not row:
        try:
            cur.execute(
                """
                SELECT id, page, section_path, text
                FROM chunks
                WHERE owner_id=? AND doc_id=? AND (
                    section_path LIKE ? COLLATE NOCASE
                    OR text LIKE ? COLLATE NOCASE
                )
                ORDER BY id ASC
                LIMIT 30
                """,
                (uid, doc_id, f"%{num_norm}%", f"%{num_norm}%"),
            )
            candidates = cur.fetchall() or []
        except Exception:
            candidates = []

        for r in candidates:
            line = ((r["text"] or "") + " " + (r["section_path"] or "")).strip()
            if not line:
                continue
            # –∏—â–µ–º "–†–∏—Å—É–Ω–æ–∫/–†–∏—Å. <–Ω–æ–º–µ—Ä>" —É–∂–µ –≤ —Å—É–º–º–∞—Ä–Ω–æ–π —Å—Ç—Ä–æ–∫–µ
            m = re.search(
                r"(?:–†–∏—Å\.?|–†–∏—Å—É–Ω–æ–∫)\s+(\d+(?:\.\d+)*)",
                line,
                flags=re.IGNORECASE,
            )
            if not m:
                continue
            found_num = _num_norm_fig(m.group(1))
            if found_num == num_norm:
                row = r
                break

    con.close()

    if not row:
        return None


    caption = ((row["text"] or "")).strip()
    section_path = row["section_path"] or ""

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ö–µ–ª–ø–µ—Ä, –∫–∞–∫ –±—É–¥—Ç–æ —ç—Ç–æ figure-–æ–±—ä–µ–∫—Ç:
    fake_fig_row = {
        "id": row["id"],
        "section_path": section_path,
    }

    near_text = _figure_following_paragraphs(
        uid,
        doc_id,
        fake_fig_row,
        max_paragraphs=max_paragraphs,
        max_chars=max_chars,
    ) or []

    return {
        "caption": caption if caption else None,
        "near_text": near_text,
        "section_path": section_path or None,
    }

def _figure_fallback_context_from_caption(
    uid: int,
    doc_id: int,
    num: str,
    max_paragraphs: int = 3,
    max_chars: int = 1500,
) -> tuple[str | None, list[str]]:
    """
    –§–æ–ª–±—ç–∫ –¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ –ù–ï–¢ figure-—á–∞–Ω–∫–∞ (SmartArt, "–≤–∏—Å—è—á–∞—è" –ø–æ–¥–ø–∏—Å—å –∏ —Ç.–ø.).

    –ò—â–µ–º –≤ chunks —Å—Ç—Ä–æ–∫—É —Å —Ç–µ–∫—Å—Ç–æ–º "–†–∏—Å—É–Ω–æ–∫ N" / "–†–∏—Å. N",
    —Å—á–∏—Ç–∞–µ–º –µ—ë –ø–æ–¥–ø–∏—Å—å—é –∏ –±–µ—Ä—ë–º 1‚Äì3 —Å–ª–µ–¥—É—é—â–∏—Ö –∞–±–∑–∞—Ü–∞ –≤ —ç—Ç–æ–º –∂–µ section_path
    –∫–∞–∫ —Ç–µ–∫—Å—Ç —Ä—è–¥–æ–º —Å —Ä–∏—Å—É–Ω–∫–æ–º.
    """
    num = (num or "").strip()
    if not num:
        return None, []

    # –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –Ω–æ–º–µ—Ä –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤ –∏ —Ö–≤–æ—Å—Ç–æ–≤—ã—Ö —Ç–æ—á–µ–∫
    n = (
        num.replace(" ", "")
           .rstrip(".,")
    )

    con = get_conn()
    cur = con.cursor()

    row = None
    patterns = [
        f"%–†–∏—Å—É–Ω–æ–∫ {num}%",
        f"%–†–∏—Å. {num}%",
        f"%–†–∏—Å.{num}%",
        f"%–†–∏—Å—É–Ω–æ–∫ {n}%",
        f"%–†–∏—Å. {n}%",
        f"%–†–∏—Å.{n}%",
    ]

    try:
        for pat in patterns:
            cur.execute(
                """
                SELECT id, page, section_path, text
                FROM chunks
                WHERE owner_id=? AND doc_id=? AND text LIKE ? COLLATE NOCASE
                ORDER BY id ASC
                LIMIT 1
                """,
                (uid, doc_id, pat),
            )
            row = cur.fetchone()
            if row:
                break
    except Exception:
        row = None
    finally:
        try:
            con.close()
        except Exception:
            pass

    if not row:
        return None, []

    raw_caption = (row["text"] or "").strip()

    # –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–µ–ª–ø–µ—Ä –¥–ª—è –ø–æ–¥—á–∏—Å—Ç–∫–∏ –ø–æ–¥–ø–∏—Å–∏ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
    try:
        caption = _clean_caption_for_figure(raw_caption, num)
        caption = (caption or "").strip()
    except Exception:
        caption = raw_caption

    # –ë–µ—Ä—ë–º –∞–±–∑–∞—Ü—ã –ü–û–°–õ–ï –ø–æ–¥–ø–∏—Å–∏ ‚Äî —Ç–µ–º –∂–µ –º–µ—Ö–∞–Ω–∏–∑–º–æ–º, —á—Ç–æ –∏ –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö figure-—á–∞–Ω–∫–æ–≤
    try:
        near = _figure_following_paragraphs(
            uid,
            doc_id,
            row,
            max_paragraphs=max_paragraphs,
            max_chars=max_chars,
        )
    except Exception:
        near = []

    return (caption or None), near

def _figure_fallback_from_caption_text(
    uid: int,
    doc_id: int,
    num: str,
    max_paragraphs: int = 3,
    max_chars: int = 1500,
) -> tuple[str | None, list[str]]:
    """
    –§–æ–ª–±—ç–∫ –¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ –Ω–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ figure-chunk'–∞ (SmartArt, –∫—Ä–∏–≤–æ–π DOCX –∏ —Ç.–ø.).

    –ò—â–µ–º –≤ chunks –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∞–±–∑–∞—Ü —Å –ø–æ–¥–ø–∏—Å—å—é –≤–∏–¥–∞
    ¬´–†–∏—Å. 1.2 ...¬ª / ¬´–†–∏—Å—É–Ω–æ–∫ 1.2 ...¬ª –∏ –±–µ—Ä—ë–º –µ–≥–æ –∫–∞–∫ caption,
    –∞ –∑–∞—Ç–µ–º 2‚Äì3 —Å–ª–µ–¥—É—é—â–∏—Ö –∞–±–∑–∞—Ü–∞ –≤ —Ç–æ–º –∂–µ section_path ‚Äî –∫–∞–∫ near_text.
    """
    num = (num or "").strip()
    if not num:
        return None, []

    # –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –Ω–æ–º–µ—Ä, —á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å "1.2." –∏ —Ç.–ø.
    n = num.replace(" ", "").rstrip(".,")

    con = get_conn()
    cur = con.cursor()

    # –ò—â–µ–º –ø–æ–¥–ø–∏—Å—å –≤ —Ç–µ–∫—Å—Ç–µ. element_type != 'figure', –ø–æ—Ç–æ–º—É —á—Ç–æ SmartArt
    # —á–∞—Å—Ç–æ –Ω–µ —Ä–∞–∑–º–µ—á–∞–µ—Ç—Å—è –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π figure-chunk.
    caption_row = None
    patterns = [
        f"–†–∏—Å. {n}%",       # –†–∏—Å. 1.2 ...
        f"–†–∏—Å.{n}%",        # –†–∏—Å.1.2 ...
        f"–†–∏—Å—É–Ω–æ–∫ {n}%",    # –†–∏—Å—É–Ω–æ–∫ 1.2 ...
        f"–†–∏—Å—É–Ω–æ–∫ {n}.%",   # –†–∏—Å—É–Ω–æ–∫ 1.2. ...
    ]

    for pat in patterns:
        try:
            cur.execute(
                """
                SELECT id, page, section_path, element_type, text
                FROM chunks
                WHERE owner_id=? AND doc_id=?
                  AND (element_type IS NULL OR element_type NOT IN ('figure','table','heading','table_row'))
                  AND text LIKE ? ESCAPE '\\'
                ORDER BY id ASC
                LIMIT 1
                """,
                (uid, doc_id, pat),
            )
            row = cur.fetchone()
            if row:
                caption_row = row
                break
        except Exception:
            continue

    if not caption_row:
        con.close()
        return None, []

    caption_text = (caption_row["text"] or "").strip()
    sec = caption_row["section_path"] or ""
    base_id = caption_row["id"]

    # –¢–µ–ø–µ—Ä—å –±–µ—Ä—ë–º 2‚Äì3 –∞–±–∑–∞—Ü–∞ –ü–û–°–õ–ï –ø–æ–¥–ø–∏—Å–∏ –≤ —Ç–æ–º –∂–µ section_path,
    # –ø–æ–∫–∞ –Ω–µ –≤—Å—Ç—Ä–µ—Ç–∏–º —Å–ª–µ–¥—É—é—â–∏–π heading/table/figure/table_row.
    has_et = _table_has_columns(con, "chunks", ["element_type"])

    if has_et:
        cur.execute(
            """
            SELECT text, element_type
            FROM chunks
            WHERE owner_id=? AND doc_id=? AND id>? AND section_path=?
            ORDER BY id ASC
            LIMIT 20
            """,
            (uid, doc_id, base_id, sec),
        )
    else:
        cur.execute(
            """
            SELECT text, NULL AS element_type
            FROM chunks
            WHERE owner_id=? AND doc_id=? AND id>? AND section_path=?
            ORDER BY id ASC
            LIMIT 20
            """,
            (uid, doc_id, base_id, sec),
        )

    rows = cur.fetchall() or []
    con.close()

    paras: list[str] = []
    total = 0

    for r in rows:
        et = (r["element_type"] or "").lower() if "element_type" in r.keys() else ""
        if et in ("heading", "table", "figure", "table_row"):
            break
        t = (r["text"] or "").strip()
        if not t:
            continue
        paras.append(t)
        total += len(t)
        if len(paras) >= max_paragraphs or total >= max_chars:
            break

    return caption_text, paras


def _figure_following_paragraphs(
    uid: int,
    doc_id: int,
    fig_row,
    max_paragraphs: int = 3,
    max_chars: int = 1500,
) -> list[str]:
    """
    –ë–µ—Ä—ë–º 1‚Äì2 –∞–±–∑–∞—Ü–∞ —Ç–µ–∫—Å—Ç–∞ –î–û —Ä–∏—Å—É–Ω–∫–∞ –∏ 2‚Äì3 –∞–±–∑–∞—Ü–∞ –ü–û–°–õ–ï —Ä–∏—Å—É–Ω–∫–∞
    –≤ —Ç–æ–º –∂–µ section_path. –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è, –∫–∞–∫ —Ç–æ–ª—å–∫–æ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏
    —Å–ª–µ–¥—É—é—â–∏–π heading/table/figure.
    """
    if not fig_row:
        return []

    base_id = fig_row["id"]
    sec = fig_row["section_path"] or ""

    con = get_conn()
    cur = con.cursor()

    has_et = _table_has_columns(con, "chunks", ["element_type"])

    # --- –∞–±–∑–∞—Ü—ã –ü–ï–†–ï–î —Ä–∏—Å—É–Ω–∫–æ–º ---
    if has_et:
        cur.execute(
            """
            SELECT text, element_type
            FROM chunks
            WHERE owner_id=? AND doc_id=? AND id<? AND section_path=?
            ORDER BY id DESC
            LIMIT 5
            """,
            (uid, doc_id, base_id, sec),
        )
    else:
        cur.execute(
            """
            SELECT text, NULL AS element_type
            FROM chunks
            WHERE owner_id=? AND doc_id=? AND id<? AND section_path=?
            ORDER BY id DESC
            LIMIT 5
            """,
            (uid, doc_id, base_id, sec),
        )
    before_rows = list(reversed(cur.fetchall() or []))

    # --- –∞–±–∑–∞—Ü—ã –ü–û–°–õ–ï —Ä–∏—Å—É–Ω–∫–∞ ---
    if has_et:
        cur.execute(
            """
            SELECT text, element_type
            FROM chunks
            WHERE owner_id=? AND doc_id=? AND id>? AND section_path=?
            ORDER BY id ASC
            LIMIT 20
            """,
            (uid, doc_id, base_id, sec),
        )
    else:
        cur.execute(
            """
            SELECT text, NULL AS element_type
            FROM chunks
            WHERE owner_id=? AND doc_id=? AND id>? AND section_path=?
            ORDER BY id ASC
            LIMIT 20
            """,
            (uid, doc_id, base_id, sec),
        )
    after_rows = cur.fetchall() or []
    con.close()

    paras: list[str] = []
    total = 0

    # —Å–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–ª—è–µ–º 1‚Äì2 –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã—Ö –∞–±–∑–∞—Ü–∞ –¥–æ —Ä–∏—Å—É–Ω–∫–∞
    for r in before_rows:
        et = (r["element_type"] or "").lower() if "element_type" in r.keys() else ""
        if et in ("heading", "table", "figure", "table_row"):
            continue
        t = (r["text"] or "").strip()
        if not t:
            continue
        paras.append(t)
        total += len(t)
        if len(paras) >= 2 or total >= max_chars:
            break

    # –∑–∞—Ç–µ–º –¥–æ–±–∞–≤–ª—è–µ–º 2‚Äì3 –∞–±–∑–∞—Ü–∞ –ø–æ—Å–ª–µ —Ä–∏—Å—É–Ω–∫–∞
    for r in after_rows:
        et = (r["element_type"] or "").lower() if "element_type" in r.keys() else ""
        if et in ("heading", "table", "figure", "table_row"):
            break
        t = (r["text"] or "").strip()
        if not t:
            continue
        paras.append(t)
        total += len(t)
        if len(paras) >= max_paragraphs or total >= max_chars:
            break

    return paras


def _parse_chart_data(attrs_json: str | None) -> tuple[list | None, str | None, dict]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∞ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å—Ö–µ–º attrs.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (data_rows, chart_type, attrs_dict), –≥–¥–µ data_rows ‚Äî —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
    –≤–∏–¥–∞ {"label": ..., "value": ..., "unit": ...}.
    """
    try:
        a = json.loads(attrs_json or "{}")

        # —Å–∞–º—ã–µ —á–∞—Å—Ç—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        raw = (a.get("chart_data")
            or (a.get("chart") or {}).get("data")
            or a.get("data")
            or a.get("series"))
        ctype = (a.get("chart_type")
                or (a.get("chart") or {}).get("type")
                or a.get("type"))


        # –£–∂–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ [{label, value, unit?}]
        if isinstance(raw, list) and raw:
            return raw, ctype, a

        # –†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω–∞—è —Ñ–æ—Ä–º–∞: {"categories":[...], "series":[{"name":..., "values":[...], "unit":"%"}]}
        if isinstance(raw, dict) and raw.get("categories") and raw.get("series"):
            cats = list(raw.get("categories") or [])
            s0   = (raw.get("series") or [{}])[0] or {}
            vals = list(s0.get("values") or s0.get("data") or [])
            unit = s0.get("unit")
            rows = []
            for i in range(min(len(cats), len(vals))):
                rows.append({
                    "label": str(cats[i]),
                    "value": vals[i],
                    "unit": unit
                })
            if rows:
                return rows, (ctype or s0.get("type") or "chart"), a
    except Exception:
        pass
    return None, None, {}

def _extract_raw_values_from_attrs(attrs_json: str | None) -> dict | None:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–∏–∞–≥—Ä–∞–º–º—ã –ò–ó OOXML-–∞—Ç—Ä–∏–±—É—Ç–æ–≤.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict –≤–∏–¥–∞:
    {
      "categories": [...],
      "series": [
        {"name": "–ù–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å", "unit": "%", "values": [65, 60, ...]},
        ...
      ]
    }
    –∏–ª–∏ None, –µ—Å–ª–∏ —Ç–∞–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –Ω–µ—Ç.

    –í–ê–ñ–ù–û:
    - –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –∏–∑ –Ω–æ–≤–æ–≥–æ ooxml_lite (chart.cats + chart.series);
    - –µ—Å–ª–∏ chart_data ‚Äî —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ [{label, value, unit, series_name}],
      —Å–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–µ —Å–µ—Ä–∏–∏, –∞ –Ω–µ —Å—Ö–ª–æ–ø—ã–≤–∞–µ–º –≤—Å—ë –≤ –æ–¥–Ω—É.
    """
    if not attrs_json:
        return None
    try:
        a = json.loads(attrs_json or "{}")
    except Exception:
        return None

    # 1) –¢–∏–ø–∏—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç OOXML-–∏–Ω–¥–µ–∫—Å–∞: {"chart_data": {"categories": [...], "series": [...]}},
    #    –ª–∏–±–æ {"chart": {...}}, –ª–∏–±–æ {"data": {...}}.
    for key in ("chart_data", "chart", "data"):
        raw = a.get(key)
        if isinstance(raw, dict) and raw.get("categories") and raw.get("series"):
            cats = list(raw.get("categories") or [])
            series_out: list[dict] = []
            for s in (raw.get("series") or []):
                if not isinstance(s, dict):
                    continue
                name = s.get("name")
                unit = s.get("unit")
                vals = list(s.get("values") or s.get("data") or [])
                series_out.append({
                    "name": name,
                    "unit": unit,
                    "values": vals,
                })
            if cats and series_out:
                return {"categories": cats, "series": series_out}

    # 1–∞) –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–∑ ooxml_lite: "chart": {"cats": [...], "series": [...]}
    chart = a.get("chart")
    if isinstance(chart, dict) and chart.get("series"):
        cats = chart.get("cats") or chart.get("categories") or []
        cats = [str(c) for c in cats]
        series_out: list[dict] = []
        for s in (chart.get("series") or []):
            if not isinstance(s, dict):
                continue
            name = s.get("name")
            unit = s.get("unit")
            # –≤ ooxml_lite –º—ã —É–∂–µ –∫–ª–∞–¥—ë–º —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ s["values"]
            vals = list(s.get("values") or s.get("data") or s.get("vals") or [])
            series_out.append({
                "name": name,
                "unit": unit,
                "values": vals,
            })
        if cats and series_out:
            return {"categories": cats, "series": series_out}

    # 2) chart_data –∫–∞–∫ –°–ü–ò–°–û–ö —Å—Ç—Ä–æ–∫ [{label, value, unit, series_name, ...}]
    raw_rows = a.get("chart_data")
    if isinstance(raw_rows, list) and raw_rows:
        # 2.1. –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ label'—ã –≤ –ø–æ—Ä—è–¥–∫–µ –ø–µ—Ä–≤–æ–≥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è
        categories: list[str] = []
        cat_index: dict[str, int] = {}
        for r in raw_rows:
            label = str(
                r.get("label")
                or r.get("name")
                or r.get("category")
                or ""
            ).strip()
            if label not in cat_index:
                cat_index[label] = len(categories)
                categories.append(label)

        if not categories:
            return None

        # 2.2. –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ series_name (–µ—Å–ª–∏ –µ—Å—Ç—å), –∏–Ω–∞—á–µ –≤—Å—ë –≤ –æ–¥–Ω—É —Å–µ—Ä–∏—é None
        series_map: dict[str | None, dict] = {}
        any_named_series = False

        for r in raw_rows:
            # –∏–º—è —Å–µ—Ä–∏–∏
            raw_sname = (
                r.get("series_name")
                or r.get("series")
                or r.get("name")
            )
            sname = str(raw_sname).strip() if raw_sname is not None else None
            if sname:
                any_named_series = True
                key = sname
            else:
                key = None  # –±–µ–∑—ã–º—è–Ω–Ω–∞—è —Å–µ—Ä–∏—è

            # –∫–∞—Ç–µ–≥–æ—Ä–∏—è ‚Üí –∏–Ω–¥–µ–∫—Å
            label = str(
                r.get("label")
                or r.get("name")
                or r.get("category")
                or ""
            ).strip()
            idx = cat_index.get(label)
            if idx is None:
                continue

            # –∑–Ω–∞—á–µ–Ω–∏–µ –∏ unit
            v = r.get("value")
            if v is None:
                v = r.get("y") or r.get("x") or r.get("v") or r.get("count")

            unit = r.get("unit")
            unit_str = str(unit).strip() if isinstance(unit, str) else None

            if key not in series_map:
                series_map[key] = {
                    "name": key,
                    "unit": unit_str,
                    "values": [None] * len(categories),
                }

            # –µ—Å–ª–∏ –≤ —Å–µ—Ä–∏–∏ unit –µ—â—ë –Ω–µ –ø—Ä–æ—Å—Ç–∞–≤–ª–µ–Ω, –∞ —Ç—É—Ç –µ—Å—Ç—å ‚Äî –∑–∞–ø–æ–º–∏–Ω–∞–µ–º
            if unit_str and not series_map[key].get("unit"):
                series_map[key]["unit"] = unit_str

            series_map[key]["values"][idx] = v

        series_out = list(series_map.values())

        # –µ—Å–ª–∏ –∏–º—ë–Ω —Å–µ—Ä–∏–π –Ω–µ—Ç –≤–æ–æ–±—â–µ ‚Äî –≤—Å—ë —Ä–∞–≤–Ω–æ –≤–µ—Ä–Ω—ë–º –æ–¥–Ω—É —Å–µ—Ä–∏—é,
        # —á—Ç–æ–±—ã _format_exact_values –º–æ–≥ –µ—ë –∫—Ä–∞—Å–∏–≤–æ –æ—Ñ–æ—Ä–º–∏—Ç—å
        if not series_out and raw_rows:
            vals: list = []
            unit: str | None = None
            for r in raw_rows:
                vv = r.get("value")
                if vv is None:
                    vv = r.get("y") or r.get("x") or r.get("v") or r.get("count")
                vals.append(vv)
                if isinstance(r.get("unit"), str):
                    unit = r.get("unit")
            if vals:
                series_out = [{
                    "name": None,
                    "unit": unit,
                    "values": vals,
                }]

        if categories and series_out:
            return {
                "categories": categories,
                "series": series_out,
            }

    return None



def _format_exact_values(raw_values: dict) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º raw_values, –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –æ–±—Ä–∞—â–∞—è—Å—å —Å –¥–æ–ª—è–º–∏:
    –µ—Å–ª–∏ unit —Å–æ–¥–µ—Ä–∂–∏—Ç '%' –∏ –í–°–ï –∑–Ω–∞—á–µ–Ω–∏—è –ª–µ–∂–∞—Ç –≤ [0 .. 1.2],
    —Å—á–∏—Ç–∞–µ–º –∏—Ö –¥–æ–ª—è–º–∏ –∏ –≤—ã–≤–æ–¥–∏–º –∫–∞–∫ –ø—Ä–æ—Ü–µ–Ω—Ç—ã (0.7 ‚Üí 70 %).
    """
    if not raw_values:
        return ""

    cats = list(raw_values.get("categories") or [])
    series = list(raw_values.get("series") or [])

    if not cats or not series:
        return ""

    lines: list[str] = ["–¢–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ):", ""]
    n = len(cats)

    for s in series:
        name = (s.get("name") or "").strip()
        unit = (s.get("unit") or "").strip()
        vals = list(s.get("values") or [])

        # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ ¬´—ç—Ç–æ –¥–æ–ª–∏ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö¬ª
        numeric_vals: list[float] = []
        for v in vals:
            try:
                numeric_vals.append(float(str(v).replace(",", ".")))
            except Exception:
                # —Ç–µ–∫—Å—Ç/–ø—É—Å—Ç–æ ‚Äî –∏–≥–Ω–æ—Ä–∏–º –¥–ª—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
                pass

        has_percent_unit = bool(unit) and "%" in unit
        is_share_like = bool(
            has_percent_unit
            and numeric_vals
            and all(0.0 <= x <= 1.2 for x in numeric_vals)
        )

        header = name or "–°–µ—Ä–∏—è"
        # –µ—Å–ª–∏ –µ–¥–∏–Ω–∏—Ü—ã –ù–ï –ø—Ä–æ—Ü–µ–Ω—Ç—ã ‚Äî –ø–æ–∫–∞–∂–µ–º –∏—Ö –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
        if unit and "%" not in unit:
            header = f"{header} ({unit})"
        lines.append(f"{header}:")

        for i in range(min(n, len(vals))):
            label = str(cats[i]).strip() or str(i + 1)
            raw_v = vals[i]

            v_num: float | None = None
            sval = ""

            if isinstance(raw_v, (int, float, Decimal)):
                v_num = float(raw_v)
            else:
                try:
                    v_num = float(str(raw_v).replace(",", "."))
                except Exception:
                    sval = str(raw_v) if raw_v is not None else ""

            if v_num is not None:
                if is_share_like:
                    v_num *= 100.0  # 0.7 ‚Üí 70.0

                if abs(v_num - round(v_num)) < 0.05:
                    sval = str(int(round(v_num)))
                else:
                    sval = f"{v_num:.2f}".rstrip("0").rstrip(".")

            # —Å—É—Ñ—Ñ–∏–∫—Å –µ–¥–∏–Ω–∏—Ü
            unit_suffix = ""
            if has_percent_unit:
                # —Ö–æ—Ç–∏–º ¬´70%¬ª, –±–µ–∑ –ø—Ä–æ–±–µ–ª–∞
                if not sval.endswith("%"):
                    unit_suffix = "%"
            elif unit:
                unit_suffix = f" {unit}"

            line = f"‚Äî {label}: {sval}{unit_suffix}".strip()
            if line:
                lines.append(line)

        lines.append("")  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É —Å–µ—Ä–∏—è–º–∏

    return "\n".join(l for l in lines if l.strip())



def _format_chart_values(chart_data: list) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º chart_data –ë–ï–ó –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∏ —Å—É–º–º –∏ –±–µ–∑ ¬´–ø–æ–¥–≥–æ–Ω–∫–∏¬ª –∫ 100%.

    –õ–æ–≥–∏–∫–∞:
      - –µ—Å–ª–∏ unit —Å–æ–¥–µ—Ä–∂–∏—Ç '%' –∏ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ [0..1.2],
        —Ç—Ä–∞–∫—Ç—É–µ–º –∏—Ö –∫–∞–∫ –¥–æ–ª–∏ (0.8 ‚Üí 80) –∏ –¥–æ–º–Ω–æ–∂–∞–µ–º –Ω–∞ 100;
      - –¥–∞–ª—å—à–µ –ø—Ä–æ—Å—Ç–æ –ø–µ—á–∞—Ç–∞–µ–º: ¬´‚Äî label: 80%¬ª.
    """
    rows = chart_data or []
    if not rows:
        return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–≤–æ–¥–∞."

    # —Å–æ–±–µ—Ä—ë–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –µ–≤—Ä–∏—Å—Ç–∏–∫–∏ ¬´—ç—Ç–æ –¥–æ–ª–∏ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö¬ª
    numeric_vals: list[float] = []
    has_percent_unit = False
    for r in rows:
        unit = r.get("unit")
        if isinstance(unit, str) and "%" in unit:
            has_percent_unit = True

        v = r.get("value")
        if v is None:
            v = r.get("y") or r.get("x") or r.get("v") or r.get("count")
        try:
            numeric_vals.append(float(str(v).replace(",", ".")))
        except Exception:
            # –µ—Å–ª–∏ —Ö–æ—Ç—å –æ–¥–∏–Ω –Ω–µ –ø—Ä–∏–≤–æ–¥–∏—Ç—Å—è –∫ —á–∏—Å–ª—É ‚Äî –ø—Ä–æ—Å—Ç–æ –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ–º –µ–≤—Ä–∏—Å—Ç–∏–∫—É
            pass

    is_share_like = bool(
        has_percent_unit
        and numeric_vals
        and all(0.0 <= x <= 1.2 for x in numeric_vals)
    )

    lines: list[str] = []
    for r in rows:
        label = (str(r.get("label") or r.get("name") or r.get("category") or "")).strip()

        raw_v = r.get("value")
        if raw_v is None:
            raw_v = r.get("y") or r.get("x") or r.get("v") or r.get("count")

        unit = r.get("unit")

        v_num: float | None = None
        sval = ""

        # –ø—Ä–æ–±—É–µ–º –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —á–∏—Å–ª—É
        if isinstance(raw_v, (int, float, Decimal)):
            v_num = float(raw_v)
        else:
            try:
                v_num = float(str(raw_v).replace(",", "."))
            except Exception:
                # —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞/—Ç–µ–∫—Å—Ç ‚Äî –æ—Å—Ç–∞–≤–∏–º –∫–∞–∫ –µ—Å—Ç—å
                sval = str(raw_v) if raw_v is not None else ""

        # —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ ‚Üí —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º
        if v_num is not None:
            if is_share_like:
                v_num *= 100.0  # 0.8 ‚Üí 80.0

            if abs(v_num - round(v_num)) < 0.05:
                sval = str(int(round(v_num)))
            else:
                sval = f"{v_num:.2f}".rstrip("0").rstrip(".")

        # –¥–æ–±–∞–≤–ª—è–µ–º –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
        unit_suffix = ""
        if isinstance(unit, str) and unit.strip():
            u = unit.strip()
            # –µ—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Ü–µ–Ω—Ç—ã –∏ –≤ —Å—Ç—Ä–æ–∫–µ –µ—â—ë –Ω–µ—Ç '%', –¥–æ–±–∞–≤–∏–º –±–µ–∑ –ø—Ä–æ–±–µ–ª–∞
            if "%" in u and not sval.endswith("%"):
                unit_suffix = "%"
            else:
                unit_suffix = f" {u}"

        text = (f"‚Äî {label}: {sval}{unit_suffix}").strip()
        if text:
            lines.append(text)

    return "\n".join(lines) if lines else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–≤–æ–¥–∞."

# --- –Ω–µ–±–æ–ª—å—à–∞—è –∫–æ—Å–º–µ—Ç–∏–∫–∞ –¥–ª—è –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –∏–∑ OOXML-–≥—Ä–∞—Ñ–∏–∫–æ–≤ ---

# –¥–≤–æ–µ—Ç–æ—á–∏–µ + –ø—Ä–æ–±–µ–ª—ã, —Å—Ä–∞–∑—É –ø–µ—Ä–µ–¥ ';' –∏–ª–∏ –∫–æ–Ω—Ü–æ–º —Å—Ç—Ä–æ–∫–∏
_EMPTY_PERCENT_RE = re.compile(r"(:\s*)(?=;|$)")

def _fill_empty_percents(text: str) -> str:
    """
    'label:' –∏–ª–∏ 'label: ;' ‚Üí 'label: 0%' –ø–µ—Ä–µ–¥ ';' –∏–ª–∏ –∫–æ–Ω—Ü–æ–º —Å—Ç—Ä–æ–∫–∏.
    –†–∞–±–æ—Ç–∞–µ—Ç –∏ –¥–ª—è –∫—É—Å–æ—á–∫–æ–≤ –≤–∏–¥–∞ '‚Ä¶; 3:' –∏ '‚Ä¶; 3: ;'.
    """
    return _EMPTY_PERCENT_RE.sub(lambda m: m.group(1) + "0%", text)


def _list_figures_db(uid: int, doc_id: int, limit: int = 25) -> dict:
    """–°–æ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ä–∏—Å—É–Ω–∫–æ–≤ –∏–∑ –ë–î (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å–æ —Å—Ç–∞—Ä—ã–º–∏ –∏–Ω–¥–µ–∫—Å–∞–º–∏)."""
    con = get_conn()
    cur = con.cursor()
    has_type = _table_has_columns(con, "chunks", ["element_type", "attrs"])

    if has_type:
        cur.execute(
            "SELECT DISTINCT section_path, attrs, text FROM chunks "
            "WHERE owner_id=? AND doc_id=? AND element_type='figure' "
            "ORDER BY id ASC",
            (uid, doc_id),
        )
    else:
        # —Å—Ç–∞—Ä—ã–µ –∏–Ω–¥–µ–∫—Å—ã ‚Äî –∫–æ–ª–æ–Ω–∫–∏ attrs –º–æ–∂–µ—Ç –Ω–µ –±—ã—Ç—å, –Ω–µ –≤—ã–±–∏—Ä–∞–µ–º –µ—ë
        cur.execute(
            "SELECT DISTINCT section_path, text FROM chunks "
            "WHERE owner_id=? AND doc_id=? AND (text LIKE '[–†–∏—Å—É–Ω–æ–∫]%' OR lower(section_path) LIKE '%—Ä–∏—Å—É–Ω–æ–∫%') "
            "ORDER BY id ASC",
            (uid, doc_id),
        )
    rows = cur.fetchall() or []
    con.close()

    items: list[str] = []
    for r in rows:
        section_path = r["section_path"] or ""
        attrs_json = r["attrs"] if ("attrs" in r.keys()) else None  # –≤ else –µ—ë –ø—Ä–æ—Å—Ç–æ –Ω–µ—Ç ‚Äî –æ–∫
        txt = r["text"] or None
        disp = _compose_figure_display(attrs_json, section_path, txt)
        items.append(disp)

    seen = set()
    uniq = []
    for it in items:
        k = it.strip().lower()
        if k and k not in seen:
            seen.add(k)
            uniq.append(it)

    total = len(uniq)
    return {
        "count": total,
        "list": uniq[:limit],
        "more": max(0, total - limit),
    }



# -------- –†–∞–Ω–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤–æ–ø—Ä–æ—Å–æ–≤ –≤–∏–¥–∞ ¬´—Ä–∏—Å—É–Ω–æ–∫ 2.1¬ª, ¬´—Ä–∏—Å. 3¬ª, ¬´figure 1.2¬ª --------

FIG_NUM_RE = re.compile(
    r"(?i)\b(?:—Ä–∏—Å\w*|—Å—Ö–µ–º\w*|–∫–∞—Ä—Ç–∏–Ω\w*|–¥–∏–∞–≥—Ä–∞–º\w*|–≥–∏—Å—Ç–æ–≥—Ä–∞–º\w*|diagram|chart|figure|fig\.?|picture|pic\.?)"
    r"\s*(?:‚Ññ\s*|no\.?\s*|–Ω–æ–º–µ—Ä\s*)?([A-Za-z–ê-–Ø–∞-—è]?\s*[\d.,\s]+(?:\s*(?:–∏|and)\s*[\d.,\s]+)*)"
)

# –Ω–æ–≤—ã–π —Ö–∏–Ω—Ç –¥–ª—è —Ä–µ–∂–∏–º–∞ ¬´–∏–∑–≤–ª–µ—á—å –∑–Ω–∞—á–µ–Ω–∏—è¬ª
_VALUES_HINT = re.compile(r"(?i)\b(–∑–Ω–∞—á–µ–Ω–∏[—è–µ]|—Ü–∏—Ñ—Ä[–∞—ã]|–ø—Ä–æ—Ü–µ–Ω—Ç[–∞-—è]*|values?|numbers?)\b")
_SPLIT_FIG_LIST_RE = re.compile(r"\s*(?:,|;|\band\b|–∏)\s*", re.IGNORECASE)

def _extract_fig_nums(text: str) -> list[str]:
    nums: list[str] = []
    for mm in FIG_NUM_RE.finditer(text or ""):
        seg = (mm.group(1) or "").strip()
        # —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏: –∑–∞–ø—è—Ç–∞—è, —Ç–æ—á–∫–∞ —Å –∑–∞–ø—è—Ç–æ–π, "–∏/and"
        parts = _SPLIT_FIG_LIST_RE.split(seg)
        for p in parts:
            p = p.strip()
            if not p:
                continue
            nums.append(p)
    return nums

_ALL_FIGS_HINT = re.compile(r"(?i)\b(–≤—Å–µ\s+—Ä–∏—Å—É–Ω–∫\w*|–≤—Å–µ\s+—Å—Ö–µ–º\w*|–≤—Å–µ\s+–∫–∞—Ä—Ç–∏–Ω\w*|all\s+pictures?|all\s+figs?)\b")

def _num_norm_fig(s: str | None) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–æ–º–µ—Ä —Ä–∏—Å—É–Ω–∫–∞ –¥–æ —á–∏—Å—Ç–æ–≥–æ –≤–∏–¥–∞:
    - –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º –¢–û–õ–¨–ö–û —á–∏—Å–ª–æ–≤—É—é —á–∞—Å—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–†–∏—Å. 2.1" -> "2.1");
    - –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ñ–æ—Ä–º–∞—Ç—ã 2.1, 2, 2.1.3 –∏ —Ç.–ø.;
    - —É–±–∏—Ä–∞–µ–º —Ö–≤–æ—Å—Ç–æ–≤—É—é –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é ("2.1." -> "2.1").
    """
    s = (s or "").strip()
    if not s:
        return ""

    # NBSP -> –ø—Ä–æ–±–µ–ª, –ø—Ä–∏–≤–æ–¥–∏–º –∑–∞–ø—è—Ç—É—é –∫ —Ç–æ—á–∫–µ
    s = s.replace("\u00A0", " ")
    s = s.replace(",", ".")

    # –ë–µ—Ä—ë–º –ü–û–°–õ–ï–î–ù–Æ–Æ —á–∏—Å–ª–æ–≤—É—é –≥—Ä—É–ø–ø—É –≤–∏–¥–∞ "1.2" / "2" / "3.4.5"
    m = re.search(r"(\d+(?:\.\d+)*)", s)
    if not m:
        return ""

    num = m.group(1)

    # –°—Ä–µ–∑–∞–µ–º —Ö–≤–æ—Å—Ç–æ–≤—É—é –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é, –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –æ—Å—Ç–∞–ª–∞—Å—å
    num = re.sub(r"[.:;)\]]+$", "", num)

    return num


def _is_pure_figure_request(text: str) -> bool:
    """
    –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –∑–∞–ø—Ä–æ—Å –¢–û–õ–¨–ö–û –ø—Ä–æ —Ä–∏—Å—É–Ω–∫–∏ (–æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–æ–º–µ—Ä–æ–≤),
    –±–µ–∑ —Ç–∞–±–ª–∏—Ü, —Ä–∞–∑–¥–µ–ª–æ–≤ –∏ –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.

    –ò—Å–ø–æ–ª—å–∑—É–µ–º, —á—Ç–æ–±—ã:
    ‚Äî —É–π—Ç–∏ –≤ –µ–¥–∏–Ω—ã–π figure-–ø–∞–π–ø–ª–∞–π–Ω;
    ‚Äî –Ω–µ –∑–∞–ø—É—Å–∫–∞—Ç—å –ø–æ—Ç–æ–º –æ–±—â–∏–π RAG-–ø–∞–π–ø–ª–∞–π–Ω, –∫–æ—Ç–æ—Ä—ã–π –¥—É–±–ª–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç—ã
      –∏ –º–æ–∂–µ—Ç –≤—ã–¥–∞–≤–∞—Ç—å ¬´–¥–∞–Ω–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞ –Ω–µ—Ç –≤ —Ä–∞–±–æ—Ç–µ¬ª.
    """
    t = (text or "").strip()
    if not t:
        return False

    # ¬´–≤—Å–µ —Ä–∏—Å—É–Ω–∫–∏¬ª ‚Äî –æ—Ç–¥–µ–ª—å–Ω–∞—è –≤–µ—Ç–∫–∞ (_ALL_FIGS_HINT)
    if _ALL_FIGS_HINT.search(t):
        return False

    # –Ω–µ—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Ä–∏—Å—É–Ω–∫–æ–≤ ‚Äî –Ω–µ –Ω–∞—à —Å–ª—É—á–∞–π
    if not FIG_NUM_RE.search(t):
        return False

    # –µ—Å–ª–∏ —è–≤–Ω–æ —É–ø–æ–º–∏–Ω–∞—é—Ç —Ç–∞–±–ª–∏—Ü—ã –∏–ª–∏ —Ä–∞–∑–¥–µ–ª—ã/–≥–ª–∞–≤—ã ‚Äî —ç—Ç–æ —É–∂–µ —Å–º–µ—à–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
    if _TABLE_ANY.search(t) or _SECTION_NUM_RE.search(t):
        return False

    return True


def _is_pure_section_request(text: str, intents: dict | None = None) -> bool:
    """
    –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: ¬´—á–∏—Å—Ç—ã–π¬ª –∑–∞–ø—Ä–æ—Å –ø—Ä–æ –≥–ª–∞–≤—É/—Ä–∞–∑–¥–µ–ª/–ø—É–Ω–∫—Ç:
      ‚Äî –µ—Å—Ç—å —Å—Å—ã–ª–∫–∞ –Ω–∞ –≥–ª–∞–≤—É/—Ä–∞–∑–¥–µ–ª/–ø—É–Ω–∫—Ç;
      ‚Äî –Ω–µ—Ç –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –ø—Ä–æ —Ç–∞–±–ª–∏—Ü—ã, —Ä–∏—Å—É–Ω–∫–∏ –∏–ª–∏ —Å–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.

    –í—Å—ë, —á—Ç–æ —Å–º–µ—à–∞–Ω–Ω–æ–µ (–≥–ª–∞–≤–∞ + —Ç–∞–±–ª–∏—Ü—ã/—Ä–∏—Å—É–Ω–∫–∏/–∏—Å—Ç–æ—á–Ω–∏–∫–∏), –¥–æ–ª–∂–Ω–æ –∏–¥—Ç–∏
    –≤ –æ–±—â–∏–π –º—É–ª—å—Ç–∏–∏ÃÜ–Ω—Ç–µ–Ω—Ç–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω, –∞ –Ω–µ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–µ–∫—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç.
    """
    t = (text or "").strip()
    if not t:
        return False

    # –Ω–µ—Ç —É–∫–∞–∑–∞–Ω–∏—è –ø—É–Ω–∫—Ç–∞/–≥–ª–∞–≤—ã ‚Äî –Ω–µ –Ω–∞—à —Å–ª—É—á–∞–π
    if not _SECTION_NUM_RE.search(t):
        return False

    # –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ —è–≤–Ω–æ —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –ø—Ä–æ —Ç–∞–±–ª–∏—Ü—ã/—Ä–∏—Å—É–Ω–∫–∏/–∏—Å—Ç–æ—á–Ω–∏–∫–∏ ‚Äî —ç—Ç–æ —É–∂–µ –º–∏–∫—Å
    if _TABLE_ANY.search(t) or FIG_NUM_RE.search(t) or _SOURCES_HINT.search(t):
        return False

    # –µ—Å–ª–∏ detect_intents —É–∂–µ —É–≤–∏–¥–µ–ª —Ç–∞–±–ª–∏—Ü—ã/—Ä–∏—Å—É–Ω–∫–∏/–∏—Å—Ç–æ—á–Ω–∏–∫–∏ ‚Äî —Ç–æ–∂–µ –Ω–µ —á–∏—Å—Ç—ã–π —Ä–∞–∑–¥–µ–ª
    if intents:
        if (
            intents.get("tables", {}).get("want")
            or intents.get("figures", {}).get("want")
            or intents.get("sources", {}).get("want")
        ):
            return False

    return True

def _build_figure_records(
    uid: int,
    doc_id: int,
    nums: list[str],
    *,
    need_values: bool = False,   # –Ω—É–∂–µ–Ω –ª–∏ –∞–∫—Ü–µ–Ω—Ç –Ω–∞ —á–∏—Å–ª–∞—Ö
) -> list[dict]:
    """
    –ï–¥–∏–Ω–∞—è "—Å–±–æ—Ä–∫–∞" –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∏—Å—É–Ω–∫–∞—Ö:
    ‚Äî –Ω–æ–º–µ—Ä –∏ –∫—Ä–∞—Å–∏–≤—ã–π display;
    ‚Äî –ø—É—Ç–∏ –∫ –∫–∞—Ä—Ç–∏–Ω–∫–∞–º;
    ‚Äî —Ç–æ—á–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–∏–∑ chart_data/OOXML/—Ç–∞–±–ª–∏—Ü);
    ‚Äî –ø–æ–¥–ø–∏—Å—å –∏ —Ç–µ–∫—Å—Ç —Ä—è–¥–æ–º;
    ‚Äî vision-–æ–ø–∏—Å–∞–Ω–∏–µ (–µ—Å–ª–∏ –µ—Å—Ç—å –∏ –Ω–µ ¬´–æ–ø–∏—Å–∞–Ω–∏–µ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ¬ª);
    ‚Äî —Ç–∏–ø —Ä–∏—Å—É–Ω–∫–∞ (bar/pie/line/org_chart/‚Ä¶).
    """
    if not nums:
        return []

    # –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π —Ö–µ–ª–ø–µ—Ä: –ø—ã—Ç–∞–µ–º—Å—è –≤—ã—Ç–∞—â–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä —Ä–∏—Å—É–Ω–∫–∞ –∏–∑ row
    def _row_fig_label(row, attrs_json=None) -> str:
        num = None
        try:
            aj = attrs_json
            if aj is None and ("attrs" in row.keys()):
                aj = row["attrs"]
            if isinstance(aj, str):
                aj = json.loads(aj)
            if isinstance(aj, dict):
                for key in ("caption_num", "num", "number", "label"):
                    if aj.get(key):
                        num = str(aj[key])
                        break
        except Exception:
            num = None

        # –µ—Å–ª–∏ –≤ attrs –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –ø—Ä–æ–±—É–µ–º –≤—ã—Ç–∞—â–∏—Ç—å –∏–∑ —Ç–µ–∫—Å—Ç–∞ ¬´–†–∏—Å. 2.1¬ª
        if not num:
            try:
                text = (row["text"] if ("text" in row.keys()) else "") or ""
                m = re.search(r"(?:–†–∏—Å\.?|–†–∏—Å—É–Ω–æ–∫)\s+([\d.]+)", text)
                if m:
                    num = m.group(1)
            except Exception:
                pass

        return _num_norm_fig(num) if num else ""

    # –∑–∞—Ä–∞–Ω–µ–µ —Ç—è–Ω–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –∏–∑ retrieval, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å images/—Ç–µ–∫—Å—Ç —Ä—è–¥–æ–º/vision
    try:
        cards = describe_figures_by_numbers(
            uid,
            doc_id,
            nums,
            sample_chunks=2,
            use_vision=True,
            lang="ru",
            vision_first_image_only=True,
        ) or []
    except Exception:
        cards = []

    cards_by_norm: dict[str, dict] = {}
    for c in cards:
        key = _num_norm_fig(str(c.get("num") or ""))
        if key and key not in cards_by_norm:
            cards_by_norm[key] = c

    idx_oox = _ooxml_get_index(doc_id)
    fig_idx = FIG_INDEX.get(doc_id)

    # –∫–ª—é—á: –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –Ω–æ–º–µ—Ä —Ä–∏—Å—É–Ω–∫–∞ ‚Üí record
    records_by_num: dict[str, dict] = {}

    for orig in nums:
        norm = _num_norm_fig(orig)
        if not norm:
            continue

        # –µ—Å–ª–∏ —ç—Ç–æ—Ç –Ω–æ–º–µ—Ä —É–∂–µ —Å–æ–±—Ä–∞–Ω ‚Äî –Ω–µ —Å–æ–∑–¥–∞—ë–º –¥—É–±–ª—å
        if norm in records_by_num:
            continue

        card = cards_by_norm.get(norm)
        rec: dict = {
            "owner_id": uid,
            "doc_id": doc_id,
            "num": norm,
            "orig": orig,
            "display": None,
            "images": [],
            # –µ–¥–∏–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∏—Å—Ç–∏–Ω—ã –ø–æ —á–∏—Å–ª–∞–º
            "raw_values": None,
            "values_text": None,
            "values_source": None,     # "ooxml" | "summary" | "vision" | "table" | "rag"
            "values": None,            # –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º –∫–æ–¥–æ–º
            "near_text": [],
            "caption": None,
            "vision_desc": None,
            "chunk_id": None,
            "figure_kind": None,       # bar / pie / line / org_chart / text_blocks / ...
        }

                # --- 1) –¥–∞–Ω–Ω—ã–µ –∏–∑ RAG-–∫–∞—Ä—Ç–æ—á–µ–∫ ---
        if card:
            # display –∏–∑ –∫–∞—Ä—Ç–æ—á–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω –ø—Ä–æ —Ç–æ—Ç –∂–µ –Ω–æ–º–µ—Ä,
            # –∏–Ω–∞—á–µ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º, —á—Ç–æ–±—ã 1.1/1.2 –Ω–µ –ø–æ–¥–º–µ–Ω—è–ª–∏—Å—å –Ω–∞ 2.1 –∏ —Ç.–ø.
            card_display = (card.get("display") or "").strip()
            if card_display:
                disp_num = _num_norm_fig(card_display)
                if not disp_num or disp_num == norm:
                    rec["display"] = card_display

            rec["images"] = [p for p in (card.get("images") or []) if p]

            # —Ö–∞–π–ª–∞–π—Ç—ã –∏–∑ RAG –±–µ—Ä—ë–º –∫–∞–∫ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç,
            # –Ω–æ –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º –∞–±–∑–∞—Ü—ã, –≥–¥–µ —è–≤–Ω–æ —É–ø–æ–º—è–Ω—É—Ç –î–†–£–ì–û–ô –Ω–æ–º–µ—Ä —Ä–∏—Å—É–Ω–∫–∞
            clean_highlights: list[str] = []
            for h in (card.get("highlights") or []):
                txt = (h or "").strip()
                if not txt:
                    continue
                m = re.search(r"(?:–†–∏—Å\.?|–†–∏—Å—É–Ω–æ–∫)\s+([\d.]+)", txt, flags=re.IGNORECASE)
                if m:
                    other = _num_norm_fig(m.group(1))
                    if other and other != norm:
                        # —ç—Ç–æ —è–≤–Ω–æ –ø—Ä–æ –¥—Ä—É–≥–æ–π —Ä–∏—Å—É–Ω–æ–∫ ‚Üí –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        continue
                clean_highlights.append(txt)

            rec["near_text"] = clean_highlights



            # VISION: –∑–∞–±–∏—Ä–∞–µ–º –º–∞–∫—Å–∏–º—É–º —Ç–µ–∫—Å—Ç–∞ —Å –∫–∞—Ä—Ç–∏–Ω–∫–∏
            vision = card.get("vision") or {}
            vis_parts: list[str] = []

            desc = (vision.get("description") or "").strip()
            if desc:
                vis_parts.append(desc)

            raw_text = (vision.get("raw_text") or vision.get("text") or "").strip()
            if raw_text:
                vis_parts.append(raw_text)

            vis_clean = " ".join(vis_parts).strip()
            low = vis_clean.lower()
            logging.info(
                "FIGURE %s kind=%r vision_desc=%r",
                rec["num"],
                rec.get("figure_kind"),
                vis_clean[:300],
            )
            if vis_clean and "–æ–ø–∏—Å–∞–Ω–∏–µ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ" not in low and "—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è" not in low:
                rec["vision_desc"] = vis_clean

            # NEW: —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è/—Å—Ç—Ä–æ–∫–∏ –∏–∑ retrieval (–≤ —Ç.—á. –∏–∑ —Ç–∞–±–ª–∏—Ü—ã-–∏—Å—Ç–æ—á–Ω–∏–∫–∞)
            vals = (card.get("values_str") or "").strip()
            if vals and not rec.get("values_text"):
                rec["values_text"] = vals
                rec["values_source"] = rec.get("values_source") or "rag"
                rec["values"] = rec["values_text"]

        # --- 2) OOXML-–∏–Ω–¥–µ–∫—Å: –ø–æ–¥–ø–∏—Å—å –∏ image_path ---
        if idx_oox:
            oox_rec = _ooxml_find_figure_by_label(idx_oox, norm) or _ooxml_find_figure_by_label(idx_oox, orig)
            if oox_rec:
                cap = (oox_rec.get("caption") or "").strip()
                if cap:
                    rec["caption"] = cap
                if not rec["display"]:
                    label = oox_rec.get("n") or norm
                    rec["display"] = f"–†–∏—Å—É–Ω–æ–∫ {label}" + (f" ‚Äî {cap}" if cap else "")
                path = oox_rec.get("image_path")
                if path and path not in rec["images"]:
                    rec["images"].append(path)

                kind_oox = (oox_rec.get("kind") or "").strip()
                if kind_oox and not rec.get("figure_kind"):
                    rec["figure_kind"] = kind_oox

        # --- 3) –ª–æ–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å figures.py: –ø—É—Ç—å –∫ –∫–∞—Ä—Ç–∏–Ω–∫–µ + –ø–æ–¥–ø–∏—Å—å ---
        if fig_idx:
            try:
                recs = fig_find(fig_idx, number=orig) or fig_find(fig_idx, number=norm) or []
            except Exception:
                recs = []
            for r in recs:
                if not rec["display"]:
                    rec["display"] = figure_display_name(r)
                ap = r.get("abs_path")
                if ap and ap not in rec["images"]:
                    rec["images"].append(ap)
                cap_text = r.get("caption") or r.get("title")
                if cap_text and not rec["caption"]:
                    rec["caption"] = cap_text
                if not rec["near_text"] and cap_text:
                    rec["near_text"].append(cap_text)

                kind_loc = (r.get("kind") or "").strip()
                if kind_loc and not rec.get("figure_kind"):
                    rec["figure_kind"] = kind_loc

                # üîé 3.bis. –ú—è–≥–∫–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ "–ø–æ –ø–æ–¥–ø–∏—Å–∏": —Ç–æ–ª—å–∫–æ –æ–±—â–∏–µ —Å—Ö–µ–º—ã
        # –í–ê–ñ–ù–û:
        #  - –±–æ–ª—å—à–µ –ù–ï –ø–æ–º–µ—á–∞–µ–º –Ω–∏—á–µ–≥–æ –∫–∞–∫ org_chart —Ç–æ–ª—å–∫–æ –ø–æ —Å–ª–æ–≤–∞–º –≤ –ø–æ–¥–ø–∏—Å–∏,
        #    —á—Ç–æ–±—ã —Ä–∏—Å—É–Ω–∫–∏ 1.1 / 1.2 –Ω–µ ¬´–ø—Ä–∏—Ç—è–≥–∏–≤–∞–ª–∏—Å—å¬ª –∫ –æ—Ä–≥—Å—Ç—Ä—É–∫—Ç—É—Ä–∞–º –∏–∑ 2.1;
        #  - org_chart —Ç–µ–ø–µ—Ä—å –º–æ–∂–µ—Ç –ø–æ—è–≤–∏—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –∏–∑ OOXML/figures-–∏–Ω–¥–µ–∫—Å–∞,
        #    –≥–¥–µ —è–≤–Ω–æ —É–∫–∞–∑–∞–Ω kind –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞.
        if not rec.get("figure_kind"):
            cap_low = (rec.get("caption") or "").strip().lower()
            # —Ç–æ–ª—å–∫–æ –æ—á–µ–Ω—å –æ–±—â–∏–µ "—Å—Ö–µ–º–∞/–º–æ–¥–µ–ª—å/–∞–ª–≥–æ—Ä–∏—Ç–º", –±–µ–∑ "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞"
            if cap_low and any(kw in cap_low for kw in ("—Å—Ö–µ–º–∞", "–º–æ–¥–µ–ª—å", "–∞–ª–≥–æ—Ä–∏—Ç–º", "–±–ª–æ–∫-—Å—Ö–µ–º–∞")):
                rec["figure_kind"] = "schema"


        # --- 4) chart_data –∏–∑ attrs (–¢–û–ß–ù–´–ï —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ OOXML) ---
        row = _fetch_figure_row_by_num(uid, doc_id, orig)
        logging.info("FIGURE %s: fetch_row(orig=%r) -> %s", norm, orig, "HIT" if row else "MISS")

        if not row and norm != orig:
            row = _fetch_figure_row_by_num(uid, doc_id, norm)
            logging.info("FIGURE %s: fetch_row(norm=%r) -> %s", norm, norm, "HIT" if row else "MISS")

        # ‚¨áÔ∏è –ù–û–í–û–ï: –¥–∞–∂–µ –µ—Å–ª–∏ fetch_row —á—Ç–æ-—Ç–æ –Ω–∞—à—ë–ª, –ø—Ä–æ–≤–µ—Ä—è–µ–º,
        # —á—Ç–æ –≤–Ω—É—Ç—Ä–∏ chunk‚Äô–∞ —Ä–µ–∞–ª—å–Ω–æ —ç—Ç–æ—Ç –∂–µ –Ω–æ–º–µ—Ä —Ä–∏—Å—É–Ω–∫–∞, –∞ –Ω–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä, 2.1
        if row:
            try:
                real_label = _row_fig_label(row)
            except Exception:
                real_label = ""

            if real_label and real_label != norm:
                logging.info(
                    "FIGURE %s: fetch_row returned foreign figure (real=%s), ignore row",
                    norm,
                    real_label,
                )
                row = None

        # ‚¨áÔ∏è –ù–û–í–û–ï: –µ—Å–ª–∏ figure-—á–∞–Ω–∫–∞ –Ω–µ—Ç, –ø—Ä–æ–±—É–µ–º —Å–æ–±—Ä–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ —Å—Ç—Ä–æ–∫–µ "–†–∏—Å—É–Ω–æ–∫ N"
        if not row and not rec.get("caption") and not rec.get("near_text"):
            cap_fallback, near_fallback = _figure_fallback_context_from_caption(uid, doc_id, norm)
            if cap_fallback:
                rec["caption"] = rec.get("caption") or cap_fallback
            if near_fallback:
                rec["near_text"] = near_fallback

        # –µ—Å–ª–∏ –ø–æ caption_num –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –ø—Ä–æ–±—É–µ–º –¥–æ—Å—Ç–∞—Ç—å figure-chunk –ø–æ —Ç–µ–∫—Å—Ç—É/section_path
        if not row:
            try:
                con = get_conn()
                cur = con.cursor()

                pats = []
                cap = (rec.get("caption") or "").strip()
                if cap:
                    cap_snip = cap[:60]
                    pats.append(f"%{cap_snip}%")

                pats.extend([
                    f"%–†–∏—Å—É–Ω–æ–∫ {norm}%",
                    f"%–†–∏—Å. {norm}%",
                    f"%–†–∏—Å.{norm}%",
                    f"%{norm}%",
                ])

                for pat in pats:
                    cur.execute(
                        """
                        SELECT id, page, section_path, attrs, text
                        FROM chunks
                        WHERE owner_id=? AND doc_id=? AND element_type='figure'
                          AND (
                                (text IS NOT NULL AND text LIKE ? COLLATE NOCASE)
                             OR (section_path IS NOT NULL AND section_path LIKE ? COLLATE NOCASE)
                          )
                        ORDER BY id ASC LIMIT 1
                        """,
                        (uid, doc_id, pat, pat),
                    )
                    row = cur.fetchone()
                    if not row:
                        continue

                    # üîç NEW: –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–π chunk —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–æ –Ω—É–∂–Ω—ã–π –Ω–æ–º–µ—Ä —Ä–∏—Å—É–Ω–∫–∞
                    real_label = _row_fig_label(row)
                    if real_label and real_label != norm:
                        logging.info(
                            "FIGURE %s: SQL fallback matched foreign figure %r (real=%s), skip",
                            norm,
                            row.get("id") if hasattr(row, "get") else None,
                            real_label,
                        )
                        row = None
                        continue

                    # –µ—Å–ª–∏ –Ω–æ–º–µ—Ä–∞ –Ω–µ—Ç –≤–æ–æ–±—â–µ (–Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å) ‚Äî –ø—É—Å—Ç—å –æ—Å—Ç–∞—ë—Ç—Å—è
                    break
            except Exception:
                row = None
            finally:
                try:
                    con.close()
                except Exception:
                    pass

        # ‚¨áÔ∏è –ù–û–í–û–ï: –µ—Å–ª–∏ –¥–∞–∂–µ –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫ figure-—á–∞–Ω–∫ —Ç–∞–∫ –∏ –Ω–µ –Ω–∞—à–ª–∏,
        # –ø—Ä–æ–±—É–µ–º –≤—ã—Ç–∞—â–∏—Ç—å –ø–æ–¥–ø–∏—Å—å –∏ —Ç–µ–∫—Å—Ç –ø–æ –Ω–æ–º–µ—Ä—É "–†–∏—Å—É–Ω–æ–∫ X.Y" –∏–∑ –æ–±—ã—á–Ω—ã—Ö –∞–±–∑–∞—Ü–µ–≤.
        if not row:
            fb = _figure_fallback_from_caption(uid, doc_id, norm)
            if fb:
                cap_fb = (fb.get("caption") or "").strip()
                if cap_fb and not rec.get("caption"):
                    rec["caption"] = cap_fb

                near_fb = fb.get("near_text") or []
                if near_fb and not rec.get("near_text"):
                    rec["near_text"] = near_fb

                # –µ—Å–ª–∏ —Ç–∏–ø –µ—â—ë –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω, —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–π —Å—Ö–µ–º–æ–π
                if not rec.get("figure_kind"):
                    rec["figure_kind"] = "schema"

        if row:
            try:
                rec["chunk_id"] = row["id"]

            except Exception:
                pass

            attrs_json = row["attrs"] if ("attrs" in row.keys()) else None

            try:
                if attrs_json and not rec.get("figure_kind"):
                    if isinstance(attrs_json, str):
                        _attrs_obj = json.loads(attrs_json)
                    else:
                        _attrs_obj = attrs_json or {}
                    kind_attr = (_attrs_obj.get("figure_kind") or "").strip()
                    if kind_attr:
                        rec["figure_kind"] = kind_attr
            except Exception:
                pass

            # 4.a) –ø—Ä–æ–±—É–µ–º –¥–æ—Å—Ç–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ raw_values –∏–∑ OOXML
            raw = _extract_raw_values_from_attrs(attrs_json)
            if raw:
                rec["raw_values"] = raw
                rec["values_text"] = _format_exact_values(raw)
                rec["values_source"] = "ooxml"
                rec["values"] = rec["values_text"]

            if not rec.get("raw_values"):
                cd, _ctype, _attrs = _parse_chart_data(attrs_json)
                if cd:
                    categories = [
                        str(r.get("label") or r.get("name") or r.get("category") or "")
                        for r in cd
                    ]
                    values = []
                    for r in cd:
                        v = r.get("value")
                        if v is None:
                            v = r.get("y") or r.get("x") or r.get("v") or r.get("count")
                        values.append(v)
                    rec["raw_values"] = {
                        "categories": categories,
                        "series": [{
                            "name": None,
                            "unit": (cd[0].get("unit") if cd and isinstance(cd[0].get("unit"), str) else None),
                            "values": values,
                        }],
                    }
                    rec["values_text"] = _format_exact_values(rec["raw_values"])
                    rec["values_source"] = "ooxml"
                    rec["values"] = rec["values_text"]

            # 4.b) display ‚Äî –∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ
            if not rec["display"]:
                title_text = row["text"] if ("text" in row.keys()) else None
                rec["display"] = _compose_figure_display(
                    attrs_json,
                    row["section_path"],
                    title_text,
                )

            # 4.c) —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ —Ä–∏—Å—É–Ω–∫–∞: 2‚Äì3 –∞–±–∑–∞—Ü–∞ –ø—Ä—è–º–æ –∏–∑ –¥–∏–ø–ª–æ–º–∞
            try:
                follow = _figure_following_paragraphs(
                    uid, doc_id, row, max_paragraphs=3, max_chars=1500
                )
                if follow:
                    # ‚ö†Ô∏è –í–ê–ñ–ù–û: —Å—á–∏—Ç–∞–µ–º –∏–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç ¬´–∏—Å—Ç–∏–Ω–æ–π¬ª –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞
                    # –∏ –Ω–µ —Å–º–µ—à–∏–≤–∞–µ–º –µ–≥–æ —Å RAG-—Ö–∞–π–ª–∞–π—Ç–∞–º–∏ –æ—Ç –¥—Ä—É–≥–∏—Ö —Ä–∏—Å—É–Ω–∫–æ–≤.
                    rec["near_text"] = follow
                elif not rec.get("near_text") and rec.get("caption"):
                    # –µ—Å–ª–∏ –≤–æ–∫—Ä—É–≥ —Ä–∏—Å—É–Ω–∫–∞ –Ω–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∞–±–∑–∞—Ü–µ–≤,
                    # –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ö–æ—Ç—è –±—ã –ø–æ–¥–ø–∏—Å—å –∫–∞–∫ –º–∏–Ω–∏–º—É–º —Ç–µ–∫—Å—Ç–∞
                    rec["near_text"] = [rec["caption"]]
            except Exception:
                pass

            # 4.d) —Ñ–æ–ª–±—ç–∫ –ø–æ —Ç–∞–±–ª–∏—Ü–µ: —Ç–æ–ª—å–∫–æ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö —Ñ–∏–≥—É—Ä –∏ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —á–∏—Å–µ–ª
            if not rec.get("raw_values"):
                try:
                    textual_kinds = {
                        "org_chart",
                        "orgchart",
                        "flowchart",
                        "text_blocks",
                        "schema",
                        "scheme",
                        "block_diagram",
                        "structure",
                    }
                    fig_kind = (rec.get("figure_kind") or "").strip().lower()
                    is_textual_figure = fig_kind in textual_kinds

                    if not is_textual_figure and need_values:
                        _attach_table_values_from_near_text(uid, doc_id, rec)
                except Exception:
                    logging.exception("figure->table fallback failed")

        if not rec["display"]:
            rec["display"] = f"–†–∏—Å—É–Ω–æ–∫ {norm}"

        # --- 5) VISION fallback ---
        if not rec.get("vision_desc") and va_analyze_figure and rec.get("images"):
            try:
                vis = va_analyze_figure(rec["images"][0], lang="ru")
                if isinstance(vis, dict):
                    desc = (vis.get("description") or "").strip()
                    raw_text = (vis.get("raw_text") or vis.get("text") or "").strip()
                    vis_clean = " ".join([p for p in (desc, raw_text) if p]).strip()

                    low = vis_clean.lower()
                    if vis_clean and "–æ–ø–∏—Å–∞–Ω–∏–µ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ" not in low and "—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è" not in low:
                        rec["vision_desc"] = vis_clean
                        logging.info("FIGURE %s vision_fallback=%r", rec["num"], vis_clean[:300])
                    else:
                        logging.info("FIGURE %s vision_fallback discarded=%r", rec["num"], vis_clean[:300])
            except Exception as e:
                logging.exception("vision fallback failed for figure %s: %s", rec["num"], e)

                # --- 6) –°–∞–Ω–∏—Ç–∞—Ä–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ near_text ---
        # –£–¥–∞–ª—è–µ–º –∫—É—Å–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–Ω–æ –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –î–†–£–ì–ò–ú —Ä–∏—Å—É–Ω–∫–∞–º
        clean_near: list[str] = []
        for t in rec.get("near_text") or []:
            txt = (t or "").strip()
            if not txt:
                continue
            m = re.search(r"(?:–†–∏—Å\.?|–†–∏—Å—É–Ω–æ–∫)\s+([\d.]+)", txt, flags=re.IGNORECASE)
            if m:
                other = _num_norm_fig(m.group(1))
                # –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ —É–ø–æ–º—è–Ω—É—Ç –¥—Ä—É–≥–æ–π –Ω–æ–º–µ—Ä —Ä–∏—Å—É–Ω–∫–∞ ‚Äî –≤—ã–∫–∏–¥—ã–≤–∞–µ–º —Ç–∞–∫–æ–π –∞–±–∑–∞—Ü
                if other and other != norm:
                    continue
            clean_near.append(txt)

        rec["near_text"] = clean_near

        # --- 7) –§–æ–ª–±—ç–∫ –ø–æ –ø–æ–¥–ø–∏—Å–∏ –≤ –æ–±—ã—á–Ω–æ–º —Ç–µ–∫—Å—Ç–µ (SmartArt –∏ ¬´–Ω–µ–≤–∏–¥–∏–º—ã–µ¬ª —Ä–∏—Å—É–Ω–∫–∏) ---
        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –≤—Å–µ—Ö —à–∞–≥–æ–≤ –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É –Ω–µ—Ç –Ω–∏ –ø–æ–¥–ø–∏—Å–∏, –Ω–∏ –≤–Ω—è—Ç–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Ä—è–¥–æ–º,
        # –ø—Ä–æ–±—É–µ–º –¥–æ—Å—Ç–∞—Ç—å –∏—Ö –∏–∑ –æ–±—ã—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∞–±–∑–∞—Ü–∞ –≤–∏–¥–∞ ¬´–†–∏—Å. 1.2 ...¬ª.
        if (not rec.get("caption")) or not rec.get("near_text"):
            try:
                cap_fb, near_fb = _figure_fallback_from_caption_text(uid, doc_id, norm)
            except Exception:
                cap_fb, near_fb = None, []

            if cap_fb and not rec.get("caption"):
                rec["caption"] = cap_fb
            if near_fb and not rec.get("near_text"):
                rec["near_text"] = near_fb

        # –µ—Å–ª–∏ –ø–æ—Å–ª–µ –≤—Å–µ—Ö —Ñ–æ–ª–±—ç–∫–æ–≤ –≤–æ–∫—Ä—É–≥ —Ä–∏—Å—É–Ω–∫–∞ –≤—Å—ë –µ—â—ë –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞ ‚Äî
        # –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ö–æ—Ç—è –±—ã –ø–æ–¥–ø–∏—Å—å –∫–∞–∫ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if not rec.get("near_text") and rec.get("caption"):
            rec["near_text"] = [rec["caption"]]

        records_by_num[norm] = rec


    return list(records_by_num.values())



def _clean_caption_for_figure(caption: str, expected_num: str) -> str:
    """
    –ï—Å–ª–∏ –ø–æ–¥–ø–∏—Å—å –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ '–†–∏—Å. 2.1. ...', –∞ –º—ã –æ–ø–∏—Å—ã–≤–∞–µ–º, –Ω–∞–ø—Ä–∏–º–µ—Ä, 1.2 ‚Äî
    –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ–º —á—É–∂–æ–π –Ω–æ–º–µ—Ä –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –Ω–µ–≥–æ.
    –ï—Å–ª–∏ –Ω–æ–º–µ—Ä —Å–æ–≤–ø–∞–¥–∞–µ—Ç –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—É—é —Å—Ç—Ä–æ–∫—É.
    """
    caption = (caption or "").strip()
    if not caption:
        return ""

    try:
        m = re.match(
            r"^\s*(—Ä–∏—Å(—É–Ω–æ–∫)?\.?\s+)?([\d.]+)\s*[\).:-]?\s*(.*)$",
            caption,
            flags=re.IGNORECASE,
        )
    except Exception:
        return caption

    if not m:
        return caption

    label_num_raw = m.group(3) or ""
    tail = (m.group(4) or "").strip()

    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ–±–∞ –Ω–æ–º–µ—Ä–∞
    exp_norm = _num_norm_fig(expected_num)
    label_norm = _num_norm_fig(label_num_raw)

    # –µ—Å–ª–∏ –Ω–æ–º–µ—Ä –≤ –ø–æ–¥–ø–∏—Å–∏ –¥—Ä—É–≥–æ–π ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ ¬´—Ö–≤–æ—Å—Ç¬ª –±–µ–∑ "–†–∏—Å. X.X"
    if label_norm and exp_norm and label_norm != exp_norm:
        return tail or ""

    # –Ω–æ–º–µ—Ä —Å–æ–≤–ø–∞–¥–∞–µ—Ç –∏–ª–∏ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å—å –∫–∞–∫ –µ—Å—Ç—å
    return caption


def _format_table_values_for_figure(table_num: str, ctx: str) -> str:
    """
    –ê–∫–∫—É—Ä–∞—Ç–Ω–æ –æ–±–æ—Ä–∞—á–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç —Ç–∞–±–ª–∏—Ü—ã –≤ –ø–æ—è—Å–Ω–µ–Ω–∏–µ –¥–ª—è –≤—ã–≤–æ–¥–∞ –ø–æ —Ä–∏—Å—É–Ω–∫—É.

    –ù–∏—á–µ–≥–æ –Ω–µ –ø–∞—Ä—Å–∏—Ç –∏ –Ω–µ –ø–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç:
    - –æ—Å—Ç–∞–≤–ª—è–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç/Markdown-—Ç–∞–±–ª–∏—Ü—É –∫–∞–∫ –µ—Å—Ç—å;
    - –¥–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫
      "–ü–æ –¥–∞–Ω–Ω—ã–º —Ç–∞–±–ª–∏—Ü—ã X.X —Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ):".
    """
    ctx = (ctx or "").strip()
    if not ctx:
        return ""

    # –†–∞–∑–Ω–æ—Å–∏–º –≤–æ–∑–º–æ–∂–Ω—É—é —Å—Ç—Ä–æ–∫—É "–¢–∞–±–ª–∏—Ü–∞ 2.5 ..." –æ—Ç–¥–µ–ª—å–Ω–æ
    lines = [l.rstrip() for l in ctx.splitlines() if l.strip()]
    title_line = None
    body_lines: list[str] = []

    for ln in lines:
        if title_line is None and ln.lower().startswith("—Ç–∞–±–ª–∏—Ü–∞"):
            title_line = ln
        else:
            body_lines.append(ln)

    header = f"–ü–æ –¥–∞–Ω–Ω—ã–º —Ç–∞–±–ª–∏—Ü—ã {table_num} —Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ):"
    md: list[str] = [header]

    if title_line:
        md.append("")
        md.append(title_line)

    body_text = "\n".join(body_lines) if body_lines else ctx

    # –ª—ë–≥–∫–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã—Ö –ø—Ä–æ—Å—Ç—ã–Ω–µ–π
    if len(body_text) > 4000:
        body_text = body_text[:4000] + "‚Ä¶"

    md.append("")
    md.append(body_text)

    return "\n".join(md)



def _attach_table_values_from_near_text(
    uid: int,
    doc_id: int,
    rec: dict,
) -> None:
    """
    –§–æ–ª–±—ç–∫ –¥–ª—è –†–ò–°–£–ù–ö–û–í-–ë–ê–†–ß–ê–†–¢–û–í/–ì–†–ê–§–ò–ö–û–í –±–µ–∑ —á–∏—Å–µ–ª.

    –í–ê–ñ–ù–û: –¥–ª—è —Å—Ö–µ–º/–æ—Ä–≥—Å—Ç—Ä—É–∫—Ç—É—Ä/–±–ª–æ–∫-—Å—Ö–µ–º —Ç–∞–±–ª–∏—Ü—ã –ù–ï –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ–º –≤–æ–æ–±—â–µ,
    —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ —Å—Ç—Ä–∞–Ω–Ω—ã—Ö ¬´—Ç–∞–±–ª–∏—Ü–∞ ?¬ª –∏ –ª–∏—à–Ω–∏—Ö —á–∏—Å–µ–ª.
    """

    # --- 0. –ñ—ë—Å—Ç–∫–∏–π —Å—Ç–æ–ø –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å—Ö–µ–º / –æ—Ä–≥—Å—Ç—Ä—É–∫—Ç—É—Ä ---
    fig_kind = (rec.get("figure_kind") or "").strip().lower()
    textual_kinds = {
        "org_chart",
        "orgchart",
        "flowchart",
        "text_blocks",
        "schema",
        "scheme",
        "block_diagram",
        "structure",
    }

    # –µ—Å–ª–∏ –¥–≤–∏–∂–æ–∫/–∏–Ω–¥–µ–∫—Å—ã —É–∂–µ –ø–æ–º–µ—Ç–∏–ª–∏ —Ä–∏—Å—É–Ω–æ–∫ –∫–∞–∫ —Å—Ö–µ–º—É ‚Äî —Å—Ä–∞–∑—É –≤—ã—Ö–æ–¥–∏–º
    if fig_kind in textual_kinds:
        return

    # –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ–¥–ø–∏—Å–∏:
    # ¬´–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è¬ª, ¬´—Å—Ö–µ–º–∞¬ª, ¬´–º–æ–¥–µ–ª—å¬ª, ¬´–∞–ª–≥–æ—Ä–∏—Ç–º¬ª –∏ —Ç.–ø.
    caption_low = (rec.get("caption") or "").strip().lower()
    caption_keywords = (
        "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞",
        "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è",
        "–æ—Ä–≥—Å—Ç—Ä—É–∫—Ç—É—Ä–∞",
        "—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è",
        "—Å—Ö–µ–º–∞",
        "–º–æ–¥–µ–ª—å",
        "–∞–ª–≥–æ—Ä–∏—Ç–º",
        "–±–ª–æ–∫-—Å—Ö–µ–º–∞",
    )
    if any(kw in caption_low for kw in caption_keywords):
        return

    """
    –î–∞–ª—å—à–µ ‚Äî –°–¢–ê–†–ê–Ø –õ–û–ì–ò–ö–ê, –Ω–æ —É–∂–µ —Ç–æ—á–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –¥–∏–∞–≥—Ä–∞–º–º.
    """

    # 1) –µ—Å–ª–∏ —É —Ä–∏—Å—É–Ω–∫–∞ —É–∂–µ –µ—Å—Ç—å ¬´—Å–∏–ª—å–Ω—ã–µ¬ª –∑–Ω–∞—á–µ–Ω–∏—è (OOXML / table) ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
    if rec.get("raw_values"):
        return
    src = (rec.get("values_source") or "").lower()
    if src in {"ooxml", "table"}:
        return

    # –Ω–æ–º–µ—Ä —Ä–∏—Å—É–Ω–∫–∞, —á—Ç–æ–±—ã —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ –≥–ª–∞–≤–µ (2.1 ‚Üí "2")
    fig_num = str(rec.get("orig") or rec.get("num") or "").strip()

    def _same_chapter(fig: str, tbl: str) -> bool:
        if not fig or not tbl:
            return True  # –ª—É—á—à–µ –Ω–µ —Ä–µ–∑–∞—Ç—å —Å–ª–∏—à–∫–æ–º –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ
        f_ch = fig.split(".", 1)[0]
        t_ch = tbl.split(".", 1)[0]
        return f_ch == t_ch

    # 2) –ø–æ–¥–ø–∏—Å—å + —Ç–µ–∫—Å—Ç —Ä—è–¥–æ–º ‚Äî –ø—Ä–∏–≥–æ–¥–∏—Ç—Å—è –∏ –¥–ª—è —è–≤–Ω—ã—Ö —Å—Å—ã–ª–æ–∫
    parts: list[str] = []
    cap = (rec.get("caption") or "").strip()
    if cap:
        parts.append(cap)

    near_parts = rec.get("near_text") or []
    parts.extend(p for p in near_parts if p)

    near_text = " ".join(parts).strip()

    table_num_raw: Optional[str] = None
    snippets = None
    full_ctx: Optional[str] = None

    # 3) —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —è–≤–Ω–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã: "—Ç–∞–±–ª–∏—Ü–∞ 2.5", "—Ç–∞–±–ª. 1.1", "table 3"
    if near_text:
        try:
            m = _TABLE_NUM_IN_TEXT_RE.search(near_text)
        except Exception:
            m = None

        if m:
            candidate = (m.group(1) or "").strip() or None
            if candidate and _same_chapter(fig_num, candidate):
                table_num_raw = candidate
                try:
                    snippets = get_table_context_for_numbers(
                        owner_id=uid,
                        doc_id=doc_id,
                        numbers=[table_num_raw],
                        include_all_values=True,
                        rows_limit=None,  # –±–µ—Ä—ë–º –≤—Å—é —Ç–∞–±–ª–∏—Ü—É
                    )
                except Exception as e:
                    logging.exception(
                        "figure->table: get_table_context_for_numbers failed (explicit): %s",
                        e,
                    )

    # 4) –µ—Å–ª–∏ —è–≤–Ω–æ–π —Å—Å—ã–ª–∫–∏ –Ω–µ—Ç –ò–õ–ò –ø–æ –Ω–µ–π –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –ø—Ä–æ–±—É–µ–º –±–ª–∏–∂–∞–π—à—É—é —Ç–∞–±–ª–∏—Ü—É –≤—ã—à–µ
    if not snippets and rec.get("chunk_id"):
        try:
            tbl_meta = find_nearest_table_above(doc_id=doc_id, chunk_id=rec["chunk_id"])
        except Exception as e:
            logging.exception("figure->table: find_nearest_table_above failed: %s", e)
            tbl_meta = None

        if tbl_meta:
            # –ø—Ä–æ–±—É–µ–º –≤—ã—Ç–∞—â–∏—Ç—å –Ω–æ–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã –∏–∑ attrs
            if not table_num_raw:
                attrs = tbl_meta.get("attrs") or {}
                for key in ("caption_num", "num", "number", "label"):
                    if key in attrs and attrs[key]:
                        candidate = str(attrs[key]).strip()
                        if _same_chapter(fig_num, candidate):
                            table_num_raw = candidate
                        break

            # –µ—Å–ª–∏ –Ω–æ–º–µ—Ä —É–¥–∞–ª–æ—Å—å –≤—ã—Ç–∞—â–∏—Ç—å –∏ –≥–ª–∞–≤–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—É—Ç—å
            if table_num_raw:
                try:
                    snippets = get_table_context_for_numbers(
                        owner_id=uid,
                        doc_id=doc_id,
                        numbers=[table_num_raw],
                        include_all_values=True,
                        rows_limit=None,
                    )
                except Exception as e:
                    logging.exception(
                        "figure->table: get_table_context_for_numbers failed (nearest): %s",
                        e,
                    )

            # –µ—Å–ª–∏ –ø–æ –Ω–æ–º–µ—Ä—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏, —Ö–æ—Ç—è —Ç–∞–±–ª–∏—Ü–∞ –µ—Å—Ç—å ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë text –∫–∞–∫ —Å—ã—Ä–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            if not snippets:
                full_ctx = (tbl_meta.get("text") or "").strip() or None

    # 5) –µ—Å–ª–∏ –µ—Å—Ç—å snippets ‚Äî —Å–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–∏—Ö
    if snippets and not full_ctx:
        try:
            full_ctx = build_rag_context(snippets, max_chars=2000) or None
        except Exception as e:
            logging.exception("figure->table: build_rag_context failed: %s", e)
            full_ctx = None

    if not full_ctx or not full_ctx.strip():
        return

    # 5.a) sanity-check: —Ç–∞–±–ª–∏—Ü–∞ –≤–æ–æ–±—â–µ –≤—ã–≥–ª—è–¥–∏—Ç —á–∏—Å–ª–æ–≤–æ–π?
    try:
        if not _looks_like_numeric_table_text(full_ctx):
            # –Ω–µ –º—É—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å—Ç—Ä–∞–Ω–Ω–æ–π "—Ç–∞–±–ª–∏—Ü–µ–π" –±–µ–∑ —Ü–∏—Ñ—Ä
            return
    except Exception:
        # –µ—Å–ª–∏ —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ —É–ø–∞–ª–∞ ‚Äî –Ω–µ —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ –±–ª–æ–∫–µ—Ä–æ–º
        pass

    # 6) –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –≤—ã–≤–æ–¥–∞ –ø–æ —Ä–∏—Å—É–Ω–∫—É
    try:
        formatted = _format_table_values_for_figure(table_num_raw or "?", full_ctx)
    except Exception:
        # –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ª–æ–º–∞–ª–æ—Å—å ‚Äî —Ö–æ—Ç—è –±—ã —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
        formatted = full_ctx

    rec["values_text"] = formatted
    rec["values_source"] = "table"
    rec["values"] = formatted
    if table_num_raw:
        rec["source_table_num"] = table_num_raw

# --- —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è "–º–æ—Å—Ç–∞" —Ä–∏—Å—É–Ω–æ–∫ ‚Üî —Ç–∞–±–ª–∏—Ü–∞ ---

# –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –ª–µ–≥–∫–æ –ø–æ–Ω—è—Ç—å, —á—Ç–æ —Ä–µ—á—å –æ —á–∏—Å–ª–æ–≤–æ–π –¥–∏–∞–≥—Ä–∞–º–º–µ/–¥–∏–Ω–∞–º–∏–∫–µ
_NUMERIC_FIGURE_KEYWORDS = [
    "–¥–∏–Ω–∞–º–∏–∫",      # –¥–∏–Ω–∞–º–∏–∫–∞, –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π
    "–≥—Ä–∞—Ñ–∏–∫",
    "–¥–∏–∞–≥—Ä–∞–º",
    "—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏",
    "—Å–æ—Å—Ç–∞–≤",
    "—É–¥–µ–ª—å–Ω",
    "–æ–±—ä–µ–º",
    "–æ–±—ä—ë–º",
    "–≤—ã—Ä—É—á–∫",
    "–∑–∞—Ç—Ä–∞—Ç",
    "–¥–æ—Ö–æ–¥",
    "–ø—Ä–∏–±—ã–ª",
]


def _is_numeric_chart_figure_text(text: str) -> bool:
    """
    –û—á–µ–Ω—å –ø—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –ø–æ –ø–æ–¥–ø–∏—Å–∏/–∫–æ–Ω—Ç–µ–∫—Å—Ç—É –≤–æ–∫—Ä—É–≥ —Ä–∏—Å—É–Ω–∫–∞ —Ä–µ—à–∞–µ–º,
    —á—Ç–æ —ç—Ç–æ –∏–º–µ–Ω–Ω–æ —á–∏—Å–ª–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞, –∞ –Ω–µ –æ—Ä–≥—Å—Ç—Ä—É–∫—Ç—É—Ä–∞/—Å—Ö–µ–º–∞/–∫–∞—Ä—Ç–∏–Ω–∫–∞ —Å —Ç–µ–∫—Å—Ç–æ–º.

    –ù–µ –ª–µ–∑–µ–º –≤ –ë–î, —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ —Å—Ç—Ä–æ–∫–µ.
    """
    if not text:
        return False

    t = text.lower()

    has_kw = any(k in t for k in _NUMERIC_FIGURE_KEYWORDS)
    has_digit = bool(re.search(r"\d", t))
    has_percent = "%" in t
    has_money = "—Ä—É–±" in t or "—Ç—ã—Å. —Ä—É–±" in t

    # –¥–æ–≤–æ–ª—å–Ω–æ –º—è–≥–∫–æ–µ —É—Å–ª–æ–≤–∏–µ:
    # - –ª–∏–±–æ –µ—Å—Ç—å "–¥–∏–Ω–∞–º–∏–∫–∞/–≥—Ä–∞—Ñ–∏–∫/–¥–∏–∞–≥—Ä–∞–º–º–∞/–∑–∞—Ç—Ä–∞—Ç—ã/–≤—ã—Ä—É—á–∫–∞/..." (—Ç–∏–ø–∏—á–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫),
    # - –ª–∏–±–æ —è–≤–Ω–æ –µ—Å—Ç—å —Ü–∏—Ñ—Ä—ã/–ø—Ä–æ—Ü–µ–Ω—Ç—ã/–¥–µ–Ω—å–≥–∏.
    if has_kw or has_digit or has_percent or has_money:
        return True

    return False


def _looks_like_numeric_table_text(ctx: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–∫—Å—Ç –ø–æ —Ç–∞–±–ª–∏—Ü–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø–æ—Ö–æ–∂ –Ω–∞ —á–∏—Å–ª–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É.
    –ù–µ –∏–¥–µ–∞–ª—å–Ω–æ, –Ω–æ –æ—Ç—Å–µ–∫–∞–µ—Ç —Å–æ–≤—Å–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —à—Ç—É–∫–∏.
    """
    if not ctx:
        return False

    txt = " ".join(l.strip() for l in ctx.splitlines() if l.strip())
    if not txt:
        return False

    digits = len(re.findall(r"\d", txt))
    letters = len(re.findall(r"[A-Za-z–ê-–Ø–∞-—è–Å—ë]", txt))

    # –º–∏–Ω–∏–º—É–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä
    if digits < 3:
        return False

    # –≥—Ä—É–±–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ: —Ü–∏—Ñ—Ä –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–æ–≤—Å–µ–º –º–∞–ª–æ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—Å—Ç–∞
    if letters > 0 and digits / max(letters, 1) < 0.05:
        return False

    return True



def _fig_values_text_from_records(
    records: list[dict],
    *,
    need_values: bool,
) -> str:
    """
    –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫ —Å —Ç–æ—á–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –ø–æ —Ä–∏—Å—É–Ω–∫–∞–º.
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
      1) rec.raw_values / rec.values_text (OOXML / —Ç–∞–±–ª–∏—Ü—ã);
      2) oox_fig_lookup (–≥–æ—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç).
    –§–æ—Ä–º–∞—Ç ‚Äî –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç, –±–µ–∑ Markdown-—Ä–∞–∑–º–µ—Ç–∫–∏.
    """
    lines: list[str] = []
    # —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –±–ª–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–¥–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è –¥–≤—É—Ö —Ä–∏—Å—É–Ω–∫–æ–≤)
    seen_blocks: set[tuple[str, str, str]] = set()

    for rec in records:
        # 1) –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç ‚Äî —Å—ã—Ä—ã–µ OOXML-–¥–∞–Ω–Ω—ã–µ
        raw = rec.get("raw_values")
        values_text = (rec.get("values_text") or rec.get("values") or "").strip()

        if raw and not values_text:
            values_text = _format_exact_values(raw)
            rec["values_text"] = values_text
            rec["values"] = values_text
            rec["values_source"] = rec.get("values_source") or "ooxml"

        # 2) –§–û–õ–ë–≠–ö: OOXML-–∏–Ω–¥–µ–∫—Å figure_lookup (–≥–æ—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç)
        if not values_text:
            try:
                doc_id = rec.get("doc_id")
                num = rec.get("orig") or rec.get("num")
                idx = _ooxml_get_index(doc_id) if doc_id else None
                body = ""

                if idx and "oox_fig_lookup" in globals() and num:
                    oox_res = oox_fig_lookup(idx, str(num))
                    if isinstance(oox_res, str):
                        body = oox_res.strip()
                    elif isinstance(oox_res, dict):
                        body = (
                            (oox_res.get("values_text")
                             or oox_res.get("text")
                             or "")
                        ).strip()

                if body:
                    values_text = body
                    rec["values_text"] = body
                    rec["values"] = body
                    rec["values_source"] = rec.get("values_source") or "ooxml_text"
            except Exception:
                pass

        if not values_text:
            continue

        disp = rec.get("display") or f"–†–∏—Å—É–Ω–æ–∫ {rec.get('num') or ''}".strip()
        src = (rec.get("values_source") or "").lower()
        tbl_num = (rec.get("source_table_num") or "").strip()

        # –∫–ª—é—á –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ (src + –Ω–æ–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã + —Å–∞–º —Ç–µ–∫—Å—Ç)
        block_key = (src or "?", tbl_num, values_text)
        if block_key in seen_blocks:
            continue
        seen_blocks.add(block_key)

        if src == "ooxml":
            title = f"{disp} ‚Äî —Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ)"
        elif src == "table":
            if tbl_num:
                title = f"{disp} ‚Äî –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —Ç–∞–±–ª–∏—Ü–µ {tbl_num} (–∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ)"
            else:
                title = f"{disp} ‚Äî –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —Å–≤—è–∑–∞–Ω–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ (–∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ)"
        elif src in {"summary", "vision", "rag"}:
            title = f"{disp} ‚Äî –∑–Ω–∞—á–µ–Ω–∏—è, —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –∏–ª–∏ —Å—É–º–º–∞—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ (–≤–æ–∑–º–æ–∂–Ω—ã –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç–∏)"
        else:
            title = f"{disp} ‚Äî –∑–Ω–∞—á–µ–Ω–∏—è"

        lines.append(f"{title}\n\n{values_text}")

    if lines:
        return "\n\n".join(lines)

    # üëá NEW: –µ—Å–ª–∏ —á–∏—Å–µ–ª –Ω–µ—Ç ‚Äî —Ä–µ—à–∞–µ–º, –Ω–∞–¥–æ –ª–∏ –≤–æ–æ–±—â–µ –ø–∏—Å–∞—Ç—å —Ç–µ—Ö-—Å–æ–æ–±—â–µ–Ω–∏–µ
    textual_kinds = {
        "org_chart",
        "orgchart",
        "flowchart",
        "text_blocks",
        "schema",
        "scheme",
        "block_diagram",
        "structure",
    }

    has_numeric_figure = any(
        ((rec.get("figure_kind") or "").strip().lower() not in textual_kinds)
        for rec in (records or [])
    )

    # –¢–µ—Ö-—Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –¢–û–õ–¨–ö–û –µ—Å–ª–∏:
    #  - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—Å–∏–ª —á–∏—Å–ª–∞ (need_values=True)
    #  - –∏ —Å—Ä–µ–¥–∏ —Ä–∏—Å—É–Ω–∫–æ–≤ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω ¬´–Ω–æ—Ä–º–∞–ª—å–Ω—ã–π¬ª –≥—Ä–∞—Ñ–∏–∫/–¥–∏–∞–≥—Ä–∞–º–º–∞
    if need_values and has_numeric_figure:
        return (
            "–ü–æ —É–∫–∞–∑–∞–Ω–Ω—ã–º —Ä–∏—Å—É–Ω–∫–∞–º –Ω–µ —É–¥–∞–ª–æ—Å—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–≤–ª–µ—á—å —Ç–æ—á–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ "
            "(–Ω–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö OOXML-–¥–∞–Ω–Ω—ã—Ö, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü –∏–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø–æ –∫–∞—Ä—Ç–∏–Ω–∫–∞–º). "
            "–ú–æ–≥—É –¥–∞—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ."
        )

    # –î–ª—è —Å—Ö–µ–º/–æ—Ä–≥—Å—Ç—Ä—É–∫—Ç—É—Ä –±–µ–∑ —á–∏—Å–µ–ª ‚Äî –ø—Ä–æ—Å—Ç–æ –º–æ–ª—á–∏–º, –ø—É—Å—Ç—å –±—É–¥–µ—Ç —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
    return ""


async def _send_fig_values_from_records(
    m: types.Message,
    records: list[dict],
    *,
    need_values: bool,
) -> None:
    """
    –û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –æ—Ç–¥–µ–ª—å–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–∞.
    –í –æ—Å–Ω–æ–≤–Ω–æ–º —Å—Ü–µ–Ω–∞—Ä–∏–∏ —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ–º _fig_values_text_from_records
    –∏ —Å–∫–ª–µ–∏–≤–∞–µ–º —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º.
    """
    text = _fig_values_text_from_records(records, need_values=need_values)
    if text:
        await _send(m, text)


async def _explain_figures_with_gpt(
    m: types.Message,
    records: list[dict],
    question: str,
    *,
    verbosity: str,
    need_values: bool,
    values_prefix: str = "",
) -> None:
    """
    –§–∏–Ω–∞–ª—å–Ω—ã–π —à–∞–≥: GPT –¥–∞—ë—Ç —Å–≤—è–∑–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º —Ä–∏—Å—É–Ω–∫–∞–º —Å—Ä–∞–∑—É,
    –∏—Å–ø–æ–ª—å–∑—É—è –ø–æ–¥–ø–∏—Å–∏, —Ç–µ–∫—Å—Ç —Ä—è–¥–æ–º –∏ —É–∂–µ –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ.

    –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω values_prefix, —Ç–æ –æ–Ω –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –≤ –Ω–∞—á–∞–ª–æ –æ—Ç–≤–µ—Ç–∞:
    —Å–Ω–∞—á–∞–ª–∞ –±–ª–æ–∫ ¬´—Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è¬ª, –∑–∞—Ç–µ–º –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è.
    """
    if not (chat_with_gpt or chat_with_gpt_stream):
        return

    if not records:
        return

    # 1) –°–æ–±–∏—Ä–∞–µ–º –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ –∫–∞–∂–¥–æ–º—É —Ä–∏—Å—É–Ω–∫—É
    ctx_blocks: list[str] = []
    for idx, rec in enumerate(records, start=1):
        disp = rec.get("display") or f"–†–∏—Å—É–Ω–æ–∫ {rec.get('num') or ''}".strip()
        num = (rec.get("orig") or rec.get("num") or "").strip()

        header = f"–†–∏—Å—É–Ω–æ–∫ {idx}: {disp}"
        if num:
            header += f" (–Ω–æ–º–µ—Ä –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ: {num})"

        parts: list[str] = [header]

        caption = (rec.get("caption") or "").strip()
        if caption:
            parts.append(f"–ü–æ–¥–ø–∏—Å—å –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ: {caption}")

        near_list = rec.get("near_text") or []
        if near_list:
            parts.append("–¢–µ–∫—Å—Ç —Ä—è–¥–æ–º —Å —Ä–∏—Å—É–Ω–∫–æ–º: " + " ".join(near_list[:2]))

        vision_desc = (rec.get("vision_desc") or "").strip()
        if vision_desc:
            parts.append("–û–ø–∏—Å–∞–Ω–∏–µ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (vision): " + vision_desc)

        values_text = (rec.get("values_text") or rec.get("values") or "").strip()
        if values_text:
            parts.append("–¢–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ):\n" + values_text)

        # JSON —Å raw_values –Ω–µ –ø–µ—Ä–µ–¥–∞—ë–º, —á—Ç–æ–±—ã –Ω–µ —Ä–∞–∑–¥—É–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –Ω–µ —Ä–æ–Ω—è—Ç—å –æ—Ç–≤–µ—Ç –ø–æ –¥–ª–∏–Ω–µ

        ctx_blocks.append("\n".join(parts))

    ctx = "\n\n---\n\n".join(ctx_blocks)
    if not ctx.strip():
        return

    focus = (
        "—Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ —Ç–æ—á–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏ –∏—Ö –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é"
        if need_values
        else "–ø–æ–¥—Ä–æ–±–Ω–æ –ø–æ—è—Å–Ω—è—è —Å–º—ã—Å–ª –∏ –≤—ã–≤–æ–¥—ã –ø–æ —Ä–∏—Å—É–Ω–∫–∞–º"
    )

    system_prompt = (
        "–¢—ã —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ –¥–∏–ø–ª–æ–º–Ω—ã–º —Ä–∞–±–æ—Ç–∞–º. –í –≠–¢–û–ú –≤—ã–∑–æ–≤–µ —Ç—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å —Ç–æ–ª—å–∫–æ —Ä–∏—Å—É–Ω–∫–∏ "
        "(–¥–∏–∞–≥—Ä–∞–º–º—ã, –≥—Ä–∞—Ñ–∏–∫–∏, —Å—Ö–µ–º—ã, –æ—Ä–≥—Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –±–ª–æ–∫-—Å—Ö–µ–º—ã) –∏–∑ –¥–∏–ø–ª–æ–º–∞.\n"
        "–¢–µ–±–µ —É–∂–µ –¥–∞–Ω—ã –ø–æ–¥–ø–∏—Å–∏, –±–ª–∏–∂–∞–π—à–∏–π —Ç–µ–∫—Å—Ç, –æ–ø–∏—Å–∞–Ω–∏—è –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (vision) –∏, –≥–¥–µ –µ—Å—Ç—å, "
        "—Ç–æ—á–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –µ—Å—Ç—å: –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã–µ —á–∏—Å–ª–∞, "
        "–Ω–µ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–π –ø—Ä–æ—Ü–µ–Ω—Ç—ã –∏ –Ω–µ –ø—ã—Ç–∞–π—Å—è –Ω–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å—É–º–º—ã –¥–æ 100%. –ù–µ —Å—Å—ã–ª–∞–π—Å—è –Ω–∞ –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü.\n"
        "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –ø—Ä–µ–¥–º–µ—Ç–Ω—É—é –æ–±–ª–∞—Å—Ç—å –∏ —Ç–µ—Ä–º–∏–Ω—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ–¥–∞–∂–∏, –∫–ª–∏–µ–Ω—Ç—ã, –≤—ã—Ä—É—á–∫–∞, "
        "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ —Ç.–ø.), –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —É–ø–æ–º—è–Ω—É—Ç—ã –≤ –ø–æ–¥–ø–∏—Å—è—Ö –∏–ª–∏ —Ç–µ–∫—Å—Ç–µ —Ä—è–¥–æ–º —Å —Ä–∏—Å—É–Ω–∫–æ–º.\n"
        "–ï—Å–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ —É—á–∞—Å—Ç–≤—É—é—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∏—Å—É–Ω–∫–æ–≤, –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û —Ä–∞–∑–±–∏—Ä–∞–π –∫–∞–∂–¥—ã–π –∏–∑ –Ω–∏—Ö "
        "–æ—Ç–¥–µ–ª—å–Ω—ã–º –ø–æ–¥–ø—É–Ω–∫—Ç–æ–º."
    )

    # 2) –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å + —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞
    user_prompt = (
        f"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {question}\n\n"
        "–í—ã—à–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ —Å–ª—É–∂–µ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Ä–∏—Å—É–Ω–∫–∞–º (–ø–æ–¥–ø–∏—Å–∏, —Ç–µ–∫—Å—Ç —Ä—è–¥–æ–º, –æ–ø–∏—Å–∞–Ω–∏—è –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é, "
        "—Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å). –ß–∏—Å–ª–∞ –∏ –ø—Ä–æ—Ü–µ–Ω—Ç—ã —É–∂–µ –¥–∞–Ω—ã –≤ —ç—Ç–∏—Ö –±–ª–æ–∫–∞—Ö. "
        "–ù–ï –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–π –≤—Å—é —Ç–∞–±–ª–∏—Ü—É —Ü–µ–ª–∏–∫–æ–º –∏ –ù–ï –∏–∑–º–µ–Ω—è–π –ø—Ä–æ—Ü–µ–Ω—Ç—ã.\n\n"
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–º—ã—Å–ª–æ–≤–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:\n"
        "‚Ä¢ —á—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Ä–∏—Å—É–Ω–∫–∏;\n"
        "‚Ä¢ –∫–∞–∫–∏–µ —É—Ä–æ–≤–Ω–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –≤—ã—à–µ/–Ω–∏–∂–µ (–µ—Å–ª–∏ –µ—Å—Ç—å —á–∏—Å–ª–∞);\n"
        "‚Ä¢ –∫–∞–∫–∏–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ –∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–∏–¥–Ω—ã;\n"
        "‚Ä¢ –∫–∞–∫–∏–µ –≤—ã–≤–æ–¥—ã –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å.\n\n"
        "–û–°–û–ë–ï–ù–ù–û –í–ê–ñ–ù–û: –µ—Å–ª–∏ —Ä–∏—Å—É–Ω–æ–∫ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Å—Ö–µ–º–∞–º, –æ—Ä–≥—Å—Ç—Ä—É–∫—Ç—É—Ä–∞–º, –±–ª–æ–∫-—Å—Ö–µ–º–∞–º –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–º "
        "—Ä–∏—Å—É–Ω–∫–∞–º –ë–ï–ó —á–∏—Å–ª–æ–≤—ã—Ö —Ä—è–¥–æ–≤, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (vision) –∏ –ø–æ–¥–ø–∏—Å—è–º –Ø–í–ù–û "
        "–ø–µ—Ä–µ—Å–∫–∞–∑–∞—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–ª–æ–∫–æ–≤/–ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π —Å–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏: –∫–∞–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã –µ—Å—Ç—å, –∫–∞–∫ –æ–Ω–∏ "
        "–Ω–∞–∑—ã–≤–∞—é—Ç—Å—è –∏ –∫–∞–∫ —Å–≤—è–∑–∞–Ω—ã –º–µ–∂–¥—É —Å–æ–±–æ–π. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–∞–∑–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ.\n\n"
        "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π, –∫ –∫–∞–∫–æ–π –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –æ—Ç–Ω–æ—Å—è—Ç—Å—è –¥–∞–Ω–Ω—ã–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ–¥–∞–∂–∏, –∫–ª–∏–µ–Ω—Ç—ã, —Ä—ã–Ω–æ–∫, "
        "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ —Ç.–ø.), –µ—Å–ª–∏ —ç—Ç–æ —è–≤–Ω–æ –Ω–µ —É–∫–∞–∑–∞–Ω–æ –≤ –ø–æ–¥–ø–∏—Å—è—Ö –∏–ª–∏ —Ç–µ–∫—Å—Ç–µ —Ä—è–¥–æ–º. –ï—Å–ª–∏ –ø–æ —Ä–∏—Å—É–Ω–∫–∞–º "
        "–Ω–µ–ø–æ–Ω—è—Ç–Ω–æ, –∫ —á–µ–º—É –æ—Ç–Ω–æ—Å—è—Ç—Å—è –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏, –ø—Ä—è–º–æ –Ω–∞–ø–∏—à–∏, —á—Ç–æ –ø—Ä–µ–¥–º–µ—Ç–Ω–∞—è –æ–±–ª–∞—Å—Ç—å –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ —É–∫–∞–∑–∞–Ω–∞.\n\n"
        "–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:\n"
        "1) –ï—Å–ª–∏ –≤ –Ω–∞—á–∞–ª–µ –æ—Ç–≤–µ—Ç–∞ –µ—Å—Ç—å –±–ª–æ–∫ —Å —Ç–æ—á–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ (—Ç–∞–±–ª–∏—Ü–∞/—Å–ø–∏—Å–æ–∫), –Ω–∞—á–Ω–∏ —Å 1‚Äì3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π "
        "–∫—Ä–∞—Ç–∫–æ–≥–æ –æ–±—â–µ–≥–æ –≤—ã–≤–æ–¥–∞ –ø–æ –¥–∏–Ω–∞–º–∏–∫–µ/—Å—Ç—Ä—É–∫—Ç—É—Ä–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–∏—Ö —á–∏—Å–µ–ª (–±–µ–∑ –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏—è –≤—Å–µ–π —Ç–∞–±–ª–∏—Ü—ã).\n"
        "2) –î–∞–ª–µ–µ –ø–æ –ö–ê–ñ–î–û–ú–£ —Ä–∏—Å—É–Ω–∫—É —Å–¥–µ–ª–∞–π –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø–æ–¥–ø—É–Ω–∫—Ç –≤ —Ç–∞–∫–æ–º –≤–∏–¥–µ:\n"
        "   ‚Ä¢ –ó–∞–≥–æ–ª–æ–≤–æ–∫: ¬´–†–∏—Å—É–Ω–æ–∫ X.Y. ‚Ä¶¬ª –∏–ª–∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ.\n"
        "   ‚Ä¢ 2‚Äì4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: —á—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∏—Å—É–Ω–æ–∫, –∫–∞–∫–∏–µ —Ç—Ä–µ–Ω–¥—ã/–∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–∏–¥–Ω–æ –∏–º–µ–Ω–Ω–æ –Ω–∞ –Ω—ë–º "
        "     (–∏–ª–∏ –∫–∞–∫–∏–µ –±–ª–æ–∫–∏/–ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∏ —Å–≤—è–∑–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω—ã, –µ—Å–ª–∏ —ç—Ç–æ —Å—Ö–µ–º–∞/–æ—Ä–≥—Å—Ç—Ä—É–∫—Ç—É—Ä–∞).\n"
        "   ‚Ä¢ 1‚Äì2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤—ã–≤–æ–¥–æ–≤ –ø–æ —Å–º—ã—Å–ª—É.\n"
        "–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–π–¥–∏ –ø–æ –≤—Å–µ–º —Ä–∏—Å—É–Ω–∫–∞–º, –∫–æ—Ç–æ—Ä—ã–µ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã –≤ —Å–ª—É–∂–µ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –ù–µ –ø—Ä–æ–ø—É—Å–∫–∞–π –Ω–∏ –æ–¥–∏–Ω.\n\n"
        f"–°–∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä—É–π—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö —Ä–∏—Å—É–Ω–∫–∞—Ö, –æ–ø–∏—à–∏ –∏—Ö —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –∏ —Å–¥–µ–ª–∞–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é {focus}.\n"
        f"{_verbosity_addendum(verbosity, '–æ–ø–∏—Å–∞–Ω–∏—è —Ä–∏—Å—É–Ω–∫–æ–≤')}"
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "assistant", "content": f"[–°–æ–±—Ä–∞–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–∏—Å—É–Ω–∫–∞—Ö]\n{ctx}"},
        {"role": "user", "content": user_prompt},
    ]

    try:
        ans = chat_with_gpt(messages, temperature=0.2, max_tokens=FINAL_MAX_TOKENS)
    except Exception as e:
        logging.exception("figure explanation failed: %s", e)
        ans = ""

    ans = (ans or "").strip()
    prefix = (values_prefix or "").strip()

    if prefix and ans:
        final = prefix + "\n\n" + ans
    elif prefix:
        final = prefix
    else:
        final = ans

    if final:
        await _send(m, _strip_unwanted_sections(final))


async def _answer_figure_query(
    m: types.Message, uid: int, doc_id: int, text: str, *, verbosity: str = "normal"
) -> bool:
    """
    –ù–æ–≤—ã–π –µ–¥–∏–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π:
    1) –≤—Å–µ–≥–¥–∞ –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º –ø–æ —Ä–∏—Å—É–Ω–∫–∞–º (_build_figure_records);
    2) —Å–æ–±–∏—Ä–∞–µ–º –±–ª–æ–∫–∏ —Å —Ç–æ—á–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –ø–æ –ö–ê–ñ–î–û–ú–£ —Ä–∏—Å—É–Ω–∫—É (–µ—Å–ª–∏ –µ—Å—Ç—å);
    3) –¥–∞—ë–º –ø–æ –∫–∞–∂–¥–æ–º—É —Ä–∏—Å—É–Ω–∫—É –ø–æ—è—Å–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ GPT + –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –±–ª–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π.

    –í–ê–ñ–ù–û: —Ç–µ–ø–µ—Ä—å –º—ã —Ä–∞–∑–¥–µ–ª—è–µ–º:
    - user_asked_values: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ø–í–ù–û –ø—Ä–æ—Å–∏–ª —á–∏—Å–ª–∞;
    - need_values_for_search: –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞, —á—Ç–æ–±—ã –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–µ–µ –∏—Å–∫–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã/OOXML.
    """

    # 0) –ø–æ —Ç–µ–∫—Å—Ç—É –∑–∞–ø—Ä–æ—Å–∞ ‚Äî –µ—Å—Ç—å –ª–∏ –Ø–í–ù–´–ô –Ω–∞–º—ë–∫ –Ω–∞ —á–∏—Å–ª–∞
    user_asked_values = bool(_VALUES_HINT.search(text or ""))

    # —ç—Ç–æ—Ç —Ñ–ª–∞–≥ –±—É–¥–µ–º –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –≤ _build_figure_records, –µ–≥–æ –º–æ–∂–Ω–æ —Ñ–æ—Ä—Å–∏—Ç—å —ç–≤—Ä–∏—Å—Ç–∏–∫–æ–π
    need_values_for_search = user_asked_values

    # 1) –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º –Ω–æ–º–µ—Ä–∞ —Ä–∏—Å—É–Ω–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞
    raw_list = _extract_fig_nums(text or "")
    seen: set[str] = set()
    nums: list[str] = []
    for token in raw_list:
        n = _num_norm_fig(token)
        if n and n not in seen:
            seen.add(n)
            # ‚¨áÔ∏è –í–ê–ñ–ù–û: —Ä–∞–±–æ—Ç–∞–µ–º –¥–∞–ª—å—à–µ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º –Ω–æ–º–µ—Ä–æ–º
            nums.append(n)


    if not nums:
        return False

    # üéØ –≠–í–†–ò–°–¢–ò–ö–ê –¢–û–õ–¨–ö–û –î–õ–Ø –ü–û–ò–°–ö–ê –ß–ò–°–ï–õ, –ù–ï –î–õ–Ø –°–û–û–ë–©–ï–ù–ò–ô –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Æ
    # –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å—Ç–æ ¬´–æ–ø–∏—à–∏ —Ä–∏—Å—É–Ω–æ–∫ 2.2¬ª, –Ω–æ –ø–æ OOXML –Ω–µ—Ç —Å—ã—Ä—ã—Ö —á–∏—Å–µ–ª ‚Äî
    # –º–æ–∂–Ω–æ —Ñ–æ—Ä—Å–Ω—É—Ç—å need_values_for_search=True, —á—Ç–æ–±—ã –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–µ–µ –∏—Å–∫–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã.
    if not need_values_for_search:
        try:
            for token in nums:
                n = _num_norm_fig(token)
                if not n:
                    continue
                rec_row = _fetch_figure_row_by_num(uid, doc_id, n)
                if not rec_row:
                    continue
                attrs_json = rec_row["attrs"] if ("attrs" in rec_row.keys()) else None
                raw = _extract_raw_values_from_attrs(attrs_json)
                # –µ—Å–ª–∏ —Å—ã—Ä—ã—Ö —á–∏—Å–µ–ª –Ω–µ—Ç ‚Äî –ª—É—á—à–µ –≤–∫–ª—é—á–∏—Ç—å –ø–æ–∏—Å–∫ —Ç–∞–±–ª–∏—Ü
                if not raw:
                    need_values_for_search = True
                    break
        except Exception:
            # –Ω–µ —Å—á–∏—Ç–∞–µ–º –ø–∞–¥–µ–Ω–∏–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ —Ñ–∞—Ç–∞–ª—å–Ω—ã–º
            pass

    # 2) —Å–æ–±–∏—Ä–∞–µ–º –µ–¥–∏–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–æ –≤—Å–µ–º —Ä–∏—Å—É–Ω–∫–∞–º (—Å—é–¥–∞ –ø–µ—Ä–µ–¥–∞—ë–º –í–ù–£–¢–†–ï–ù–ù–ò–ô —Ñ–ª–∞–≥)
    records = _build_figure_records(uid, doc_id, nums, need_values=need_values_for_search)
    if not records:
        return False

    # 3) –ø–æ –∫–∞–∂–¥–æ–º—É —Ä–∏—Å—É–Ω–∫—É –æ—Ç–¥–µ–ª—å–Ω–æ: –ø–æ—è—Å–Ω–µ–Ω–∏–µ + –µ–≥–æ –±–ª–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π
        # 3) –ø–æ –∫–∞–∂–¥–æ–º—É —Ä–∏—Å—É–Ω–∫—É –æ—Ç–¥–µ–ª—å–Ω–æ: –ø–æ—è—Å–Ω–µ–Ω–∏–µ + –µ–≥–æ –±–ª–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π
    for rec in records:
        num = rec.get("num")
        if not num:
            continue

        try:
            # ‚¨áÔ∏è –ü–µ—Ä–µ–¥–∞—ë–º rec –≤–Ω—É—Ç—Ä—å, —á—Ç–æ–±—ã GPT-–æ–ø–∏—Å–∞–Ω–∏–µ –∂—ë—Å—Ç–∫–æ –æ–ø–∏—Ä–∞–ª–æ—Å—å
            # –Ω–∞ —É–∂–µ –Ω–∞–π–¥–µ–Ω–Ω—É—é –∫–∞—Ä—Ç–æ—á–∫—É, –∞ –Ω–µ –Ω–∞ –∑–∞–Ω–æ–≤–æ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
            explanation = await _describe_figure_for_multi(
                uid,
                doc_id,
                num,
                text,
                verbosity,
                rec=rec,
            )
        except Exception as e:
            logging.exception("describe_figure_for_multi failed in _answer_figure_query: %s", e)
            explanation = ""


        if not explanation:
            continue

        # –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ä–∏—Å—É–Ω–∫–∞
        fig_kind = (rec.get("figure_kind") or "").strip().lower()
        textual_kinds = {
            "org_chart",
            "orgchart",
            "flowchart",
            "text_blocks",
            "schema",
            "scheme",
            "block_diagram",
            "structure",
        }

        # üëâ –í–ê–ñ–ù–û:
        # user_asked_values ‚Äî "–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–æ—Å–∏–ª —á–∏—Å–ª–∞",
        # –∞ –Ω–µ "–º—ã –≤–Ω—É—Ç—Ä–∏ —Ö–æ—Ç–∏–º –ø–æ–∏—Å–∫–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É".
        # –î–ª—è —Å—Ö–µ–º/–æ—Ä–≥—Å—Ç—Ä—É–∫—Ç—É—Ä –Ω–µ –ø—Ä–æ—Å–∏–º —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–∞–∂–µ –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏—Ö —Ö–æ—Ç–µ–ª.
        need_values_for_message = user_asked_values and (fig_kind not in textual_kinds)

        # üî¢ –î–ª—è —ç—Ç–æ–≥–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞ —Å–æ–±–∏—Ä–∞–µ–º –µ–≥–æ "–¢–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è"
        per_values_block = _fig_values_text_from_records(
            [rec],
            need_values=need_values_for_message,
        )

        if per_values_block:
            explanation = explanation.rstrip() + "\n\n" + per_values_block.strip()

        await m.answer(explanation)

    # 6) –æ–±–Ω–æ–≤–ª—è–µ–º ¬´–ø–æ—Å–ª–µ–¥–Ω–∏–π —É–ø–æ–º—è–Ω—É—Ç—ã–π —Ä–∏—Å—É–Ω–æ–∫¬ª –¥–ª—è –∞–Ω–∞—Ñ–æ—Ä–∏—á–µ—Å–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
    try:
        LAST_REF.setdefault(uid, {})["figure_nums"] = [r["num"] for r in records]
    except Exception:
        pass

    return True



def _ooxml_table_block(uid: int, doc_id: int, num: str) -> str | None:
    """
    1) –ü—ã—Ç–∞–µ–º—Å—è –≤–∑—è—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –∏–∑ OOXML-–∏–Ω–¥–µ–∫—Å–∞ —á–µ—Ä–µ–∑ oox_tbl_lookup.
    2) –ï—Å–ª–∏ —Ç–∞–º –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –ø–∞–¥–∞–µ–º –≤ –æ–±—ã—á–Ω—ã–µ chunks (table/table_row) –∏
       —Å–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç —Ç–∞–±–ª–∏—Ü—ã –ø–æ —Å—Ç—Ä–æ–∫–∞–º. –≠—Ç–æ –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç –≥–ª—é–∫–æ–≤ OOXML-–ø–∞—Ä—Å–µ—Ä–∞.
    """

    # –º–∞–ª–µ–Ω—å–∫–∏–π –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ö–µ–ª–ø–µ—Ä: –∫—Ä–∞—Å–∏–≤–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º rows ‚Üí —Ç–µ–∫—Å—Ç–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É
    def _format_oox_rows(res: dict) -> str:
        rows = res.get("rows") or []
        lines: list[str] = []
        for row in rows:
            if not isinstance(row, (list, tuple)):
                continue
            cells = [(str(c) if c is not None else "").strip() for c in row]
            # –ø—É—Å—Ç—ã–µ —Ö–≤–æ—Å—Ç–æ–≤—ã–µ —è—á–µ–π–∫–∏ —É–±–∏—Ä–∞–µ–º
            while cells and cells[-1] == "":
                cells.pop()
            lines.append(" | ".join(cells))
        return "\n".join(lines).strip()

    # --- 1. OOXML ---
    idx = _ooxml_get_index(doc_id)
    if idx and "oox_tbl_lookup" in globals():
        try:
            res = oox_tbl_lookup(idx, str(num))
        except Exception:
            res = None

        if res is not None:
            if isinstance(res, str):
                body = res.strip()
            elif isinstance(res, dict) and "rows" in res:
                # –ù–û–†–ú–ê–õ–¨–ù–û–ï —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
                body = _format_oox_rows(res)
            else:
                # –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç: –µ—Å–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è ‚Äî –ø—Ä–æ—Å—Ç–æ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º
                try:
                    body = json.dumps(res, ensure_ascii=False, indent=2)
                except Exception:
                    body = str(res)

            body = (body or "").strip()
            if body:
                # –º–µ–Ω—è–µ–º –ø–æ–¥–ø–∏—Å—å, —Ç.–∫. —Ç–µ–ø–µ—Ä—å —ç—Ç–æ –Ω–µ ¬´—Å—ã—Ä–æ–π JSON¬ª, –∞ –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
                return f"–¢–∞–±–ª–∏—Ü–∞ {num} (–∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ):\n{body}"

    # --- 2. –§–æ–ª–±—ç–∫: chunks –∏–∑ –ë–î ---
    con = get_conn()
    cur = con.cursor()

    has_et   = _table_has_columns(con, "chunks", ["element_type"])
    has_attr = _table_has_columns(con, "chunks", ["attrs"])

    rows = []

    try:
        if has_attr and has_et:
            like1 = f'%\"caption_num\": \"{num}\"%'
            like2 = f'%\"label\": \"{num}\"%'
            cur.execute(
                """
                SELECT section_path, text
                FROM chunks
                WHERE owner_id=? AND doc_id=?
                  AND element_type IN ('table','table_row')
                  AND (attrs LIKE ? OR attrs LIKE ?)
                ORDER BY id ASC
                """,
                (uid, doc_id, like1, like2),
            )
            rows = cur.fetchall() or []

        if not rows:
            # —Ñ–æ–ª–±—ç–∫ –ø–æ section_path / —Ç–µ–∫—Å—Ç—É, —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–∞–∂–µ –Ω–∞ —Å—Ç–∞—Ä—ã—Ö –∏–Ω–¥–µ–∫—Å–∞—Ö
            variants = _table_num_variants(num)
            sec_patterns = []
            txt_patterns = []

            for v in variants:
                # "–¢–∞–±–ª–∏—Ü–∞ 6", "—Ç–∞–±–ª–∏—Ü–∞ 6", "—Ç–∞–±–ª. 6"
                sec_patterns.append(f"%–¢–∞–±–ª–∏—Ü–∞ {v}%")
                sec_patterns.append(f"%—Ç–∞–±–ª–∏—Ü–∞ {v}%")
                sec_patterns.append(f"%—Ç–∞–±–ª. {v}%")
                # —Ç–µ–∫—Å—Ç–æ–≤—ã–π –≤–∞—Ä–∏–∞–Ω—Ç —Ç–∏–ø–∞ "[–¢–∞–±–ª–∏—Ü–∞] 6" –∏ "[—Ç–∞–±–ª.] 6"
                txt_patterns.append(f"[–¢–∞–±–ª–∏—Ü–∞]%{v}%")
                txt_patterns.append(f"[—Ç–∞–±–ª.]%{v}%")

            if not sec_patterns and not txt_patterns:
                rows = []
            else:
                conds_sec = " OR ".join(["section_path LIKE ? COLLATE NOCASE"] * len(sec_patterns)) if sec_patterns else "0"
                conds_txt = " OR ".join(["text LIKE ? COLLATE NOCASE"] * len(txt_patterns)) if txt_patterns else "0"

                sql = f"""
                    SELECT section_path, text
                    FROM chunks
                    WHERE owner_id=? AND doc_id=?
                      AND ( ({conds_sec}) OR ({conds_txt}) )
                    ORDER BY page ASC, id ASC
                """

                params = [uid, doc_id] + sec_patterns + txt_patterns
                cur.execute(sql, params)
                rows = cur.fetchall() or []
    finally:
        con.close()

    if not rows:
        return None

    sec = (rows[0]["section_path"] or "").strip()
    lines = []
    if sec:
        lines.append(f"[{sec}]")
    for r in rows:
        t = (r["text"] or "").strip()
        if t:
            lines.append(t)

    body = "\n".join(lines).strip()
    if not body:
        return None

    return f"–¢–∞–±–ª–∏—Ü–∞ {num} (–∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ, –ø–æ —Å—Ç—Ä–æ–∫–∞–º —Ç–∞–±–ª–∏—Ü—ã):\n{body}"


def _table_related_context(
    uid: int,
    doc_id: int,
    num: str,
    *,
    max_chars: int = 4000,
) -> str:
    """
    –ò—â–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π —Å–≤—è–∑–∞–Ω —Å —Ç–∞–±–ª–∏—Ü–µ–π `num`.

    1) –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –ø—Ä—è–º—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è ¬´—Ç–∞–±–ª–∏—Ü–∞ N¬ª (–∫—Ä–æ–º–µ —Å–∞–º–∏—Ö —è—á–µ–µ–∫ —Ç–∞–±–ª–∏—Ü—ã).
    2) –ï—Å–ª–∏ —Ç–∞–∫–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç ‚Äì –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∞–±–∑–∞—Ü(—ã) –≤–∏–¥–∞ ¬´–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ ‚Ä¶¬ª
       —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ —ç—Ç–æ–π —Ç–∞–±–ª–∏—Ü—ã.
    3) –ï—Å–ª–∏ –∏ —ç—Ç–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ ‚Äì –¥–µ–ª–∞–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É.
    """
    con = get_conn()
    cur = con.cursor()
    has_et = _table_has_columns(con, "chunks", ["element_type"])

    variants = _table_num_variants(num)
    txt_patterns: list[str] = []
    for v in variants:
        txt_patterns.append(f"%–¢–∞–±–ª–∏—Ü–∞ {v}%")
        txt_patterns.append(f"%—Ç–∞–±–ª–∏—Ü–∞ {v}%")
        txt_patterns.append(f"%—Ç–∞–±–ª. {v}%")

    if not txt_patterns:
        cur.close()
        con.close()
        return ""

    conds_txt = " OR ".join(["text LIKE ? COLLATE NOCASE"] * len(txt_patterns))

    if has_et:
        cur.execute(
            f"""
            SELECT page, section_path, text, element_type
            FROM chunks
            WHERE owner_id=? AND doc_id=?
              AND ({conds_txt})
            ORDER BY page ASC, id ASC
            """,
            (uid, doc_id, *txt_patterns),
        )
    else:
        cur.execute(
            f"""
            SELECT page, section_path, text
            FROM chunks
            WHERE owner_id=? AND doc_id=?
              AND ({conds_txt})
            ORDER BY page ASC, id ASC
            """,
            (uid, doc_id, *txt_patterns),
        )

    rows = cur.fetchall() or []
    con.close()

    parts: list[str] = []
    total = 0

    for r in rows:
        et = ""
        if "element_type" in r.keys():
            et = (r["element_type"] or "").lower()
        if et in ("table", "table_row"):
            continue

        t = (r["text"] or "").strip()
        if not t:
            continue

        if total + len(t) > max_chars:
            parts.append(t[: max_chars - total])
            break

        parts.append(t)
        total += len(t)

    extra = "\n\n".join(parts).strip()
    if extra:
        return extra

    # –ù–û–í–û–ï: –µ—Å–ª–∏ –ø—Ä—è–º—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π ¬´—Ç–∞–±–ª–∏—Ü–∞ N¬ª –Ω–µ—Ç,
    # –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ–¥–æ–±—Ä–∞—Ç—å ¬´–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ ‚Ä¶¬ª —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ —ç—Ç–æ–π —Ç–∞–±–ª–∏—Ü—ã.
    try:
        con = get_conn()
        cur = con.cursor()
        has_et = _table_has_columns(con, "chunks", ["element_type"])
        has_attr = _table_has_columns(con, "chunks", ["attrs"])

        base_row = None
        if has_attr and has_et:
            like1 = f'%\"caption_num\": \"{num}\"%'
            like2 = f'%\"label\": \"{num}\"%'
            cur.execute(
                """
                SELECT id, page, section_path, element_type, text
                FROM chunks
                WHERE owner_id=? AND doc_id=?
                  AND element_type IN ('table','table_row')
                  AND (attrs LIKE ? OR attrs LIKE ?)
                ORDER BY id ASC LIMIT 1
                """,
                (uid, doc_id, like1, like2),
            )
            base_row = cur.fetchone()

        if not base_row:
            cur.execute(
                """
                SELECT id, page, section_path, element_type, text
                FROM chunks
                WHERE owner_id=? AND doc_id=?
                  AND element_type IN ('table','table_row')
                  AND section_path LIKE ? COLLATE NOCASE
                ORDER BY id ASC LIMIT 1
                """,
                (uid, doc_id, f'%–¢–∞–±–ª–∏—Ü–∞ {num}%'),
            )
            base_row = cur.fetchone()

        note_text = ""
        if base_row:
            base_id = base_row["id"]
            page = base_row["page"]

            cur.execute(
                """
                SELECT text, element_type
                FROM chunks
                WHERE owner_id=? AND doc_id=? AND id>? AND page=?
                ORDER BY id ASC LIMIT 10
                """,
                (uid, doc_id, base_id, page),
            )
            note_parts: list[str] = []
            started = False
            for r in cur.fetchall() or []:
                et = (r["element_type"] or "").lower() if "element_type" in r.keys() else ""
                if et in ("heading", "table", "figure", "table_row"):
                    # –¥–∞–ª—å—à–µ —É–∂–µ –¥—Ä—É–≥–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
                    break
                t = (r["text"] or "").strip()
                if not t:
                    continue
                low = t.lower()
                if low.startswith("–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ"):
                    started = True
                    note_parts.append(t)
                    continue
                if started:
                    # —Ü–µ–ø–ª—è–µ–º —Ö–≤–æ—Å—Ç –ø—Ä–∏–º–µ—á–∞–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–æ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–±–∑–∞—Ü–µ–≤
                    note_parts.append(t)

            if note_parts:
                note_text = "\n".join(note_parts).strip()

        con.close()

        if note_text:
            return note_text
    except Exception:
        # –Ω–µ –ª–æ–º–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω, –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫
        pass

    # –≤—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥: —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É
    query = f"–ø–æ–¥—Ä–æ–±–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ—è—Å–Ω–µ–Ω–∏–µ, –∞–Ω–∞–ª–∏–∑ –∏ –≤—ã–≤–æ–¥—ã –ø–æ –¥–∞–Ω–Ω—ã–º —Ç–∞–±–ª–∏—Ü—ã {num}"
    try:
        ctx = best_context(
            uid,
            doc_id,
            query,
            max_chars=max_chars,
        ) or ""
    except Exception:
        ctx = ""

    return (ctx or "").strip()


async def _answer_table_query(
    m: types.Message,
    uid: int,
    doc_id: int,
    text: str,
    *,
    verbosity: str = "normal",
    mode: str = "normal",
) -> bool:
    """
    –°–ø–µ—Ü-–ø—É—Ç—å –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –≤–∏–¥–∞:
      - "–æ–ø–∏—à–∏ —Ç–∞–±–ª–∏—Ü—É 4"
      - "—á—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–∞–±–ª–∏—Ü–∞ 2.3"
      - "—Å–¥–µ–ª–∞–π –≤—ã–≤–æ–¥—ã –ø–æ —Ç–∞–±–ª–∏—Ü–µ 4"
      - –∏ —Ñ–æ–ª–ª–æ—É-–∞–ø–∞ "–æ–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ" –ø–æ —ç—Ç–æ–π –∂–µ —Ç–∞–±–ª–∏—Ü–µ (mode=\"more\").
    """
    nums = _extract_table_nums(text)
    if not nums:
        return False

    # –∑–∞–ø–æ–º–∏–Ω–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é(–∏–µ) —Ç–∞–±–ª–∏—Ü—É(—ã) –¥–ª—è —Ñ—Ä–∞–∑ —Ç–∏–ø–∞ ¬´–æ–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ¬ª
    try:
        LAST_REF.setdefault(uid, {})["table_nums"] = [
            n.replace(" ", "").replace(",", ".") for n in nums
        ]
    except Exception:
        pass

    blocks: list[str] = []
    missing: list[str] = []

    for n in nums:
        # 1) –æ–±—ã—á–Ω—ã–π –ø—É—Ç—å: —Ç–∞–±–ª–∏—Ü–∞ –∏–∑ OOXML
        blk = _ooxml_table_block(uid, doc_id, n)
        if blk:
            blocks.append(blk)
            continue

        # 1a) –ù–û–í–û–ï: –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ "—Ç–∞–±–ª–∏—Ü—É-—Ä–∏—Å—É–Ω–æ–∫" –∫–∞–∫ –¥–∏–∞–≥—Ä–∞–º–º—É/—Ä–∏—Å—É–Ω–æ–∫
        fig_records = _build_figure_records(uid, doc_id, [n])
        logging.info(
            "TAB[query] table %s as figure: %d records",
            n,
            len(fig_records) if fig_records else 0,
        )
        if fig_records:
            values_text = _fig_values_text_from_records(fig_records, need_values=True)
            if values_text:
                blocks.append(
                    f"–¢–∞–±–ª–∏—Ü–∞ {n} (–≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∞ –∫–∞–∫ –¥–∏–∞–≥—Ä–∞–º–º–∞/—Ä–∏—Å—É–Ω–æ–∫):\n"
                    f"{values_text}"
                )
                try:
                    LAST_REF.setdefault(uid, {})["figure_nums"] = [r["num"] for r in fig_records]
                except Exception:
                    pass
                continue

        # 2) fallback: –Ω–∞—Å—Ç–æ—è—â–∞—è OCR –ø–æ –∫–∞—Ä—Ç–∏–Ω–∫–µ (–µ—Å–ª–∏ –Ω–∏–∫–∞–∫–∏—Ö chart_data –Ω–µ—Ç)
        ocr_blk = _ocr_table_block_from_image(uid, doc_id, n)
        if ocr_blk:
            blocks.append(ocr_blk)
        else:
            missing.append(n)

    if not blocks:
        # –Ω–∏—á–µ–≥–æ –Ω–µ —Å–º–æ–≥–ª–∏ —Å–æ–±—Ä–∞—Ç—å –Ω–∏ –∏–∑ OOXML, –Ω–∏ –∏–∑ OCR/–¥–∏–∞–≥—Ä–∞–º–º
        bad = ", ".join(missing or nums)
        await _send(
            m,
            f"–¢–∞–±–ª–∏—Ü–∞ {bad} –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. "
            "–ü—Ä–æ–≤–µ—Ä—å, –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ª–∏ —É–∫–∞–∑–∞–Ω –Ω–æ–º–µ—Ä."
        )
        return True  # —Å—á–∏—Ç–∞–µ–º –∑–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º, –¥–∞–ª—å—à–µ –ø–æ –ø–∞–π–ø–ª–∞–π–Ω—É –Ω–µ –∏–¥—ë–º

    # –µ—Å–ª–∏ —á–∞—Å—Ç—å —Ç–∞–±–ª–∏—Ü –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ ‚Äî —è–≤–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ–º –æ–± —ç—Ç–æ–º –≤ –æ—Ç–≤–µ—Ç–µ
    if missing:
        blocks.append(
            "‚ö†Ô∏è –ü–æ —Å–ª–µ–¥—É—é—â–∏–º —Ç–∞–±–ª–∏—Ü–∞–º –¥–∞–Ω–Ω—ã—Ö –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: "
            + ", ".join(missing)
        )

    ctx_tables = "\n\n---\n\n".join(blocks)

    # –ë–ª–æ–∫, –∫–æ—Ç–æ—Ä—ã–π –í–°–ï–ì–î–ê –ø–æ–π–¥—ë—Ç –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é,
    # —á—Ç–æ–±—ã –æ–Ω –≤–∏–¥–µ–ª –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã —Ä–æ–≤–Ω–æ –≤ —Ç–æ–º –≤–∏–¥–µ, –∫–∞–∫ –º—ã –µ—ë —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–∏.
    raw_values_text = ""
    if ctx_tables:
        raw_values_text = (
            "**–í—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü (–∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ)**\n\n"
            f"{ctx_tables}"
        )

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º (–¥–ª—è –æ–±—ã—á–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ –∏ "–ø–æ–¥—Ä–æ–±–Ω–µ–µ")
    # –í –æ–±—ã—á–Ω–æ–º –æ—Ç–≤–µ—Ç–µ –±–µ—Ä—ë–º –ø–æ–º–µ–Ω—å—à–µ —Å–∏–º–≤–æ–ª–æ–≤, –≤ "–ø–æ–¥—Ä–æ–±–Ω–µ–µ" ‚Äî –ø–æ–±–æ–ª—å—à–µ.
    extra_ctx_parts: list[str] = []

    for n in nums:
        extra = _table_related_context(
            uid,
            doc_id,
            n,
            max_chars=4000 if mode == "more" else 2000,
        )
        if extra:
            extra_ctx_parts.append(
                f"[–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ —Ç–∞–±–ª–∏—Ü–µ {n}]\n{extra}"
            )

    extra_ctx = "\n\n---\n\n".join(extra_ctx_parts).strip()

    # –ï—Å–ª–∏ —ç—Ç–æ –∑–∞–ø—Ä–æ—Å ¬´–ø–æ–¥—Ä–æ–±–Ω–µ–µ¬ª, –Ω–æ –≤ —Å–∞–º–æ–π —Ä–∞–±–æ—Ç–µ –ù–ï–¢ –¥–æ–ø. —Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ —ç—Ç—É —Ç–∞–±–ª–∏—Ü—É,
    # –º—ã —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç [–º–æ–¥–µ–ª—å],
    # –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –æ–ø–∏—Ä–∞—Ç—å—Å—è –Ω–∞ –≠–¢–ò –¥–∞–Ω–Ω—ã–µ.
    if mode == "more" and not extra_ctx:
        nums_str = ", ".join(nums)
        MODEL_EXTRA_PENDING[uid] = {
            "kind": "table_more",
            # —Å–∞–º –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—á–∞—â–µ –≤—Å–µ–≥–æ ¬´–æ–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ (—Ç–∞–±–ª–∏—Ü–∞ N)¬ª)
            "question": text,
            # —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü –∏–∑ OOXML/–∫–∞—Ä—Ç–∏–Ω–∫–∏ ‚Äî —á—Ç–æ–±—ã [–º–æ–¥–µ–ª—å] –∏—Ö –≤–∏–¥–µ–ª–∞
            "ctx_tables": ctx_tables,
            "nums": nums,
            # –Ω—É–∂–µ–Ω, —á—Ç–æ–±—ã –ø–æ—Ç–æ–º –µ—â—ë —Ä–∞–∑ —Å—Ö–æ–¥–∏—Ç—å –≤ –¥–æ–∫—É–º–µ–Ω—Ç –∑–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            "doc_id": doc_id,
        }
        await _send(
            m,
            "–í —Å–∞–º–æ–π —Ä–∞–±–æ—Ç–µ –Ω–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–¥—Ä–æ–±–Ω–æ –æ–±—ä—è—Å–Ω—è–µ—Ç —ç—Ç—É —Ç–∞–±–ª–∏—Ü—É. "
            "–ú–æ–≥—É –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ, –∫–∞–∫ [–º–æ–¥–µ–ª—å], –ø–æ–¥—Ä–æ–±–Ω–æ –ø–æ—è—Å–Ω–∏—Ç—å –µ—ë, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ —Å–∞–º–∏ –¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã "
            "–∏ –æ–±—â–∏–µ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞–Ω–∏—è –ø–æ —Ç–µ–º–µ (–±–µ–∑ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–µ–∫—Å—Ç –í–ö–†). "
            "–ï—Å–ª–∏ –Ω—É–∂–Ω–æ ‚Äî –Ω–∞–ø–∏—à–∏ ¬´–¥–∞¬ª, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω–æ ‚Äî ¬´–Ω–µ—Ç¬ª."
        )
        return True


    # –û–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è GPT: —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü +, –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏, –¥–æ–ø. —Ç–µ–∫—Å—Ç
    full_ctx = ctx_tables
    if extra_ctx:
        full_ctx += "\n\n[–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ —Ä–∞–±–æ—Ç—ã –ø—Ä–æ —ç—Ç–∏ —Ç–∞–±–ª–∏—Ü—ã]\n" + extra_ctx

    system_prompt = (
        "–¢—ã —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ –¥–∏–ø–ª–æ–º–Ω—ã–º —Ä–∞–±–æ—Ç–∞–º. –ù–∏–∂–µ –¥–∞–Ω—ã —Ç–∞–±–ª–∏—Ü—ã, —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ –ø—Ä—è–º–æ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞.\n"
        "–û—Ç–≤–µ—á–∞–π –°–¢–†–û–ì–û –ø–æ —ç—Ç–∏–º –¥–∞–Ω–Ω—ã–º:\n"
        "‚Äî –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏, —Å—Ç–æ–ª–±—Ü—ã –∏ –∑–Ω–∞—á–µ–Ω–∏—è;\n"
        "‚Äî –Ω–µ –¥–æ–±–∞–≤–ª—è–π —Ñ–∞–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö;\n"
        "‚Äî –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –ø—Ä–µ–¥–º–µ—Ç–Ω—É—é –æ–±–ª–∞—Å—Ç—å –∏ —Ç–µ—Ä–º–∏–Ω—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ–¥–∞–∂–∏, –∫–ª–∏–µ–Ω—Ç—ã, –≤—ã—Ä—É—á–∫–∞, —Ä—ã–Ω–æ–∫, "
        "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ —Ç.–ø.), –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö, –ø–æ–¥–ø–∏—Å—è—Ö –∏–ª–∏ —Å—Ç—Ä–æ–∫–∞—Ö —Ç–∞–±–ª–∏—Ü;\n"
        "‚Äî –Ω–µ —Å—Å—ã–ª–∞—Ç—å—Å—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã, —Ç–æ–ª—å–∫–æ –æ–ø–∏—Å—ã–≤–∞–π —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ.\n"
        "–ï—Å–ª–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ —É–∫–∞–∑–∞–Ω –Ω–æ–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã, –Ω–æ —Ç–∞–∫–æ–π —Ç–∞–±–ª–∏—Ü—ã –Ω–µ—Ç –≤ –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ ‚Äî "
        "–Ω–∞–ø–∏—à–∏, —á—Ç–æ –ø–æ —ç—Ç–æ–º—É –Ω–æ–º–µ—Ä—É –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç.\n\n"
        "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞ –î–û–õ–ñ–ù–ê –±—ã—Ç—å —Ç–∞–∫–æ–π:\n"
        "1) –†–∞–∑–¥–µ–ª ¬´–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã¬ª ‚Äî –∫–æ—Ä–æ—Ç–∫–æ –æ–±—ä—è—Å–Ω–∏, —á—Ç–æ –ø–æ —Å—Ç—Ä–æ–∫–∞–º –∏ —á—Ç–æ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º.\n"
        "2) –†–∞–∑–¥–µ–ª ¬´–í—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è¬ª ‚Äî –≤—ã–ø–∏—à–∏ –í–°–ï —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –ë–ï–ó –ü–†–û–ü–£–°–ö–û–í.\n"
        "   –î–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–û—Ç—Ü—ã¬ª, ¬´–ú–∞—Ç–µ—Ä–∏¬ª, ¬´–û–±—â–µ–µ¬ª)\n"
        "   –Ω–∞–ø–∏—à–∏ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞:\n"
        "   ¬´–û—Ç—Ü—ã: 31,55; 26,85; 27,1; ‚Ä¶; 51,1¬ª ‚Äî –∑–Ω–∞—á–µ–Ω–∏—è –∏–¥—É—Ç —Å—Ç—Ä–æ–≥–æ –ø–æ –ø–æ—Ä—è–¥–∫—É —Å—Ç–æ–ª–±—Ü–æ–≤.\n"
        "   –ù–µ–ª—å–∑—è –æ–±—ä–µ–¥–∏–Ω—è—Ç—å —Å—Ç—Ä–æ–∫–∏ –∏ –Ω–µ–ª—å–∑—è –≤—ã–±—Ä–∞—Å—ã–≤–∞—Ç—å –∫–∞–∫–∏–µ-–ª–∏–±–æ —á–∏—Å–ª–∞.\n"
        "3) –†–∞–∑–¥–µ–ª ¬´–í—ã–≤–æ–¥—ã¬ª ‚Äî —Å–¥–µ–ª–∞–π –∞–∫–∫—É—Ä–∞—Ç–Ω—É—é –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é –∏ –≤—ã–≤–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö.\n"
        "–ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –∞–±–∑–∞—Ü, –Ω–∞—á–∏–Ω–∞—é—â–∏–π—Å—è —Å ¬´–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ¬ª, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–∏–≤–µ–¥–∏ –µ–≥–æ "
        "–æ—Ç–¥–µ–ª—å–Ω—ã–º –ø–æ–¥–ø—É–Ω–∫—Ç–æ–º ¬´–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ¬ª –∏ –Ω–µ —Å–æ–∫—Ä–∞—â–∞–π —Ç–µ–∫—Å—Ç."
    )


    # –í —Ä–µ–∂–∏–º–µ "–ø–æ–¥—Ä–æ–±–Ω–µ–µ" –ø—Ä—è–º–æ –≥–æ–≤–æ—Ä–∏–º, —á—Ç–æ –Ω—É–∂–µ–Ω –±–æ–ª–µ–µ —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π —Ä–∞–∑–±–æ—Ä
    if mode == "more":

        user_prompt = (
            f"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {text}\n\n"
            "–ù–∏–∂–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü –≤ –º–∞—à–∏–Ω–Ω–æ-—á–∏—Ç–∞–µ–º–æ–º –≤–∏–¥–µ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ —Ä–∞–±–æ—Ç—ã. "
            "–°–¥–µ–ª–∞–π –ë–û–õ–ï–ï –ü–û–î–†–û–ë–ù–´–ô —Ä–∞–∑–±–æ—Ä –ø–æ —ç—Ç–æ–π —Ç–∞–±–ª–∏—Ü–µ.\n\n"
            "–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ:\n"
            "‚Äî —Å—Ç—Ä–æ–≥–æ —Å–ª–µ–¥—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –æ—Ç–≤–µ—Ç–∞ –∏–∑ —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ "
            "(¬´–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã¬ª ‚Üí ¬´–í—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è¬ª ‚Üí ¬´–í—ã–≤–æ–¥—ã¬ª);\n"
            "‚Äî –≤ —Ä–∞–∑–¥–µ–ª–µ ¬´–í—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è¬ª –ø–µ—Ä–µ—á–∏—Å–ª–∏ –í–°–ï –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∏ –∏—Ö –∑–Ω–∞—á–µ–Ω–∏—è, –±–µ–∑ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π "
            "–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤ (–º–æ–∂–Ω–æ –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–æ–≤ –ø–æ –≥—Ä—É–ø–ø–∞–º/—Å—Ç—Ä–æ–∫–∞–º/—Å—Ç–æ–ª–±—Ü–∞–º);\n"
            "‚Äî –≤ —Ä–∞–∑–¥–µ–ª–µ ¬´–í—ã–≤–æ–¥—ã¬ª –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–π —Ä–∞–∑–ª–∏—á–∏—è –∏ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏, –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö."
            f"{_verbosity_addendum('detailed', '–ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã')}\n\n"
            "[–¢–∞–±–ª–∏—Ü—ã –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞]\n"
            f"{full_ctx}"
        )

    else:
        user_prompt = (
            f"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {text}\n\n"
            "–ù–∏–∂–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü –≤ –º–∞—à–∏–Ω–Ω–æ-—á–∏—Ç–∞–µ–º–æ–º –≤–∏–¥–µ. "
            "–û—Ç–≤–µ—Ç –æ—Ñ–æ—Ä–º–∏ –≤ —Ç—Ä–∏ —è–≤–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–∞: ¬´–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã¬ª, ¬´–í—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è¬ª, ¬´–í—ã–≤–æ–¥—ã¬ª.\n"
            "–°–Ω–∞—á–∞–ª–∞ –≤ —Ä–∞–∑–¥–µ–ª–µ ¬´–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã¬ª –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ –æ–±—ä—è—Å–Ω–∏, —á—Ç–æ –ø–æ —Å—Ç—Ä–æ–∫–∞–º –∏ —á—Ç–æ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º.\n"
            "–ó–∞—Ç–µ–º –≤ —Ä–∞–∑–¥–µ–ª–µ ¬´–í—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è¬ª –≤—ã–ø–∏—à–∏ –≤—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º –≤–∏–¥–µ "
            "(–º–æ–∂–Ω–æ —Å–ø–∏—Å–∫–∞–º–∏ –ø–æ –≥—Ä—É–ø–ø–∞–º/—Å—Ç—Ä–æ–∫–∞–º/—Å—Ç–æ–ª–±—Ü–∞–º), –Ω–µ —Å–æ–∫—Ä–∞—â–∞—è –∏ –Ω–µ –≤—ã–±—Ä–∞—Å—ã–≤–∞—è —á–∏—Å–ª–∞.\n"
            "–í –∫–æ–Ω—Ü–µ, –≤ —Ä–∞–∑–¥–µ–ª–µ ¬´–í—ã–≤–æ–¥—ã¬ª, —Å–¥–µ–ª–∞–π –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–µ –≤—ã–≤–æ–¥—ã: –∫–∞–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—ã—à–µ/–Ω–∏–∂–µ, "
            "–∫–∞–∫–∏–µ —Ä–∞–∑–ª–∏—á–∏—è –∑–∞–º–µ—Ç–Ω—ã, –∫–∞–∫–∏–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ –º–æ–∂–Ω–æ –æ—Ç–º–µ—Ç–∏—Ç—å.\n"
            "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–∏–∫–∞–∫–∏—Ö —Ñ–∞–∫—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü."
            f"{_verbosity_addendum(verbosity, '–æ–ø–∏—Å–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã')}\n\n"
            "[–¢–∞–±–ª–∏—Ü—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞]\n"
            f"{full_ctx}"
        )


    try:
        answer = chat_with_gpt(
            [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.2,
            max_tokens=FINAL_MAX_TOKENS,
        )
    except Exception as e:
        logging.exception("table explanation failed: %s", e)
        await _send(
            m,
            "–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ —Ç–∞–±–ª–∏—Ü–µ ‚Äî –ø—Ä–æ–∏–∑–æ—à–ª–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞. "
            f"–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –¥–ª—è –ª–æ–≥–æ–≤: {e}"
        )
        return True  # –∑–∞–ø—Ä–æ—Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω, –Ω–µ –ø—Ä–æ–≤–∞–ª–∏–≤–∞–µ–º—Å—è –≤ –æ–±—â–∏–π RAG

    answer = (answer or "").strip()

    # --- –ù–û–í–û–ï: –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –¥–∞–ª–∞ –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–æ–≤—Å–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç,
    # –ø—Ä–æ–±—É–µ–º –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π fallback-–ø—Ä–æ–º–ø—Ç —Ç–æ–ª—å–∫–æ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º —Ç–∞–±–ª–∏—Ü—ã.
    if not answer or len(answer) < 60:
        if raw_values_text:
            fb_system = (
                "–¢—ã —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ –¥–∏–ø–ª–æ–º–Ω—ã–º —Ä–∞–±–æ—Ç–∞–º. –ù–∏–∂–µ –¥–∞–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã "
                "–∏–∑ –¥–∏–ø–ª–æ–º–∞ (–≤—Å–µ –µ—ë –∑–Ω–∞—á–µ–Ω–∏—è). "
                "–ü–æ —ç—Ç–∏–º –¥–∞–Ω–Ω—ã–º –æ–ø–∏—à–∏ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, —á—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–∞–±–ª–∏—Ü–∞, "
                "–∫–∞–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—ã—à–µ/–Ω–∏–∂–µ –∏ –∫–∞–∫–∏–µ 2‚Äì3 –≤—ã–≤–æ–¥–∞ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å. "
                "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã—Ö —á–∏—Å–µ–ª –∏ –Ω–µ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–π –ø—Ä–æ—Ü–µ–Ω—Ç—ã. "
                "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –ø—Ä–µ–¥–º–µ—Ç–Ω—É—é –æ–±–ª–∞—Å—Ç—å –∏ —Ç–µ—Ä–º–∏–Ω—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ–¥–∞–∂–∏, –∫–ª–∏–µ–Ω—Ç—ã, –≤—ã—Ä—É—á–∫–∞, "
                "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ —Ç.–ø.), –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã –≤ —Å–∞–º–æ–π —Ç–∞–±–ª–∏—Ü–µ."
            )

            fb_user = (
                f"–¢–∞–±–ª–∏—Ü–∞ –∏–∑ –¥–∏–ø–ª–æ–º–∞:\n{ctx_tables}\n\n"
                f"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {text}\n\n"
                "–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –ø–æ–Ω—è—Ç–Ω–æ–µ —á–µ–ª–æ–≤–µ–∫—É –æ–ø–∏—Å–∞–Ω–∏–µ –∏ –≤—ã–≤–æ–¥—ã –ø–æ —ç—Ç–æ–π —Ç–∞–±–ª–∏—Ü–µ."
            )
            try:
                fb_answer = chat_with_gpt(
                    [
                        {"role": "system", "content": fb_system},
                        {"role": "user",   "content": fb_user},
                    ],
                    temperature=0.3,
                    max_tokens=FINAL_MAX_TOKENS,
                )
            except Exception as e:
                logging.exception("table fallback explanation failed: %s", e)
                fb_answer = ""

            fb_answer = (fb_answer or "").strip()
            if fb_answer:
                answer = fb_answer
    # --- /–ù–û–í–û–ï ---

    # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –≤ –∏—Ç–æ–≥–µ —Ç–∞–∫ –∏ –Ω–µ –¥–∞–ª–∞ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏—è
    if not answer:
        if raw_values_text:
            await _send(
                m,
                raw_values_text
                + "\n\n"
                + "–ú–æ–¥–µ–ª—å –Ω–µ —Å–º–æ–≥–ª–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã. "
                  "–í–æ—Ç —Å–∞–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–æ—è—Å–Ω–µ–Ω–∏–µ ‚Äî –ø–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
            )
        else:
            await _send(
                m,
                "–ú–æ–¥–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ —Ç–∞–±–ª–∏—Ü–µ. "
                "–ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–¥–∞—Ç—å –µ–≥–æ –µ—â—ë —Ä–∞–∑."
            )
        return True  # —Ç–æ–∂–µ –Ω–µ –ø–∞–¥–∞–µ–º –≤ –æ–±—â–∏–π –ø–∞–π–ø–ª–∞–π–Ω

    # –ù–æ—Ä–º–∞–ª—å–Ω—ã–π –∫–µ–π—Å: —Å–Ω–∞—á–∞–ª–∞ –í–°–ï –∑–Ω–∞—á–µ–Ω–∏—è, –ø–æ—Ç–æ–º —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
    final_answer = _strip_unwanted_sections(answer)
    if raw_values_text:
        final_answer = raw_values_text + "\n\n\n" + final_answer

    await _send(m, final_answer)
    return True



# -------------------------- –°–ê–ú–û–í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï –ò–ù–î–ï–ö–°–ê --------------------------

def _count_et(con, uid: int, doc_id: int, et: str) -> int:
    cur = con.cursor()
    if _table_has_columns(con, "chunks", ["element_type"]):
        cur.execute(
            "SELECT COUNT(*) AS c FROM chunks WHERE owner_id=? AND doc_id=? AND element_type=?",
            (uid, doc_id, et),
        )
        row = cur.fetchone()
        return int(row["c"] or 0)
    return 0

def _need_self_heal(uid: int, doc_id: int, need_refs: bool, need_figs: bool) -> tuple[bool, int, int]:
    """
    –°–∞–º–æ–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–µ–ø–µ—Ä—å –∑–∞–≤—è–∑–∞–Ω–æ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –ú–ï–î–ò–ê–î–ê–ù–ù–´–•:
      ‚Äî –µ—Å—Ç—å –ª–∏ –≥–¥–µ-—Ç–æ –≤ attrs —Å–ø–∏—Å–æ–∫ images;
      ‚Äî –µ—Å—Ç—å –ª–∏ chart_data (–¥–∞–Ω–Ω—ã–µ –¥–∏–∞–≥—Ä–∞–º–º), –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç element_type.
    –ï—Å–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –Ω–∞–π–¥–µ–Ω–æ ‚Äî —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ ¬´—Ñ–∏–≥—É—Ä—ã –µ—Å—Ç—å¬ª (fc=1).
    –§–æ–ª–±—ç–∫ –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –ë–î –±–µ–∑ attrs: —Å—á–∏—Ç–∞–µ–º element_type='figure'.
    """
    con = get_conn()
    rc = _count_et(con, uid, doc_id, "reference") if need_refs else 1

    # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ¬´—Ñ–∏–≥—É—Ä—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç¬ª, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –Ω—É–∂–Ω—ã
    fc = 1
    if need_figs:
        media_found = False
        try:
            cur = con.cursor()
            # –µ—Å—Ç—å –ª–∏ –∫–æ–ª–æ–Ω–∫–∞ attrs ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ø—Ä—è–º—É—é –º–µ–¥–∏–∞–¥–∞–Ω–Ω—ã–µ
            if _table_has_columns(con, "chunks", ["attrs"]):
                cur.execute(
                    "SELECT attrs FROM chunks WHERE owner_id=? AND doc_id=? AND attrs IS NOT NULL",
                    (uid, doc_id),
                )
                rows = cur.fetchall() or []
                for r in rows:
                    attrs_json = r["attrs"] or None
                    if not attrs_json:
                        continue
                    # –±—ã—Å—Ç—Ä—ã–π —á–µ–∫ –Ω–∞ images
                    try:
                        a = json.loads(attrs_json)
                        imgs = a.get("images") or []
                        if isinstance(imgs, list) and any(imgs):
                            media_found = True
                            break
                    except Exception:
                        pass
                    # –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏–º chart_data (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø–∞—Ä—Å–µ—Ä)
                    try:
                        cd, _, _ = _parse_chart_data(attrs_json)  # returns (rows|None, type|None, attrs_dict)
                        if cd:
                            media_found = True
                            break
                    except Exception:
                        # –ø–∞—Ä—Å–µ—Ä –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è —Ä–µ—à–µ–Ω–∏—è ‚Äî –ø—Ä–æ—Å—Ç–æ –∏–¥—ë–º –¥–∞–ª—å—à–µ
                        pass
            else:
                # –æ—á–µ–Ω—å —Å—Ç–∞—Ä—ã–π –∏–Ω–¥–µ–∫—Å –±–µ–∑ attrs ‚Äî —Ñ–æ–ª–±—ç–∫ –∫ figure-—á–∞–Ω–∫–∞–º
                media_found = (_count_et(con, uid, doc_id, "figure") > 0)
        except Exception:
            # –∑–∞—â–∏—Ç–Ω—ã–π —Ñ–æ–ª–±—ç–∫: —Å—á–∏—Ç–∞–µ–º –ø–æ figure-—á–∞–Ω–∫–∞–º
            media_found = (_count_et(con, uid, doc_id, "figure") > 0)

        fc = 1 if media_found else 0

    con.close()
    return (rc == 0 or fc == 0, rc, fc)


def _reindex_with_sections(uid: int, doc_id: int, sections: list[dict]) -> None:
    delete_document_chunks(doc_id, uid)
    index_document(uid, doc_id, sections)
    invalidate_cache(uid, doc_id)
    set_document_indexer_version(doc_id, CURRENT_INDEXER_VERSION)
    update_document_meta(doc_id, layout_profile=_current_embedding_profile())


async def _ensure_modalities_indexed(m: types.Message, uid: int, doc_id: int, intents: dict):
    """–ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç —Å—Ç–∞—Ä—ã–π –∏ –Ω–µ—Ç reference/figure ‚Äî —Ç–∏—Ö–æ –ø–µ—Ä–µ–ø–∞—Ä—Å–∏–º –Ω–æ–≤—ã–º –ø–∞—Ä—Å–µ—Ä–æ–º –∏ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º."""
    need_refs = bool(intents.get("sources", {}).get("want"))

    need_figs = bool(intents.get("figures", {}).get("want"))
    if not (need_refs or need_figs):
        return

    should, have_refs, have_figs = _need_self_heal(uid, doc_id, need_refs, need_figs)
    if not should:
        return

    con = get_conn()
    cur = con.cursor()
    cur.execute("SELECT path FROM documents WHERE id=? AND owner_id=?", (doc_id, uid))
    row = cur.fetchone()
    con.close()
    if not row:
        return

    path = row["path"]
    try:
        sections = _parse_by_ext(path)
        sections = enrich_sections(sections, doc_kind=os.path.splitext(path)[1].lower().strip("."))
    except Exception as e:
        logging.exception("re-parse/enrich failed: %s", e)
        return

    new_refs = sum(1 for s in sections if (s.get("element_type") == "reference"))
    new_figs = sum(1 for s in sections if (s.get("element_type") == "figure"))

    do_reindex = False
    if need_refs and have_refs == 0 and new_refs > 0:
        do_reindex = True
    if need_figs and have_figs == 0 and new_figs > 0:
        do_reindex = True

    if do_reindex:
        try:
            _reindex_with_sections(uid, doc_id, sections)
            await _send(m, "–û–±–Ω–æ–≤–∏–ª –∏–Ω–¥–µ–∫—Å –¥–æ–∫—É–º–µ–Ω—Ç–∞: –¥–æ–±–∞–≤–ª–µ–Ω—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Ä–∏—Å—É–Ω–∫–∏/–∏—Å—Ç–æ—á–Ω–∏–∫–∏ (–≤–∫–ª—é—á–∞—è OOXML-–¥–∏–∞–≥—Ä–∞–º–º—ã).")
        except Exception as e:
            logging.exception("self-heal reindex failed: %s", e)


# -------------------------- –°–±–æ—Ä —Ñ–∞–∫—Ç–æ–≤ --------------------------

def _gather_facts(uid: int, doc_id: int, intents: dict) -> dict:
    """
    –°–æ–±–∏—Ä–∞–µ–º –¢–û–õ–¨–ö–û —Ñ–∞–∫—Ç—ã –∏–∑ –ë–î/–∏–Ω–¥–µ–∫—Å–∞, –±–µ–∑ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞.
    """
    facts: dict[str, object] = {
        "doc_id": doc_id,
        "owner_id": uid,
        # –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–Ω—Ç–µ–Ω—Ç—ã –≤–Ω—É—Ç—Ä—å facts ‚Äî answer_builder –∏—Ö —É–º–µ–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
        "intents": intents,
    }
    # —Ñ–ª–∞–≥ ¬´—Ç–æ—á–Ω—ã–µ —á–∏—Å–ª–∞ –∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ¬ª
    exact = bool(intents.get("exact_numbers"))
    # –µ—Å–ª–∏ —è–≤–Ω–æ –ø—Ä–æ—Å—è—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Ç–∞–±–ª–∏—Ü—É(—ã) ‚Äî –≤—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ–º –≤ —Ä–µ–∂–∏–º–µ –¢–û–ß–ù–´–• —á–∏—Å–µ–ª
    if intents.get("tables", {}).get("describe"):
        exact = True
    facts["exact_numbers"] = exact


    # ----- –¢–∞–±–ª–∏—Ü—ã -----
    if intents["tables"]["want"]:
        total_tables = _count_tables(uid, doc_id)
        basenames = _distinct_table_basenames(uid, doc_id)

        con = get_conn()
        cur = con.cursor()
        items: list[str] = []
        for base in basenames:
            cur.execute(
                """
                SELECT attrs FROM chunks
                WHERE owner_id=? AND doc_id=? AND element_type='table_row'
                  AND section_path LIKE ? || ' [row %'
                ORDER BY id ASC LIMIT 1
                """,
                (uid, doc_id, base),
            )
            r = cur.fetchone()
            attrs_json = r["attrs"] if r else None

            cur.execute(
                """
                SELECT text FROM chunks
                WHERE owner_id=? AND doc_id=? AND element_type='table_row'
                  AND section_path LIKE ? || ' [row %'
                ORDER BY id ASC LIMIT 2
                """,
                (uid, doc_id, base),
            )
            rows = cur.fetchall() or []
            first_row_text = None
            for rr in rows:
                cand = (rr["text"] or "").split("\n")[0]
                cand = " ‚Äî ".join([c.strip() for c in cand.split(" | ") if c.strip()])
                if cand:
                    first_row_text = cand
                    break

            title = _compose_display_from_attrs(attrs_json, base, first_row_text)
            title = _strip_table_prefix(title)
            items.append(title)

        con.close()
        t_limit = int(intents.get("tables", {}).get("limit", 10))
        facts["tables"] = {
            "count": total_tables,
            "list": items[:t_limit],
            "more": max(0, len(items) - t_limit),
            "describe": [],
        }

        # –ê–≤—Ç–æ-–æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –æ–±—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –ø—Ä–æ —Ç–∞–±–ª–∏—Ü—ã
        desc_cards = []
        if not intents.get("tables", {}).get("describe"):
            # –≤–æ–∑—å–º—ë–º –ø–µ—Ä–≤—ã–µ 3‚Äì5 —Ç–∞–±–ª–∏—Ü –∏–∑ —Å–ø–∏—Å–∫–∞
            bases = _distinct_table_basenames(uid, doc_id)[:min(5, t_limit)]
            con = get_conn()
            cur = con.cursor()
            for base in bases:
                # attrs + –ø–µ—Ä–≤—ã–µ 1‚Äì2 —Å—Ç—Ä–æ–∫–∏
                cur.execute("""
                    SELECT page, section_path, attrs FROM chunks
                    WHERE owner_id=? AND doc_id=? AND element_type IN ('table','table_row')
                    AND (section_path=? OR section_path LIKE ? || ' [row %')
                    ORDER BY id ASC LIMIT 1
                """, (uid, doc_id, base, base))
                row = cur.fetchone()
                if not row:
                    continue

                cur.execute("""
                    SELECT text FROM chunks
                    WHERE owner_id=? AND doc_id=? AND element_type='table_row'
                    AND (section_path=? OR section_path LIKE ? || ' [row %')
                    ORDER BY id ASC LIMIT 2
                """, (uid, doc_id, row["section_path"], row["section_path"]))
                rows = cur.fetchall() or []
                highlights = []
                for r in rows:
                    first = (r["text"] or "").split("\n")[0]
                    if first:
                        highlights.append(" ‚Äî ".join([c.strip() for c in first.split(" | ") if c.strip()]))

                attrs_json = row["attrs"] if row else None
                display = _compose_display_from_attrs(attrs_json, row["section_path"], highlights[0] if highlights else None)
                display = _strip_table_prefix(display)

                # –ø–æ–ø—Ä–æ–±—É–µ–º –≤—ã—Ç–∞—â–∏—Ç—å –Ω–æ–º–µ—Ä –¥–ª—è stats
                num, _ = _parse_table_title(display)
                stats = None
                if num:
                    try:
                        stats = analyze_table_by_num(uid, doc_id, num, max_series=6)
                    except Exception:
                        stats = None

                desc_cards.append({
                    "num": num,
                    "display": display,
                    "where": {"page": row["page"], "section_path": row["section_path"]},
                    "highlights": highlights,
                    "stats": stats,
                })
            con.close()

        # –û–±—â–∏–π —Å–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü —Å –∫—Ä–∞—Ç–∫–∏–º –æ–ø–∏—Å–∞–Ω–∏–µ–º
        facts["tables"]["describe"] = desc_cards

        # describe –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –Ω–æ–º–µ—Ä–∞–º + —Ç–æ—á–Ω—ã–µ —Ä–∞—Å—á–µ—Ç—ã (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º describe, –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π)
        if intents.get("tables", {}).get("describe"):
            desc_cards = []
            con = get_conn()
            cur = con.cursor()
            for num in intents["tables"]["describe"]:

                like1 = f'%\"caption_num\": \"{num}\"%'
                like2 = f'%\"label\": \"{num}\"%'
                cur.execute(
                    """
                    SELECT page, section_path, attrs FROM chunks
                    WHERE owner_id=? AND doc_id=? AND element_type IN ('table','table_row')
                      AND (attrs LIKE ? OR attrs LIKE ?)
                    ORDER BY id ASC LIMIT 1
                    """,
                    (uid, doc_id, like1, like2),
                )
                row = cur.fetchone()

                if not row:
                    cur.execute(
                        """
                        SELECT page, section_path, attrs FROM chunks
                        WHERE owner_id=? AND doc_id=? AND element_type IN ('table','table_row')
                          AND section_path LIKE ? COLLATE NOCASE
                        ORDER BY id ASC LIMIT 1
                        """,
                        (uid, doc_id, f'%–¢–∞–±–ª–∏—Ü–∞ {num}%'),
                    )
                    row = cur.fetchone()

                if not row:
                    continue

                attrs_json = row["attrs"] if row else None
                # 1‚Äì2 –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫–∏ –∫–∞–∫ highlights
                cur.execute(
                    """
                    SELECT text FROM chunks
                    WHERE owner_id=? AND doc_id=? AND element_type='table_row'
                      AND (section_path=? OR section_path LIKE ? || ' [row %')
                    ORDER BY id ASC LIMIT 2
                    """,
                    (uid, doc_id, row["section_path"], row["section_path"]),
                )
                rows = cur.fetchall()
                highlights = []
                for r in rows or []:
                    first_line = (r["text"] or "").split("\n")[0]
                    if first_line:
                        highlights.append(" ‚Äî ".join([c.strip() for c in first_line.split(" | ") if c.strip()]))

                base = row["section_path"]
                first_row_text = highlights[0] if highlights else None
                display = _compose_display_from_attrs(attrs_json, base, first_row_text)
                display = _strip_table_prefix(display)

                # –ù–û–í–û–ï: —Ç–æ—á–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –ø–æ —Ç–∞–±–ª–∏—Ü–µ
                stats = None
                try:
                    stats = analyze_table_by_num(uid, doc_id, num, max_series=6)
                except Exception:
                    stats = None

                desc_cards.append({
                    "num": num,
                    "display": display,
                    "where": {"page": row["page"], "section_path": row["section_path"]},
                    "highlights": highlights,
                    "stats": stats,
                })
            con.close()

            facts["tables"]["describe"] = desc_cards

            # –∑–∞–ø–æ–º–Ω–∏–º —ç—Ç–∏ –Ω–æ–º–µ—Ä–∞ —Ç–∞–±–ª–∏—Ü –∫–∞–∫ ¬´–ø–æ—Å–ª–µ–¥–Ω–∏–µ —É–ø–æ–º—è–Ω—É—Ç—ã–µ¬ª
            try:
                LAST_REF.setdefault(uid, {})["table_nums"] = [
                    str(c["num"]) for c in desc_cards if c.get("num")
                ]
            except Exception:
                pass

    # ----- –†–∏—Å—É–Ω–∫–∏ -----
    if intents["figures"]["want"]:
        f_limit = int(intents.get("figures", {}).get("limit", 10))
        lst = _list_figures_db(uid, doc_id, limit=f_limit)
        figs_block = {
            "count": int(lst.get("count") or 0),
            "list": list(lst.get("list") or []),
            "more": int(lst.get("more") or 0),
            # –∫–ª—é—á–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ, –∫–æ—Ç–æ—Ä—ã–π –∂–¥—ë—Ç answer_builder
            "describe": [],
            "describe_cards": [],
            # –Ω–∞ –±—É–¥—É—â–µ–µ: —Ñ–ª–∞–≥ —Ñ–æ–∫—É—Å–∞ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –Ω–æ–º–µ—Ä–∞—Ö —Ä–∏—Å—É–Ω–∫–æ–≤
            "single_only": False,
            "describe_nums": [],
        }


        nums = list(intents.get("figures", {}).get("describe") or [])
        if nums:
            try:
                # ‚öôÔ∏è –ë–µ—Ä—ë–º –∫–∞—Ä—Ç–æ—á–∫–∏ –¢–û–õ–¨–ö–û –ø–æ —É–∫–∞–∑–∞–Ω–Ω—ã–º –Ω–æ–º–µ—Ä–∞–º (5 –∏ 6 ‚Üí —Ç–æ–ª—å–∫–æ 5 –∏ 6)
                cards = describe_figures_by_numbers(
                    uid,
                    doc_id,
                    nums,
                    sample_chunks=2,
                    use_vision=True,
                    lang="ru",
                    vision_first_image_only=True,
                ) or []
                logging.info(
                    "FIG: –ø–æ–ª—É—á–µ–Ω–æ %d —Ä–∏—Å—É–Ω–∫–æ–≤ –¥–ª—è –Ω–æ–º–µ—Ä–æ–≤ %s",
                    len(cards),
                    ", ".join(map(str, nums)),
                )

                if not cards:
                    figs_block["describe"] = ["–î–∞–Ω–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞ –Ω–µ—Ç –≤ —Ä–∞–±–æ—Ç–µ."]
                    figs_block["describe_cards"] = []
                else:
                    # –û—Å–Ω–æ–≤–Ω–æ–µ –¥–ª—è answer_builder: –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä describe_cards
                    figs_block["describe_cards"] = cards

                    # –ß—Ç–æ–±—ã –≤ [Figures]/list –Ω–µ –ø–æ–ø–∞–¥–∞–ª–∏ –ª–∏—à–Ω–∏–µ —Ä–∏—Å—É–Ω–∫–∏,
                    # –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –±—ã–ª —Ç–æ–ª—å–∫–æ –ø—Ä–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –Ω–æ–º–µ—Ä–∞.
                    figs_block["list"] = [
                        (c.get("display")
                        or f"–†–∏—Å—É–Ω–æ–∫ {c.get('num') or ''}".strip())
                        for c in cards
                    ]
                    figs_block["count"] = len(figs_block["list"])
                    figs_block["more"] = 0

                    # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è
                    lines = []
                    for c in cards:
                        disp = c.get("display") or "–†–∏—Å—É–Ω–æ–∫"
                        vis = (c.get("vision") or {}).get("description", "") or ""
                        vis_clean = vis.strip()
                        low_vis = vis_clean.lower()
                        if ("–æ–ø–∏—Å–∞–Ω–∏–µ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ" in low_vis
                                or "—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è" in low_vis):
                            vis_clean = ""
                        hint = "; ".join([h for h in (c.get("highlights") or []) if h])
                        if vis_clean:
                            lines.append(f"{disp}: {vis_clean}")
                        elif hint:
                            lines.append(f"{disp}: {hint}")
                        else:
                            lines.append(disp)
                    figs_block["describe"] = lines[:25]

                    # üí° –≤–∞–∂–Ω–æ–µ: –ø–æ–º–µ—á–∞–µ–º, —á—Ç–æ –Ω—É–∂–Ω–æ —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ —ç—Ç–∏—Ö –Ω–æ–º–µ—Ä–∞—Ö
                    figs_block["single_only"] = True
                    figs_block["describe_nums"] = list(nums)
            except Exception as e:
                figs_block["describe"] = [f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø–∏—Å–∞—Ç—å —Ä–∏—Å—É–Ω–∫–∏: {e}"]
                figs_block["describe_cards"] = []

        facts["figures"] = figs_block

    # ----- –ò—Å—Ç–æ—á–Ω–∏–∫–∏ -----
    if intents["sources"]["want"]:
        con = get_conn()
        cur = con.cursor()
        has_type = _table_has_columns(con, "chunks", ["element_type", "attrs"])
        items: list[str] = []

        if has_type:
            cur.execute(
                "SELECT text FROM chunks WHERE owner_id=? AND doc_id=? AND element_type='reference' ORDER BY id ASC",
                (uid, doc_id),
            )
            items = [(r["text"] or "").strip() for r in cur.fetchall()]

        if not any(items):
            cur.execute(
                """
                SELECT element_type, section_path, text
                FROM chunks
                WHERE owner_id=? AND doc_id=?
                ORDER BY page ASC, id ASC
                """,
                (uid, doc_id),
            )
            raw = []
            for r in cur.fetchall():
                sec = (r["section_path"] or "").lower()
                if not any(k in sec for k in ("–∏—Å—Ç–æ—á–Ω–∏–∫", "–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä", "–±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ", "reference", "bibliograph")):
                    continue
                et = (r["element_type"] or "").lower()
                if et in ("heading", "table", "figure", "table_row"):
                    continue
                t = (r["text"] or "").strip()
                if t:
                    raw.append(t)

            seen = set()
            items = []
            for t in raw:
                k = re.sub(r"\s+", " ", t).strip().rstrip(".").lower()
                if len(k) < 5 or k in seen:
                    continue
                seen.add(k)
                items.append(t)

        con.close()

        s_limit = int(intents.get("sources", {}).get("limit", 25))
        facts["sources"] = {
            "count": len(items),
            "list": items[:s_limit],
            "more": max(0, len(items) - s_limit),
        }


    # ----- –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å -----
    if intents.get("practical"):
        facts["practical_present"] = _has_practical_part(uid, doc_id)

    # ----- Summary -----
    if intents.get("summary"):
        s = overview_context(uid, doc_id, max_chars=6000) or _first_chunks_context(uid, doc_id, n=12, max_chars=6000)
        if s:
            facts["summary_text"] = s

    # ----- –û–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç / —Ü–∏—Ç–∞—Ç—ã -----
    # app/bot.py (_gather_facts: –æ–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç / —Ü–∏—Ç–∞—Ç—ã)
    if intents.get("general_question"):
        question_text = intents.get("general_question") or ""

        vb = verbatim_find(uid, doc_id, question_text, max_hits=3)

        cov = retrieve_coverage(
            owner_id=uid,
            doc_id=doc_id,
            question=question_text,
        )
        ctx = ""
        if cov and cov.get("snippets"):
            ctx = build_context_coverage(
                cov["snippets"],
                items_count=len(cov.get("items") or []) or None,
            )

        if not ctx:
            ctx = best_context(uid, doc_id, question_text, max_chars=6000)
        if not ctx:
            hits = retrieve(uid, doc_id, question_text, top_k=12)
            if hits:
                ctx = build_context(hits)
        if not ctx:
            ctx = _first_chunks_context(uid, doc_id, n=12, max_chars=6000)

        if ctx:
            facts["general_ctx"] = ctx
        if vb:
            facts["verbatim_hits"] = vb
        if cov and cov.get("items"):
            # coverage –≤ —Ñ–æ—Ä–º–∞—Ç–µ, –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–µ—Ç facts_to_prompt
            facts["coverage"] = {"items": cov["items"]}


        # --- [VISION] –≤—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥: —á–∏—Å–ª–∞ –∏–∑ –¥–∏–∞–≥—Ä–∞–º–º/–∫–∞—Ä—Ç–∏–Ω–æ–∫ (–ø–æ–¥–º–µ—à–∏–≤–∞–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç) ---
        try:
            vision_block = ""
            if getattr(Cfg, "vision_active", lambda: False)():
                # 1) –±–µ—Ä—ë–º —Ç–æ–ø-—Ö–∏—Ç—ã —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–æ–∫
                hits_v = retrieve(uid, doc_id, question_text, top_k=10) or []

                # 1–∞) –µ—Å–ª–∏ –≤ —Ö–∏—Ç–∞—Ö –µ—Å—Ç—å chart_data (DOCX-–¥–∏–∞–≥—Ä–∞–º–º—ã) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—á–Ω—ã–µ —á–∏—Å–ª–∞, –±–µ–∑ vision
                chart_lines: list[str] = []
                for h in hits_v:
                    attrs = (h.get("attrs") or {})
                    cd = attrs.get("chart_data")
                    if cd:
                        # –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä: —É–ø–∞–∫—É–µ–º –≤ attrs-json
                        try:
                            cd_list, _, _ = _parse_chart_data(json.dumps({"chart_data": cd}))
                        except Exception:
                            cd_list = None
                        if cd_list:
                            chart_lines.append(_format_chart_values(cd_list))

                if chart_lines:
                    vision_block = "\n".join(chart_lines[:3])
                else:
                    # 2) –∏–Ω–∞—á–µ ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º 1‚Äì3 –∫–∞—Ä—Ç–∏–Ω–∫–∏ –≤ –Ω–æ–≤—ã–π vision_analyzer
                    img_paths = _pick_images_from_hits(
                        hits_v,
                        limit=getattr(Cfg, "VISION_MAX_IMAGES_PER_REQUEST", 3),
                    )
                    if img_paths and va_analyze_figure:
                        chunks: list[str] = []
                        hint = question_text[:300]
                        for p in img_paths:
                            try:
                                res = va_analyze_figure(p, caption_hint=hint, lang="ru")
                            except Exception:
                                continue

                            text_block = ""
                            if isinstance(res, dict):
                                pairs = res.get("data") or []
                                text_block = (res.get("text") or "").strip() or _pairs_to_bullets(pairs)
                            else:
                                text_block = (str(res) or "").strip()

                            if text_block:
                                chunks.append("[Text on image]\n" + text_block)

                        if chunks:
                            vision_block = "\n\n".join(chunks)
                        elif FIG_STRICT:
                            vision_block = "[No precise data]"

            if vision_block:
                prev = facts.get("general_ctx") or ""
                glue = ("\n\n" if prev else "")
                facts["general_ctx"] = (prev + glue + vision_block)
        except Exception:
            # –Ω–µ –ª–æ–º–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç, –µ—Å–ª–∏ vision –¥–∞–ª —Å–±–æ–π
            pass

        # --- [/VISION] ---


    # –ª–æ–≥–∏—Ä—É–µ–º –º–∞–ª–µ–Ω—å–∫–∏–π —Å—Ä–µ–∑ —Ñ–∞–∫—Ç–æ–≤ (–±–µ–∑ –æ–≥—Ä–æ–º–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤)
    log_snapshot = dict(facts)
    if "general_ctx" in log_snapshot and isinstance(log_snapshot["general_ctx"], str):
        log_snapshot["general_ctx"] = log_snapshot["general_ctx"][:300] + "‚Ä¶" if len(log_snapshot["general_ctx"]) > 300 else log_snapshot["general_ctx"]
    if "summary_text" in log_snapshot and isinstance(log_snapshot["summary_text"], str):
        log_snapshot["summary_text"] = log_snapshot["summary_text"][:300] + "‚Ä¶" if len(log_snapshot["summary_text"]) > 300 else log_snapshot["summary_text"]
    logging.debug("FACTS: %s", json.dumps(log_snapshot, ensure_ascii=False))
    return facts


def _strip_unwanted_sections(s: str) -> str:
    """
    –ê–∫–∫—É—Ä–∞—Ç–Ω–æ —É–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Ö–≤–æ—Å—Ç—ã –≤—Ä–æ–¥–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    ¬´–ß–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç: ‚Ä¶¬ª, –Ω–æ –Ω–µ –¥–æ–ø—É—Å–∫–∞–µ–º, —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç
    –æ–±–Ω—É–ª–∏–ª—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é ‚Äî –≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç.
    """
    if not s:
        return s

    original = s

    # –≤—ã—Ä–µ–∑–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ + –∞–±–∑–∞—Ü(—ã) –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—É—Å—Ç–æ–≥–æ —Ä–∞–∑—Ä—ã–≤–∞
    pat = re.compile(r"(?mis)^\s*(?:—á–µ–≥–æ|—á—Ç–æ)\s+–Ω–µ\s+—Ö–≤–∞—Ç–∞–µ—Ç\s*:.*?(?:\n\s*\n|\Z)")
    s = pat.sub("", s)
    # –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏-–º–µ—Ç–∫–∏
    s = re.sub(r"(?mi)^\s*–Ω–µ\s+—Ö–≤–∞—Ç–∞–µ—Ç\s*:.*$", "", s)

    s = s.strip()
    # –µ—Å–ª–∏ –ø–æ—Å–ª–µ –∑–∞—á–∏—Å—Ç–∫–∏ –≤—Å—ë –∏—Å—á–µ–∑–ª–æ ‚Äî –ª—É—á—à–µ –≤–µ—Ä–Ω—É—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç,
    # —á–µ–º –æ—Ç–¥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –ø—É—Å—Ç–æ—Ç—É
    return s or original.strip()


# ------------------------------ FULLREAD: –º–æ–¥–µ–ª—å —á–∏—Ç–∞–µ—Ç –≤–µ—Å—å —Ñ–∞–π–ª ------------------------------

def _full_document_text(owner_id: int, doc_id: int, *, limit_chars: int | None = None) -> str:
    """–°–∫–ª–µ–∏–≤–∞–µ–º –í–ï–°–¨ —Ç–µ–∫—Å—Ç –∏–∑ chunks (page ASC, id ASC)."""
    con = get_conn()
    cur = con.cursor()
    cur.execute(
        "SELECT text FROM chunks WHERE owner_id=? AND doc_id=? ORDER BY page ASC, id ASC",
        (owner_id, doc_id),
    )
    rows = cur.fetchall() or []
    con.close()

    parts = []
    total = 0
    for r in rows:
        t = (r["text"] or "").strip()
        if not t:
            continue
        if limit_chars is not None and total + len(t) > limit_chars:
            remaining = max(0, limit_chars - total)
            if remaining > 0:
                parts.append(t[:remaining])
                total += remaining
            break
        parts.append(t)
        total += len(t)
    return "\n\n".join(parts)

def _fullread_try_answer(uid: int, doc_id: int, q_text: str) -> str | None:
    """
    DIRECT: –æ—Ç–¥–∞—ë–º –º–æ–¥–µ–ª–∏ —Ü–µ–ª–∏–∫–æ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∫–∞–∫ –µ–¥–∏–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.
    –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None (—É–π–¥—ë–º –≤ –∏–Ω–æ–π —Ä–µ–∂–∏–º).
    """
    if getattr(Cfg, "FULLREAD_MODE", "off") != "direct":
        return None

    _limit = int(getattr(Cfg, "DIRECT_MAX_CHARS", 80000))
    full_text = _full_document_text(uid, doc_id, limit_chars=_limit + 1)
    if not full_text.strip():
        return None

    if len(full_text) > _limit:
        return None

    system_prompt = (
        "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –¥–∏–ø–ª–æ–º–Ω—ã–º —Ä–∞–±–æ—Ç–∞–º. –¢–µ–±–µ –¥–∞–Ω –ü–û–õ–ù–´–ô —Ç–µ–∫—Å—Ç –í–ö–†/–¥–æ–∫—É–º–µ–Ω—Ç–∞.\n"
        "–û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –ø–æ —ç—Ç–æ–º—É —Ç–µ–∫—Å—Ç—É, –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö —Ñ–∞–∫—Ç–æ–≤. –ù–µ –¥–æ–±–∞–≤–ª—è–π —Ä–∞–∑–¥–µ–ª–æ–≤ –≤–∏–¥–∞ "
        "¬´–ß–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç¬ª –∏ –Ω–µ –ø—Ä–æ—Å–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.\n"
        "–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ —Ç–∞–±–ª–∏—Ü—ã/—Ä–∏—Å—É–Ω–∫–∏ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –ø–æ–¥–ø–∏—Å–∏ –∏ –±–ª–∏–∂–∞–π—à–∏–π —Ç–µ–∫—Å—Ç; –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–º–µ—Ä–∞/–∑–Ω–∞—á–µ–Ω–∏—è.\n"
        "–ï—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞/—Ç–∞–±–ª–∏—Ü—ã –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ ‚Äî –æ—Ç–≤–µ—Ç—å: ¬´–¥–∞–Ω–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞ –Ω–µ—Ç –≤ —Ä–∞–±–æ—Ç–µ¬ª.\n"
        "–ï—Å–ª–∏ –æ–±—ä–µ–∫—Ç –µ—Å—Ç—å, –Ω–æ –æ–Ω –≤ –ø–ª–æ—Ö–æ–º –∫–∞—á–µ—Å—Ç–≤–µ/–Ω–µ—á–∏—Ç–∞–µ–º ‚Äî –æ—Ç–≤–µ—Ç—å: ¬´–†–∏—Å—É–Ω–æ–∫ –ø–ª–æ—Ö–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞, –Ω–µ –º–æ–≥—É –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å¬ª, "
        "–∏ –¥–æ–±–∞–≤—å –∫—Ä–∞—Ç–∫—É—é –ø–æ–¥–ø–∏—Å—å/–∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞. –¶–∏—Ç–∏—Ä—É–π –∫–æ—Ä–æ—Ç–∫–æ, –±–µ–∑ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã."
    )

    verbosity = _detect_verbosity(q_text)
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "assistant", "content": f"[–î–æ–∫—É–º–µ–Ω—Ç ‚Äî –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç]\n{full_text}"},
        {"role": "user", "content": f"{q_text}\n\n{_verbosity_addendum(verbosity)}"},
    ]

    try:
        answer = chat_with_gpt(messages, temperature=0.2, max_tokens=FINAL_MAX_TOKENS)
        return (answer or "").strip() or None
    except Exception as e:
        logging.exception("fullread direct failed: %s", e)
        return None


def _fullread_collect_sections(uid: int, doc_id: int, *, max_sections: int = 800) -> List[str]:
    """
    –°–µ–∫—Ü–∏–∏ –¥–ª—è –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞: —Å–æ–±–∏—Ä–∞–µ–º –±–ª–æ–∫–∏ —Ç–µ–∫—Å—Ç–∞ –ø–æ section_path –≤ –ø–æ—Ä—è–¥–∫–µ —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.
    """
    con = get_conn()
    cur = con.cursor()
    cur.execute(
        "SELECT section_path, text FROM chunks WHERE owner_id=? AND doc_id=? ORDER BY page ASC, id ASC",
        (uid, doc_id)
    )
    rows = cur.fetchall() or []
    con.close()

    out: List[str] = []
    cur_sec = None
    buf: List[str] = []

    def _flush():
        if buf:
            text = "\n".join([t for t in buf if t.strip()]).strip()
            if text:
                title = f"[{cur_sec}]" if cur_sec else ""
                out.append(f"{title}\n{text}" if title else text)
        buf.clear()


    for r in rows:
        sec = r["section_path"] or ""
        t = (r["text"] or "").strip()
        if not t:
            continue
        if cur_sec is None:
            cur_sec = sec
        if sec != cur_sec:
            _flush()
            cur_sec = sec
        buf.append(t)
        if len(out) >= max_sections:
            break
    _flush()
    return out[:max_sections]


def _group_for_steps(sections: Iterable[str], per_step_chars: int, max_steps: int) -> List[str]:
    """–ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–µ–∫—Ü–∏–∏ –≤ –±–∞—Ç—á–∏ –ø–æ —Å–∏–º–≤–æ–ª–∞–º (–¥–ª—è map-—à–∞–≥–∞)."""
    batches: List[str] = []
    cur: List[str] = []
    cur_len = 0
    for s in sections:
        if cur_len + len(s) + 1 > per_step_chars and cur:
            batches.append("\n\n".join(cur))
            cur, cur_len = [], 0
            if len(batches) >= max_steps:
                break
        cur.append(s)
        cur_len += len(s) + 1
    if cur and len(batches) < max_steps:
        batches.append("\n\n".join(cur))
    return batches[:max_steps]

def _map_extract(uid: int, doc_id: int, question: str, chunk_text: str, *, map_tokens: int) -> str:
    """–û–¥–∏–Ω map-–≤—ã–∑–æ–≤: –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã/—Ü–∏—Ç–∞—Ç—ã –∏–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞."""
    sys_map = (
        "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç-—ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä. –¢–µ–±–µ –¥–∞–Ω —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–∏–ø–ª–æ–º–∞ –∏ –≤–æ–ø—Ä–æ—Å. "
        "–ò–∑–≤–ª–µ–∫–∏ –¢–û–õ–¨–ö–û —Ñ–∞–∫—Ç—ã –∏ –º–∏–Ω–∏-—Ü–∏—Ç–∞—Ç—ã, –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ –≤–æ–ø—Ä–æ—Å—É. "
        "–ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è —Ç–∞–±–ª–∏—Ü—ã ‚Äî –≤–∫–ª—é—á–∞–π –∏—Ö –Ω–∞–∑–≤–∞–Ω–∏—è –∏ 1‚Äì2 –∫–ª—é—á–µ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å —á–∏—Å–ª–∞–º–∏ "
        "(—Å–æ—Ö—Ä–∞–Ω—è–π –ø–æ—Ä—è–¥–æ–∫ –∏ –∑–Ω–∞—á–µ–Ω–∏—è). –§–æ—Ä–º–∞—Ç: –±—É–ª–ª–µ—Ç—ã."
    )
    return chat_with_gpt(
        [
            {"role": "system", "content": sys_map},
            {"role": "assistant", "content": f"[–§—Ä–∞–≥–º–µ–Ω—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞]\n{chunk_text}"},
            {"role": "user", "content": f"–í–æ–ø—Ä–æ—Å: {question}\n–°–¥–µ–ª–∞–π –∫–æ—Ä–æ—Ç–∫—É—é –≤—ã–∂–∏–º–∫—É (–±—É–ª–ª–µ—Ç—ã)."},
        ],
        temperature=0.1,
        max_tokens=max(120, int(map_tokens)),
    )

def _iterative_fullread_build_messages(uid: int, doc_id: int, question: str) -> Tuple[Optional[list], Optional[str]]:
    """
    –°–æ–±–∏—Ä–∞–µ–º map-–≤—ã–∂–∏–º–∫–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º reduce-—Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —Å—Ç—Ä–∏–º–∞
    –ò–õ–ò –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç (–µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫).
    """
    per_step = int(getattr(Cfg, "FULLREAD_STEP_CHARS", 14000))
    max_steps = int(getattr(Cfg, "FULLREAD_MAX_STEPS", 2))
    map_tokens = int(getattr(Cfg, "DIGEST_TOKENS_PER_SECTION", 300))

    sections = _fullread_collect_sections(uid, doc_id)
    if not sections:
        return None, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç —Å–µ–∫—Ü–∏—è–º–∏."

    batches = _group_for_steps(sections, per_step_chars=per_step, max_steps=max_steps)
    if not batches:
        return None, "–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —à–∞–≥–∏ —á—Ç–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞."

    digests: List[str] = []
    for b in batches:
        try:
            digests.append(_map_extract(uid, doc_id, question, b, map_tokens=map_tokens))
        except Exception as e:
            logging.exception("map extract failed: %s", e)
            digests.append(b[:800])

    # –≤–º–µ—Å—Ç–æ —Ç–µ—Ö–Ω–∏—á–Ω—ã—Ö [MAP 1] –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –º–µ—Ç–∫–∏
    joined = "\n\n".join([f"[–§—Ä–∞–≥–º–µ–Ω—Ç {i+1}]\n{d}" for i, d in enumerate(digests)])
    ctx = joined[: int(getattr(Cfg, "FULLREAD_CONTEXT_CHARS", 9000))]

    sys_reduce = (
        "–¢—ã —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ –í–ö–†. –ù–∏–∂–µ ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ–∞–∫—Ç—ã –∏–∑ —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞. "
        "–°–æ–±–µ—Ä–∏ –∏–∑ –Ω–∏—Ö —Å–≤—è–∑–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å. –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã—Ö —Ü–∏—Ñ—Ä/—Ç–∞–±–ª–∏—Ü –∏ –Ω–µ –¥–æ–±–∞–≤–ª—è–π —Ä–∞–∑–¥–µ–ª–æ–≤ "
        "–ø—Ä–æ ¬´—á–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç¬ª. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –ø–æ –∏–º–µ—é—â–∏–º—Å—è –¥–∞–Ω–Ω—ã–º. "
        "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –ø—Ä–µ–¥–º–µ—Ç–Ω—É—é –æ–±–ª–∞—Å—Ç—å –∏ —Ç–µ—Ä–º–∏–Ω—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ–¥–∞–∂–∏, –∫–ª–∏–µ–Ω—Ç—ã, –≤—ã—Ä—É—á–∫–∞, –º–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ —Ç.–ø.), "
        "–µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ —Ñ–∞–∫—Ç–∞—Ö/—Ü–∏—Ç–∞—Ç–∞—Ö.\n"
        "–ï—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞/—Ç–∞–±–ª–∏—Ü—ã –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ ‚Äî —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –∫—Ä–∞—Ç–∫–æ: ¬´–¥–∞–Ω–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞ –Ω–µ—Ç –≤ —Ä–∞–±–æ—Ç–µ¬ª. "
        "–ï—Å–ª–∏ –æ–±—ä–µ–∫—Ç –µ—Å—Ç—å, –Ω–æ –æ–Ω –Ω–µ—á–∏—Ç–∞–µ–º, –¥–∞–π: ¬´–†–∏—Å—É–Ω–æ–∫ –ø–ª–æ—Ö–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞, –Ω–µ –º–æ–≥—É –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å¬ª, "
        "–∏ –¥–æ–±–∞–≤—å –ø–æ–¥–ø–∏—Å—å/–∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞. "
        "–í —Å–≤–æ—ë–º –æ—Ç–≤–µ—Ç–µ –Ω–µ —Å—Å—ã–ª–∞–π—Å—è –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–∫–∏ –≤—Ä–æ–¥–µ ¬´—Ñ—Ä–∞–≥–º–µ–Ω—Ç 1¬ª –∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Å–ª–æ–≤–æ ¬´–≤—ã–∂–∏–º–∫–∞¬ª."
    )



    verbosity = _detect_verbosity(question)
    messages = [
        {"role": "system", "content": sys_reduce},
        {"role": "assistant", "content": f"–°–≤–æ–¥–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞:\n{ctx}"},
        {"role": "user", "content": f"{question}\n\n{_verbosity_addendum(verbosity)}"},
    ]
    return messages, None


# ------------------------------ –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ ------------------------------

@dp.message(F.document)
async def handle_doc(m: types.Message):
    uid = ensure_user(str(m.from_user.id))
    doc = m.document

    # 0) FSM: —Ñ–∏–∫—Å–∏—Ä—É–µ–º, —á—Ç–æ –Ω–∞—á–∞–ª–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
    start_downloading(uid)
    await _send(m, Cfg.MSG_ACK_DOWNLOADING)

    # 1) —Å–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª —Ü–µ–ª–∏–∫–æ–º (–±–µ–∑ –æ–±—Ä–µ–∑–∫–∏)
    from io import BytesIO

    file = await bot.get_file(doc.file_id)
    buf = BytesIO()
    await bot.download_file(file.file_path, destination=buf)
    buf.seek(0)
    data = buf.read()  # –∑–¥–µ—Å—å –≤—Å–µ –±–∞–π—Ç—ã —Ñ–∞–π–ª–∞ –∫–∞–∫ –µ—Å—Ç—å

    # 2) —Å–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞ –¥–∏—Å–∫ (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–∞–≤–¥—ã –¥–ª—è –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞)
    filename = safe_filename(f"{m.from_user.id}_{doc.file_name}")
    path = save_upload(data, filename, Cfg.UPLOAD_DIR)
    await _send(m, Cfg.MSG_ACK_INDEXING)

    # 3) –æ–±—ë—Ä—Ç–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞ –ø–æ–¥ —Å–∏–≥–Ω–∞—Ç—É—Ä—É –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞ (–∑–∞–º—ã–∫–∞–µ–º uid)
    def _indexer_fn(doc_id: int, file_path: str, kind: str) -> dict:
        sections = _parse_by_ext(file_path)
        sections = enrich_sections(sections, doc_kind=os.path.splitext(file_path)[1].lower().strip("."))
        # sanity-check –Ω–∞ ¬´–ø—É—Å—Ç—ã–µ¬ª —Ñ–∞–π–ª—ã
        if sum(len(s.get("text") or "") for s in sections) < 500 and not any(
            s.get("element_type") in ("table", "table_row", "figure") for s in sections
        ):
            raise RuntimeError("–ü–æ—Ö–æ–∂–µ, —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç ¬´–∂–∏–≤–æ–≥–æ¬ª —Ç–µ–∫—Å—Ç–∞/—Å—Ç—Ä—É–∫—Ç—É—Ä.")
        # –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è ¬´–∫–∞–∫ —Ä–∞–Ω—å—à–µ¬ª
        delete_document_chunks(doc_id, uid)
        index_document(uid, doc_id, sections)
        invalidate_cache(uid, doc_id)
        update_document_meta(doc_id, layout_profile=_current_embedding_profile())
        return {"sections_count": len(sections)}

    # 4) –∑–∞–ø—É—Å–∫–∞–µ–º –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä (–æ–Ω —Å–∞–º: –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å, INDEXING, READY/IDLE, –≤–µ—Ä—Å–∏—è –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–∞)
    try:
        result = ingest_document(
            user_id=uid,
            file_path=path,
            kind=infer_doc_kind(doc.file_name),
            file_uid=getattr(doc, "file_unique_id", None),
            content_sha256=sha256_bytes(data),
            indexer_fn=_indexer_fn,
        )
    except Exception as e:
        logging.exception("ingest failed: %s", e)
        await _send(m, Cfg.MSG_INDEX_FAILED + f" –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏: {e}")
        return

    doc_id = int(result["doc_id"])
    ACTIVE_DOC[uid] = doc_id
    set_user_active_doc(uid, doc_id)

    # NEW: –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –∏–Ω–¥–µ–∫—Å —Ä–∏—Å—É–Ω–∫–æ–≤ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏ –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞—Ç—å (—Å—Ç–∞—Ä—ã–π –ø—É—Ç—å)
    try:
        if fig_index_document is not None:
            FIG_INDEX[doc_id] = fig_index_document(path)
    except Exception as e:
        logging.exception("figures indexing failed: %s", e)


        # NEW: –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –ï–î–ò–ù–´–ô OOXML-–∏–Ω–¥–µ–∫—Å (–≥–ª–∞–≤—ã/—Ä–∏—Å—É–Ω–∫–∏/—Ç–∞–±–ª–∏—Ü—ã/–∏—Å—Ç–æ—á–Ω–∏–∫–∏) –±–µ–∑ LibreOffice
    # NEW: –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –ï–î–ò–ù–´–ô OOXML-–∏–Ω–¥–µ–∫—Å (–≥–ª–∞–≤—ã/—Ä–∏—Å—É–Ω–∫–∏/—Ç–∞–±–ª–∏—Ü—ã/–∏—Å—Ç–æ—á–Ω–∏–∫–∏) –±–µ–∑ LibreOffice
    try:
        idx_oox = oox_build_index(path)
        OOXML_INDEX[doc_id] = idx_oox
        #persist –ø–æ–¥ ID –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –ë–î ‚Äî —á—Ç–æ–±—ã _ooxml_get_index —Ä–∞–±–æ—Ç–∞–ª –ø–æ—Å–ª–µ —Ä–µ—Å—Ç–∞—Ä—Ç–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞
        try:
            os.makedirs(os.path.join("runtime", "indexes"), exist_ok=True)
            with open(os.path.join("runtime", "indexes", f"{doc_id}.json"), "w", encoding="utf-8") as f:
                json.dump(idx_oox, f, ensure_ascii=False, indent=2)
        except Exception:
            pass
    except Exception as e:
        logging.exception("ooxml build_index failed: %s", e)


    # 5) READY: —Å–æ–æ–±—â–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º ...
    await _send(
        m,
        (f"–≠—Ç–æ—Ç —Ñ–∞–π–ª —É–∂–µ –±—ã–ª –∑–∞–≥—Ä—É–∂–µ–Ω –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç #{doc_id}. " if result.get("reused") else "") + Cfg.MSG_READY
    )

    caption = (m.caption or "").strip()
    if caption:
        await respond_with_answer(m, uid, doc_id, caption)

    # –∞–≤—Ç–æ-–¥—Ä–µ–Ω–∞–∂ –æ—á–µ—Ä–µ–¥–∏ –æ–∂–∏–¥–∞–Ω–∏—è (–±–µ–∑ –¥—É–±–ª–µ–π –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤)
    try:
        queued = dequeue_all_pending_queries(uid)
        for item in queued:
            q = (item.get("text") or "").strip()
            if not q:
                continue
            # –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –∏–∑ –æ—á–µ—Ä–µ–¥–∏ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –ø–æ–¥–ø–∏—Å—å—é –∫ —Ñ–∞–π–ª—É ‚Äî –Ω–µ –æ—Ç–≤–µ—á–∞–µ–º –≤—Ç–æ—Ä–æ–π —Ä–∞–∑
            if caption and q.strip() == caption:
                continue
            await respond_with_answer(m, uid, doc_id, q)
            await asyncio.sleep(0)  # –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º —Ü–∏–∫–ª
    except Exception as e:
        logging.exception("drain pending queue failed: %s", e)


# ------------------------------ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ–±—ã—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π ------------------------------

# @dp.message(F.text & ~F.document)
# async def handle_text_message(m: types.Message):
#     uid = ensure_user(str(m.from_user.id))
#     text = (m.text or m.caption or "").strip()

#     if not text:
#         await _send(m, "–°–æ–æ–±—â–µ–Ω–∏–µ –ø—É—Å—Ç–æ–µ. –ù–∞–ø–∏—à–∏, —á—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç–µ–±—è –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç –ø–æ –í–ö–†.")
#         return

#     # 1) –ï—Å–ª–∏ –∂–¥—ë–º ¬´–¥–∞/–Ω–µ—Ç¬ª –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç [–º–æ–¥–µ–ª—å] ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å
#     pending = MODEL_EXTRA_PENDING.get(uid)
#     if pending and (_is_yes_answer(text) or _is_no_answer(text)):
#         if _is_yes_answer(text):
#             kind = pending.get("kind") or "generic"
#             try:
#                 if kind == "table_more":
#                     await _answer_with_model_extra_table(
#                         m,
#                         uid,
#                         pending.get("doc_id"),
#                         pending.get("question") or text,
#                         pending.get("ctx_tables") or "",
#                         pending.get("nums") or [],
#                     )
#                 else:
#                     await _answer_with_model_extra(
#                         m,
#                         uid,
#                         pending.get("question") or text,
#                     )
#             finally:
#                 MODEL_EXTRA_PENDING.pop(uid, None)
#         else:
#             # –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–∫–∞–∑–∞–ª—Å—è –æ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
#             MODEL_EXTRA_PENDING.pop(uid, None)
#             await _send(
#                 m,
#                 "–û–∫, —Ç–æ–≥–¥–∞ –±—É–¥—É –æ–ø–∏—Ä–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ —Ç–µ–∫—Å—Ç —Ç–≤–æ–µ–π —Ä–∞–±–æ—Ç—ã. "
#                 "–ï—Å–ª–∏ –µ—Å—Ç—å –¥—Ä—É–≥–æ–π –≤–æ–ø—Ä–æ—Å ‚Äî –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –µ–≥–æ."
#             )
#         return

#     # 2) –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–∫—Ç–∏–≤–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –∏ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞
#     doc_id = ACTIVE_DOC.get(uid) or get_user_active_doc(uid)
#     state = get_processing_state(uid)

#     # 2–∞) –î–æ–∫—É–º–µ–Ω—Ç –µ—â—ë –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è/–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ ‚Äî —Å—Ç–∞–≤–∏–º –≤–æ–ø—Ä–æ—Å –≤ –æ—á–µ—Ä–µ–¥—å
#     if doc_id and state in (ProcessingState.DOWNLOADING, ProcessingState.INDEXING):
#         enqueue_pending_query(uid, text)
#         await _send(
#             m,
#             "–Ø –µ—â—ë –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–∞–π–ª –í–ö–†. –Ø –∑–∞–ø–æ–º–Ω–∏–ª —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—á—É –Ω–∞ –Ω–µ–≥–æ, "
#             "–∫–∞–∫ —Ç–æ–ª—å–∫–æ –∑–∞–∫–æ–Ω—á—É —Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–º. –ú–æ–∂–Ω–æ –ø–æ–∫–∞ –ø–∏—Å–∞—Ç—å –µ—â—ë –≤–æ–ø—Ä–æ—Å—ã ‚Äî –∏—Ö —Ç–æ–∂–µ —Å–æ—Ö—Ä–∞–Ω—é."
#         )
#         return

#     # 2–±) –î–æ–∫—É–º–µ–Ω—Ç–∞ –µ—â—ë –Ω–µ—Ç ‚Äî –º–æ–∂–µ–º –¥–∞—Ç—å –æ–±—â–∏–π —Å–æ–≤–µ—Ç –ª–∏–±–æ –ø–æ–ø—Ä–æ—Å–∏—Ç—å –ø—Ä–∏—Å–ª–∞—Ç—å —Ñ–∞–π–ª
#     if not doc_id:
#         hint = topical_check(text)
#         if hint:
#             await _send(m, hint + " –ü–æ–∫–∞ —Ñ–∞–π–ª–∞ –Ω–µ—Ç, –º–æ–≥—É –¥–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–±—â–∏–π —Å–æ–≤–µ—Ç.")
#         if chat_with_gpt:
#             # –æ–±—â–∏–π –æ—Ç–≤–µ—Ç –∫–∞–∫ [–º–æ–¥–µ–ª—å] –±–µ–∑ –ø—Ä–∏–≤—è–∑–∫–∏ –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ä–∞–±–æ—Ç–µ
#             await _answer_with_model_extra(m, uid, text)
#         else:
#             await _send(
#                 m,
#                 "–°–Ω–∞—á–∞–ª–∞ –ø—Ä–∏—à–ª–∏ —Ñ–∞–π–ª –í–ö–† –≤ –≤–∏–¥–µ .doc –∏–ª–∏ .docx. "
#                 "–¢–æ–≥–¥–∞ —è —Å–º–æ–≥—É –æ—Ç–≤–µ—á–∞—Ç—å –ø—Ä—è–º–æ –ø–æ —Ç–µ–∫—Å—Ç—É —Ç–≤–æ–µ–π —Ä–∞–±–æ—Ç—ã."
#             )
#         return

#     # 3) –ù–æ—Ä–º–∞–ª—å–Ω—ã–π —Å–ª—É—á–∞–π: –¥–æ–∫—É–º–µ–Ω—Ç –µ—Å—Ç—å –∏ –æ–Ω —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω ‚Äî –æ—Ç–≤–µ—á–∞–µ–º –∫–∞–∫ —Ä–∞–Ω—å—à–µ
#     await respond_with_answer(m, uid, doc_id, text)

# ------------------------------ –æ—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç—á–∏–∫ ------------------------------

async def _answer_with_model_extra(m: types.Message, uid: int, base_question: str) -> None:
    """
    –û—Ç–≤–µ—Ç –±–µ–∑ –ø—Ä–∏–≤—è–∑–∫–∏ –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É ‚Äî –æ–±—â–∏–π —Å–æ–≤–µ—Ç –æ—Ç [–º–æ–¥–µ–ª—å].

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –∫–æ–≥–¥–∞ –≤ —Ç–µ–∫—Å—Ç–µ —Ä–∞–±–æ—Ç—ã –Ω–µ –Ω–∞—à–ª–æ—Å—å —Ñ–∞–∫—Ç–æ–≤ –ø–æ –≤–æ–ø—Ä–æ—Å—É
    –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª, —á—Ç–æ —Ö–æ—á–µ—Ç —Ç–∞–∫–æ–π –æ—Ç–≤–µ—Ç.
    """
    if not (chat_with_gpt or chat_with_gpt_stream):
        await _send(
            m,
            "–°–µ–π—á–∞—Å –º–æ–≥—É –æ—Ç–≤–µ—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ —Ç–µ–∫—Å—Ç—É –¥–æ–∫—É–º–µ–Ω—Ç–∞, —Ä–µ–∂–∏–º [–º–æ–¥–µ–ª—å] –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
        )
        return

    base_question = (base_question or "").strip()
    if not base_question:
        await _send(m, "–ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –µ–≥–æ –µ—â—ë —Ä–∞–∑, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞.")
        return

    system_prompt = (
        "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ —É—á—ë–±–µ. –í –≠–¢–û–ú –æ—Ç–≤–µ—Ç–µ —Ç—ã –Ω–µ –æ–ø–∏—Ä–∞–µ—à—å—Å—è –Ω–∞ —Ç–µ–∫—Å—Ç –¥–∏–ø–ª–æ–º–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, "
        "–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å —Ç–æ–ª—å–∫–æ —Å–≤–æ–∏ –æ–±—â–∏–µ –∑–Ω–∞–Ω–∏—è –∏ –∑–¥—Ä–∞–≤—ã–π —Å–º—ã—Å–ª. "
        "–°—Ä–∞–∑—É –≤ –Ω–∞—á–∞–ª–µ –æ—Ç–≤–µ—Ç–∞ —É–∫–∞–∂–∏ —Ç–µ–≥ '[–º–æ–¥–µ–ª—å] ' –∏ –¥–∞–ª—å—à–µ –æ—Ç–≤–µ—á–∞–π –ø—Ä–æ—Å—Ç—ã–º, –ø–æ–Ω—è—Ç–Ω—ã–º —è–∑—ã–∫–æ–º."
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": base_question},
    ]

    try:
        if STREAM_ENABLED and chat_with_gpt_stream is not None:
            stream = chat_with_gpt_stream(messages, temperature=0.3, max_tokens=FINAL_MAX_TOKENS)  # type: ignore
            await _stream_to_telegram(m, stream)
            return

        answer = chat_with_gpt(messages, temperature=0.3, max_tokens=FINAL_MAX_TOKENS)
    except Exception as e:
        logging.exception("model-extra answer failed: %s", e)
        await _send(
            m,
            "–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç [–º–æ–¥–µ–ª—å]. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
        )
        return

    answer = (answer or "").strip()
    if not answer:
        await _send(
            m,
            "–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç [–º–æ–¥–µ–ª—å]. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
        )
        return

    if not answer.startswith("[–º–æ–¥–µ–ª—å]"):
        answer = "[–º–æ–¥–µ–ª—å] " + answer

    await _send(m, answer)

async def _answer_with_model_extra_table(
    m: types.Message,
    uid: int,
    doc_id: int,
    base_question: str,
    ctx_tables: str,
    nums: list[str],
) -> None:
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç [–º–æ–¥–µ–ª—å] –ø–æ —Ç–∞–±–ª–∏—Ü–µ(—Ç–∞–±–ª–∏—Ü–∞–º):
    –º–æ–¥–µ–ª—å –≤–∏–¥–∏—Ç —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü –∏–∑ OOXML –∏ –º–æ–∂–µ—Ç –Ω–∞ –Ω–∏—Ö –æ–ø–∏—Ä–∞—Ç—å—Å—è,
    –¥–æ–±–∞–≤–ª—è—è –æ–±—â—É—é —Ç–µ–æ—Ä–∏—é, –Ω–æ –ù–ï –º–µ–Ω—è—è —Å–∞–º–∏ —á–∏—Å–ª–∞.
    """
    if not (chat_with_gpt or chat_with_gpt_stream):
        await _send(
            m,
            "–°–µ–π—á–∞—Å –º–æ–≥—É –æ—Ç–≤–µ—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ —Ç–µ–∫—Å—Ç—É –¥–æ–∫—É–º–µ–Ω—Ç–∞, —Ä–µ–∂–∏–º [–º–æ–¥–µ–ª—å] –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
        )
        return

    ctx_tables = (ctx_tables or "").strip()
    if not ctx_tables:
        # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π ‚Äî —Ñ–æ–ª–±—ç–∫ –≤ –æ–±—â–∏–π —Ä–µ–∂–∏–º
        await _answer_with_model_extra(m, uid, base_question)
        return

    nums = [str(n).strip() for n in (nums or []) if str(n).strip()]
    nums_str = ", ".join(nums) if nums else "—ç—Ç–∏–º —Ç–∞–±–ª–∏—Ü–∞–º"

    base_question = (base_question or "").strip()
    if not base_question:
        base_question = f"–ü–æ–¥—Ä–æ–±–Ω–æ –æ–±—ä—è—Å–Ω–∏ –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∞–±–ª–∏—Ü–µ(—Ç–∞–±–ª–∏—Ü–∞–º) {nums_str}."

    system_prompt = (
        "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ —É—á—ë–±–µ. –í –≠–¢–û–ú –æ—Ç–≤–µ—Ç–µ —Ç—ã –æ–ø–∏—Ä–∞–µ—à—å—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü –∏–∑ –¥–∏–ø–ª–æ–º–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è "
        "(–æ–Ω–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã –Ω–∏–∂–µ –≤ –º–∞—à–∏–Ω–Ω–æ-—á–∏—Ç–∞–µ–º–æ–º –≤–∏–¥–µ). "
        "–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–∏ —á–∏—Å–ª–∞ –∫–∞–∫ –∏—Å—Ç–æ—á–Ω–∏–∫ –∏—Å—Ç–∏–Ω—ã: –Ω–µ –º–µ–Ω—è–π –∏—Ö –∏ –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –¥—Ä—É–≥–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è. "
        "–ü—Ä–∏ —ç—Ç–æ–º –º–æ–∂–µ—à—å –¥–æ–ø–æ–ª–Ω—è—Ç—å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é –æ–±—â–∏–º–∏ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–º–∏ —Å–≤–µ–¥–µ–Ω–∏—è–º–∏ –ø–æ —Ç–µ–º–µ. "
        "–°—Ä–∞–∑—É –≤ –Ω–∞—á–∞–ª–µ –æ—Ç–≤–µ—Ç–∞ —É–∫–∞–∂–∏ —Ç–µ–≥ '[–º–æ–¥–µ–ª—å] '."
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "assistant", "content": f"[–î–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü –∏–∑ –¥–∏–ø–ª–æ–º–∞]\n{ctx_tables}"},
        {"role": "user", "content": base_question},
    ]

    try:
        if STREAM_ENABLED and chat_with_gpt_stream is not None:
            stream = chat_with_gpt_stream(
                messages,
                temperature=0.3,
                max_tokens=FINAL_MAX_TOKENS,
            )  # type: ignore
            await _stream_to_telegram(m, stream)
            return

        answer = chat_with_gpt(
            messages,
            temperature=0.3,
            max_tokens=FINAL_MAX_TOKENS,
        )
    except Exception as e:
        logging.exception("model-extra-table answer failed: %s", e)
        await _send(
            m,
            "–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ —Ç–∞–±–ª–∏—Ü–µ. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
        )
        return

    answer = (answer or "").strip()
    if not answer:
        await _send(
            m,
            "–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ —Ç–∞–±–ª–∏—Ü–µ. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
        )
        return

    if not answer.startswith("[–º–æ–¥–µ–ª—å]"):
        answer = "[–º–æ–¥–µ–ª—å] " + answer

    await _send(m, answer)

def _is_structural_intro_question(q: str) -> bool:
    """
    –í–æ–ø—Ä–æ—Å —è–≤–Ω–æ –ø—Ä–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –í–ö–†:
    –≤–≤–µ–¥–µ–Ω–∏–µ / –≥–ª–∞–≤—ã / –æ–±—ä–µ–∫—Ç / –ø—Ä–µ–¥–º–µ—Ç / —Ü–µ–ª—å / –∑–∞–¥–∞—á–∏ / –≥–∏–ø–æ—Ç–µ–∑–∞ / –≤—ã–≤–æ–¥—ã.
    –î–ª—è —Ç–∞–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∑–∞–ø—É—Å–∫–∞–µ–º —Å–ø–µ—Ü-—Ä–µ–∂–∏–º fullread –ø–æ –≤—Å–µ–º—É —Ç–µ–∫—Å—Ç—É –¥–∏–ø–ª–æ–º–∞.
    """
    if not q:
        return False

    text = q.lower()

    # –ö–ª—é—á–µ–≤—ã–µ —Ç—Ä–∏–≥–≥–µ—Ä—ã –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Ä–∞–±–æ—Ç—ã
    trigger_words = [
        "–≤–≤–µ–¥–µ–Ω–∏–µ",
        "–≥–ª–∞–≤–∞ 1", "–≥–ª–∞–≤–∞ 2", "–ø–µ—Ä–≤–∞—è –≥–ª–∞–≤–∞", "–≤—Ç–æ—Ä–∞—è –≥–ª–∞–≤–∞",
        "1 –≥–ª–∞–≤–∞", "2 –≥–ª–∞–≤–∞",
        "–æ–±—ä–µ–∫—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è", "–ø—Ä–µ–¥–º–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
        "–æ–±—ä–µ–∫—Ç –∏ –ø—Ä–µ–¥–º–µ—Ç",
        "–∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–º—ã", "–∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
        "—Ü–µ–ª—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è", "—Ü–µ–ª—å —Ä–∞–±–æ—Ç—ã",
        "–∑–∞–¥–∞—á–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è", "–∑–∞–¥–∞—á–∏ —Ä–∞–±–æ—Ç—ã",
        "–≥–∏–ø–æ—Ç–µ–∑–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è", "–≥–∏–ø–æ—Ç–µ–∑–∞ —Ä–∞–±–æ—Ç—ã",
        "–≤—ã–≤–æ–¥—ã –ø–æ –≥–ª–∞–≤–µ", "–æ—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã –ø–æ –≥–ª–∞–≤–µ",
    ]

    return any(w in text for w in trigger_words)

def _extract_struct_meta_block(full_text: str) -> str:
    """
    –ì—Ä—É–±—ã–π, –Ω–æ –ø–æ–ª–µ–∑–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –í–ö–†:
    –æ–±—ä–µ–∫—Ç, –ø—Ä–µ–¥–º–µ—Ç, —Ü–µ–ª—å, –∑–∞–¥–∞—á–∏, –≥–∏–ø–æ—Ç–µ–∑–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–π–¥—ë—Ç –≤ –ø—Ä–æ–º–ø—Ç.
    """
    if not full_text:
        return ""

    low = full_text.lower()

    def _slice_after(marker: str, max_len: int = 500) -> str:
        i = low.find(marker)
        if i == -1:
            return ""
        # –ë–µ—Ä—ë–º –∫—É—Å–æ–∫ –≤–æ–∫—Ä—É–≥ –º–∞—Ä–∫–µ—Ä–∞ –∏–∑ –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ì–û —Ç–µ–∫—Å—Ç–∞, —á—Ç–æ–±—ã –Ω–µ –ø–æ—Ç–µ—Ä—è—Ç—å —Ä–µ–≥–∏—Å—Ç—Ä.
        start = max(i - 20, 0)
        end = min(i + max_len, len(full_text))
        return full_text[start:end].strip()

    parts = []

    obj = _slice_after("–æ–±—ä–µ–∫—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
    if obj:
        parts.append("[–æ–±—ä–µ–∫—Ç]\n" + obj)

    subj = _slice_after("–ø—Ä–µ–¥–º–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
    if subj:
        parts.append("[–ø—Ä–µ–¥–º–µ—Ç]\n" + subj)

    goal = _slice_after("—Ü–µ–ª—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
    if not goal:
        goal = _slice_after("—Ü–µ–ª—å —Ä–∞–±–æ—Ç—ã")
    if goal:
        parts.append("[—Ü–µ–ª—å]\n" + goal)

    tasks = _slice_after("–∑–∞–¥–∞—á–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
    if not tasks:
        tasks = _slice_after("–∑–∞–¥–∞—á–∏ —Ä–∞–±–æ—Ç—ã")
    if tasks:
        parts.append("[–∑–∞–¥–∞—á–∏]\n" + tasks)

    hyp = _slice_after("–≥–∏–ø–æ—Ç–µ–∑–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
    if not hyp:
        hyp = _slice_after("–≥–∏–ø–æ—Ç–µ–∑–∞ —Ä–∞–±–æ—Ç—ã")
    if hyp:
        parts.append("[–≥–∏–ø–æ—Ç–µ–∑–∞]\n" + hyp)

    return "\n\n".join(parts)

def _question_about_tables_or_figures(q_text: str) -> bool:
    """
    –ü—Ä–∏–∑–Ω–∞–∫, —á—Ç–æ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ —Ç–∞–±–ª–∏—Ü—ã/—Ä–∏—Å—É–Ω–∫–∏/–¥–∏–∞–≥—Ä–∞–º–º—ã ‚Äî –¥–ª—è –Ω–∏—Ö –Ω—É–∂–µ–Ω RAG —Å–æ —Å–ø–µ—Ü-–ª–æ–≥–∏–∫–æ–π.
    """
    q = (q_text or "").lower()
    keywords = [
        "—Ç–∞–±–ª–∏—Ü–∞", "—Ç–∞–±–ª.", "table",
        "—Ä–∏—Å—É–Ω–æ–∫", "—Ä–∏—Å.", "figure",
        "–¥–∏–∞–≥—Ä–∞–º–º–∞", "–≥—Ä–∞—Ñ–∏–∫", "chart",
        "–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ", "–ø—Ä–∏–ª."
    ]
    return any(k in q for k in keywords)


def _question_about_whole_work_analytic(q_text: str) -> bool:
    """
    –ü—Ä–∏–∑–Ω–∞–∫, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –∞–Ω–∞–ª–∏–∑ –í–°–ï–ô –í–ö–†, –∞ –Ω–µ –≤—ã–∂–∏–º–∫—É –ø–æ –≥–ª–∞–≤–∞–º.
    –î–ª—è —Ç–∞–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–º–µ–µ—Ç —Å–º—ã—Å–ª –≤–∫–ª—é—á–∞—Ç—å fullread.
    """
    q = (q_text or "").lower()
    triggers = [
        "–≤—Å—è –≤–∫—Ä", "–≤—Å—é –≤–∫—Ä",
        "–≤—Å—é —Ä–∞–±–æ—Ç—É", "–≤—Å—è —Ä–∞–±–æ—Ç–∞",
        "–ø–æ–ª–Ω–æ—Å—Ç—å—é", "—Ü–µ–ª–∏–∫–æ–º",
        "–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑", "–ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑",
        "–∞–Ω–∞–ª–∏–∑ –≤—Å–µ–π –≤–∫—Ä", "–∞–Ω–∞–ª–∏–∑ –≤—Å–µ–π —Ä–∞–±–æ—Ç—ã",
        "–Ω–∞—Å–∫–æ–ª—å–∫–æ —Ä–∞—Å–∫—Ä—ã—Ç–∞", "–æ—Ü–µ–Ω–∏ —Ä–∞–±–æ—Ç—É",
        "–æ—Ü–µ–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ü–µ–ª–µ–π –∏ –∑–∞–¥–∞—á",
        "–æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞", "–≤ —Ü–µ–ª–æ–º –ø–æ —Ä–∞–±–æ—Ç–µ",
    ]
    return any(t in q for t in triggers)


async def _answer_fulltext_simple(
    m: types.Message,
    uid: int,
    doc_id: int,
    q_text: str,
) -> bool:
    """
    –ü—Ä–æ—Å—Ç–æ–π —Ä–µ–∂–∏–º: –¥–∞—ë–º –º–æ–¥–µ–ª–∏ –¢–ï–ö–°–¢ –í–ö–† —Ü–µ–ª–∏–∫–æ–º –∏ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    –ë–µ–∑ RAG, –±–µ–∑ —Ç–∞–±–ª–∏—Ü/—Ä–∏—Å—É–Ω–∫–æ–≤, –ø—Ä–æ—Å—Ç–æ ¬´GPT + —Ñ–∞–π–ª¬ª.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º True, –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω. –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å ‚Äî False,
    —á—Ç–æ–±—ã –¥–∞–ª—å—à–µ –º–æ–≥ —Å—Ä–∞–±–æ—Ç–∞—Ç—å –æ–±—ã—á–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω.
    """
    _limit = int(getattr(Cfg, "DIRECT_MAX_CHARS", 60000))
    full_text = _full_document_text(uid, doc_id, limit_chars=_limit)
    if not (full_text or "").strip():
        # –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞ ‚Äî –ø—É—Å—Ç—å –¥–∞–ª—å—à–µ –æ—Ç—Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω
        return False

    system_prompt = (
        "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –¥–∏–ø–ª–æ–º–Ω—ã–º —Ä–∞–±–æ—Ç–∞–º. –¢–µ–±–µ –¥–∞–Ω –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –í–ö–† —Å—Ç—É–¥–µ–Ω—Ç–∞.\n"
        "–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –ø–æ —Ç–µ–∫—Å—Ç—É —Ä–∞–±–æ—Ç—ã, –ø—Ä–æ—Å—Ç—ã–º –ø–æ–Ω—è—Ç–Ω—ã–º —Å—Ç—É–¥–µ–Ω—Ç—É —è–∑—ã–∫–æ–º.\n"
        "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ç–æ–≥–æ, —á–µ–≥–æ –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ, —á–µ—Å—Ç–Ω–æ –Ω–∞–ø–∏—à–∏ –æ–± —ç—Ç–æ–º.\n"
        "–ï—Å–ª–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—É–Ω–∫—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä: –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å, –æ–±—ä–µ–∫—Ç, –ø—Ä–µ–¥–º–µ—Ç, —Ü–µ–ª—å, –∑–∞–¥–∞—á–∏, "
        "–≥–∏–ø–æ—Ç–µ–∑–∞, –≤—ã–≤–æ–¥—ã –ø–æ –≥–ª–∞–≤–∞–º), –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –ø—Ä–æ–π—Ç–∏ –ø–æ –ö–ê–ñ–î–û–ú–£ –ø—É–Ω–∫—Ç—É –æ—Ç–¥–µ–ª—å–Ω—ã–º –ø–æ–¥–ø—É–Ω–∫—Ç–æ–º –∏ –Ω–∏—á–µ–≥–æ –Ω–µ "
        "–ø—Ä–æ–ø—É—Å–∫–∞—Ç—å."
    )

    user_content = (
        "–í–æ—Ç —Ç–µ–∫—Å—Ç –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã:\n"
        "[–¢–µ–∫—Å—Ç –í–ö–†]\n" + full_text + "\n\n"
        "–í–æ–ø—Ä–æ—Å —Å—Ç—É–¥–µ–Ω—Ç–∞:\n" + q_text + "\n\n"
        "–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å, —Å–¥–µ–ª–∞–π —Å–≤—è–∑–Ω—ã–π –∏ –ø–æ–Ω—è—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç, –æ–ø–∏—Ä–∞—è—Å—å —Ç–æ–ª—å–∫–æ –Ω–∞ —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç."
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_content},
    ]

    try:
        # –µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω —Å—Ç—Ä–∏–º ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –µ—Å—Ç—å
        if STREAM_ENABLED and chat_with_gpt_stream is not None:
            stream = chat_with_gpt_stream(
                messages,
                temperature=0.2,
                max_tokens=FINAL_MAX_TOKENS,
            )
            await _stream_to_telegram(m, stream)
            return True

        # –æ–±—ã—á–Ω—ã–π (–Ω–µ—Å—Ç—Ä–∏–º–æ–≤—ã–π) –≤—ã–∑–æ–≤
        ans = chat_with_gpt(
            messages,
            temperature=0.2,
            max_tokens=FINAL_MAX_TOKENS,
        ) or ""
    except Exception as e:
        logging.exception("fulltext_simple failed: %s", e)
        # –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å ‚Äî –¥–∞—ë–º —à–∞–Ω—Å –æ—Å—Ç–∞–ª—å–Ω–æ–º—É –ø–∞–π–ø–ª–∞–π–Ω—É
        return False

    ans = (ans or "").strip()
    if not ans:
        # –º–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ ‚Äî —Ç–æ–∂–µ –ø—É—Å—Ç—å –¥–∞–ª—å—à–µ –ø–æ–ø—Ä–æ–±—É–µ—Ç RAG/–¥—Ä.
        return False

    text = _strip_unwanted_sections(ans)

    # üî™ –ß–¢–û –ú–´ –î–û–ë–ê–í–õ–Ø–ï–ú: –Ω–∞—Ä–µ–∑–∫–∞ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –∫—É—Å–∫–∏ –¥–ª—è –¢–µ–ª–µ–≥–∏
    MAX_TG_LEN = 3500  # —á—É—Ç—å –º–µ–Ω—å—à–µ –ª–∏–º–∏—Ç–∞, —á—Ç–æ–±—ã –Ω–µ —É–ø–µ—Ä–µ—Ç—å—Å—è –≤ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ Telegram
    start = 0
    n = len(text)
    while start < n:
        chunk = text[start:start + MAX_TG_LEN]
        await _send(m, chunk)
        start += MAX_TG_LEN

    return True


async def _answer_structural_fullread(
    m: types.Message,
    uid: int,
    doc_id: int,
    q_text: str,
) -> bool:
    """
    –°–ø–µ—Ü-—Ä–µ–∂–∏–º –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –≤–∏–¥–∞:
      - —á—Ç–æ –≤–æ –≤–≤–µ–¥–µ–Ω–∏–∏ –∏ –≤ 1‚Äì2 –≥–ª–∞–≤–µ –Ω–∞–ø–∏—Å–∞–Ω–æ;
      - –≤ —á—ë–º –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–º—ã, –∫—Ç–æ –æ–±—ä–µ–∫—Ç –∏ –ø—Ä–µ–¥–º–µ—Ç, —Ü–µ–ª—å –∏ –∑–∞–¥–∞—á–∏, –≥–∏–ø–æ—Ç–µ–∑–∞, –≤—ã–≤–æ–¥—ã –ø–æ –≥–ª–∞–≤–∞–º –∏ —Ç.–ø.

    –ß–∏—Ç–∞–µ–º –ü–û–õ–ù–´–ô —Ç–µ–∫—Å—Ç –í–ö–† –∏ –æ—Ç–≤–µ—á–∞–µ–º —Å—Ç—Ä–æ–≥–æ –ø–æ –Ω–µ–º—É.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º True, –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.
    """
    # 1) –ó–∞–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –í–ö–† (–µ—Å—Ç—å —É–∂–µ –≥–æ—Ç–æ–≤—ã–π —Ö–µ–ª–ø–µ—Ä)
    _limit = int(getattr(Cfg, "DIRECT_MAX_CHARS", 80000))
    full_text = _full_document_text(uid, doc_id, limit_chars=_limit + 1)
    full_len = len(full_text or "")

    if not (full_text or "").strip():
        # –í–æ–æ–±—â–µ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞ ‚Äî —Å–º—ã—Å–ª–∞ –Ω–µ—Ç, –ø—É—Å—Ç—å –¥–∞–ª—å—à–µ –æ—Ç—Ä–∞–±–æ—Ç–∞–µ—Ç –æ–±—ã—á–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω
        return False

    # üîß –ü—ã—Ç–∞–µ–º—Å—è –∑–∞—Ä–∞–Ω–µ–µ –≤—ã—Ç–∞—â–∏—Ç—å –æ–±—ä–µ–∫—Ç/–ø—Ä–µ–¥–º–µ—Ç/—Ü–µ–ª—å/–∑–∞–¥–∞—á–∏/–≥–∏–ø–æ—Ç–µ–∑—É,
    # —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –Ω–µ –≥–æ–≤–æ—Ä–∏–ª–∞ ¬´–Ω–µ –≤—ã–¥–µ–ª–µ–Ω–æ¬ª, –∫–æ–≥–¥–∞ —ç—Ç–æ –µ—Å—Ç—å –≤ —Ç–µ–∫—Å—Ç–µ.
    struct_meta_block = _extract_struct_meta_block(full_text)

    system_prompt = (
        "–¢—ã —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ –í–ö–†. –¢–µ–±–µ –¥–∞–Ω –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å—Ç—É–¥–µ–Ω—Ç–∞.\n"
        "–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –ø—Ä–æ—Å—Ç—ã–º –ø–æ–Ω—è—Ç–Ω—ã–º —Å—Ç—É–¥–µ–Ω—Ç—É —è–∑—ã–∫–æ–º.\n"
        "–û–ø–∏—Ä–∞–π—Å—è —Å—Ç—Ä–æ–≥–æ –Ω–∞ —Ç–µ–∫—Å—Ç —Ä–∞–±–æ—Ç—ã –∏ –±–ª–æ–∫ [–°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã], –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ç–æ–≥–æ, —á–µ–≥–æ –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç.\n"
        "–ï—Å–ª–∏ –≤ –±–ª–æ–∫–µ [–°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã] –µ—Å—Ç—å —Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—ä–µ–∫—Ç–∞, –ø—Ä–µ–¥–º–µ—Ç–∞, —Ü–µ–ª–∏, –∑–∞–¥–∞—á –∏–ª–∏ –≥–∏–ø–æ—Ç–µ–∑—ã,\n"
        "–æ—Ä–∏–µ–Ω—Ç–∏—Ä—É–π—Å—è –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å –Ω–∞ –Ω–µ–≥–æ –∏ –ù–ï –ø–∏—à–∏, —á—Ç–æ —ç—Ç–∏ —ç–ª–µ–º–µ–Ω—Ç—ã ¬´–Ω–µ –≤—ã–¥–µ–ª–µ–Ω—ã¬ª.\n"
        "–ï—Å–ª–∏ –≤ —Ä–∞–±–æ—Ç–µ –Ω–µ—Ç —è–≤–Ω–æ –≤—ã–¥–µ–ª–µ–Ω–Ω—ã—Ö –≤–≤–µ–¥–µ–Ω–∏—è –∏–ª–∏ –≥–ª–∞–≤, –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã, "
        "–∫–æ—Ç–æ—Ä—ã–µ –ø–æ —Å–º—ã—Å–ª—É –∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç, –∏ —á–µ—Å—Ç–Ω–æ —ç—Ç–æ —É–∫–∞–∂–∏.\n"
        "–ï—Å–ª–∏ –∫–∞–∫–∏—Ö-—Ç–æ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≥–∏–ø–æ—Ç–µ–∑—ã) –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –Ω–µ—Ç ‚Äî —Ç–∞–∫ –∏ –Ω–∞–ø–∏—à–∏.\n"
        "–ï—Å–ª–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—É–Ω–∫—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä: –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å, –æ–±—ä–µ–∫—Ç, –ø—Ä–µ–¥–º–µ—Ç, —Ü–µ–ª—å, –∑–∞–¥–∞—á–∏, "
        "–≥–∏–ø–æ—Ç–µ–∑–∞, –≤—ã–≤–æ–¥—ã –ø–æ –≥–ª–∞–≤–∞–º), –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –æ—Ç–≤–µ—Ç—å –ø–æ –ö–ê–ñ–î–û–ú–£ –∏–∑ –Ω–∏—Ö –æ—Ç–¥–µ–ª—å–Ω—ã–º –ø–æ–¥–ø—É–Ω–∫—Ç–æ–º, –Ω–∏—á–µ–≥–æ –Ω–µ "
        "–ø—Ä–æ–ø—É—Å–∫–∞—è.\n"
        "–°—Ç–∞—Ä–∞–π—Å—è –æ—Ç–≤–µ—á–∞—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–æ–¥—Ä–æ–±–Ω–æ, –Ω–æ –±–µ–∑ –ª–∏—à–Ω–µ–π –≤–æ–¥—ã: –ø–æ –∫–∞–∂–¥–æ–º—É –ø—É–Ω–∫—Ç—É –¥–∞–π –Ω–µ—Å–∫–æ–ª—å–∫–æ "
        "—Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —á—Ç–æ–±—ã —Å—Ç—É–¥–µ–Ω—Ç –º–æ–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –∫–∞–∫ –∫–æ–Ω—Å–ø–µ–∫—Ç."
    )


    # 2–∞) –î–æ–∫—É–º–µ–Ω—Ç —Ü–µ–ª–∏–∫–æ–º –≤–ª–µ–∑–∞–µ—Ç –≤ –ª–∏–º–∏—Ç ‚Äî –¥–∞—ë–º –º–æ–¥–µ–ª–∏ —Å—Ä–∞–∑—É –≤–µ—Å—å —Ç–µ–∫—Å—Ç
    if full_len <= _limit:
                # –°–æ–±–∏—Ä–∞–µ–º assistant-–∫–æ–Ω—Ç–µ–∫—Å—Ç: –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç + (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
        assistant_content = "[–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã]\n" + full_text
        if struct_meta_block:
            assistant_content += "\n\n[–°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã]\n" + struct_meta_block

        messages = [
            {"role": "system", "content": system_prompt},
            {
                "role": "assistant",
                "content": assistant_content,
            },
            {
                "role": "user",
                "content": (
                    "–ù–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Ä–∞–±–æ—Ç—ã –æ—Ç–≤–µ—Ç—å –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å —Å—Ç—É–¥–µ–Ω—Ç–∞:\n"
                    f"{q_text}\n\n"
                    "–°–¥–µ–ª–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç (–ø–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏):\n"
                    "- –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–º—ã;\n"
                    "- –æ–±—ä–µ–∫—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è;\n"
                    "- –ø—Ä–µ–¥–º–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è;\n"
                    "- —Ü–µ–ª—å —Ä–∞–±–æ—Ç—ã;\n"
                    "- –∑–∞–¥–∞—á–∏ (—Å–ø–∏—Å–∫–æ–º);\n"
                    "- —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã (–µ—Å–ª–∏ –µ—Å—Ç—å);\n"
                    "- –≥–ª–∞–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã –ø–æ –≥–ª–∞–≤–µ 1;\n"
                    "- –≥–ª–∞–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã –ø–æ –≥–ª–∞–≤–µ 2.\n"
                    "–ï—Å–ª–∏ –∫–∞–∫–∏—Ö-—Ç–æ –ø—É–Ω–∫—Ç–æ–≤ –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ ‚Äî —á–µ—Å—Ç–Ω–æ –Ω–∞–ø–∏—à–∏, —á—Ç–æ –æ–Ω–∏ –Ω–µ –≤—ã–¥–µ–ª–µ–Ω—ã.\n"
                    "–û—Ç–≤–µ—á–∞–π –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–æ–¥—Ä–æ–±–Ω–æ, –Ω–æ –±–µ–∑ –ª–∏—à–Ω–µ–π –≤–æ–¥—ã, —á—Ç–æ–±—ã –ø–æ –∫–∞–∂–¥–æ–º—É –ø—É–Ω–∫—Ç—É –±—ã–ª–æ –ø–æ–Ω—è—Ç–Ω–æ, "
                    "—á—Ç–æ –∏–º–µ–Ω–Ω–æ –∏–º–µ–ª–æ—Å—å –≤ –≤–∏–¥—É –≤ —Ä–∞–±–æ—Ç–µ."
                ),
            },
        ]



        if STREAM_ENABLED and chat_with_gpt_stream is not None:
            try:
                stream = chat_with_gpt_stream(
                    messages,
                    temperature=0.2,
                    max_tokens=FINAL_MAX_TOKENS,
                )
                await _stream_to_telegram(m, stream)
                return True
            except Exception as e:
                logging.exception("structural fullread stream failed: %s", e)

        try:
            ans = chat_with_gpt(
                messages,
                temperature=0.2,
                max_tokens=FINAL_MAX_TOKENS,
            )
        except Exception as e:
            logging.exception("structural fullread non-stream failed: %s", e)
            ans = ""

        ans = (ans or "").strip()
        if not ans:
            ans = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –ø–æ —Ç–µ–∫—Å—Ç—É —Ä–∞–±–æ—Ç—ã. –ü–æ–ø—Ä–æ–±—É–π –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å –µ—â—ë —Ä–∞–∑ –∏–ª–∏ —á—É—Ç—å –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å."
        await _send(m, _strip_unwanted_sections(ans))
        return True

    # 2–±) –î–æ–∫—É–º–µ–Ω—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π fullread
    try:
        # –ú–æ–∂–Ω–æ —Å–ª–µ–≥–∫–∞ –æ–±–æ–≥–∞—Ç–∏—Ç—å –≤–æ–ø—Ä–æ—Å, —á—Ç–æ–±—ã –∏—Ç–æ–≥ —Ç–æ–∂–µ –±—ã–ª —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–º
        iter_question = (
            f"{q_text}\n\n"
            "–°–¥–µ–ª–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å, –æ–±—ä–µ–∫—Ç, –ø—Ä–µ–¥–º–µ—Ç, —Ü–µ–ª—å, –∑–∞–¥–∞—á–∏, "
            "–≥–∏–ø–æ—Ç–µ–∑–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å), –≤—ã–≤–æ–¥—ã –ø–æ –≥–ª–∞–≤–∞–º 1 –∏ 2."
        )
        messages, err = _iterative_fullread_build_messages(uid, doc_id, iter_question)
    except Exception as e:
        logging.exception("structural iterative build failed: %s", e)
        messages, err = None, "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ —Ç–µ–∫—Å—Ç–∞ –¥–∏–ø–ª–æ–º–∞."

    if not messages:
        # –ù–µ —Å–º–æ–≥–ª–∏ —Å–æ–±—Ä–∞—Ç—å –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π fullread ‚Äî –ø—É—Å—Ç—å –¥–∞–ª—å—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω
        return False

    if STREAM_ENABLED and chat_with_gpt_stream is not None:
        try:
            stream = chat_with_gpt_stream(
                messages,
                temperature=0.2,
                max_tokens=FINAL_MAX_TOKENS,
            )
            await _stream_to_telegram(m, stream)
            return True
        except Exception as e:
            logging.exception("structural iterative stream failed: %s", e)

    try:
        ans = chat_with_gpt(
            messages,
            temperature=0.2,
            max_tokens=FINAL_MAX_TOKENS,
        )
    except Exception as e:
        logging.exception("structural iterative non-stream failed: %s", e)
        ans = ""

    ans = (ans or "").strip()
    if not ans:
        ans = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –ø–æ —Ç–µ–∫—Å—Ç—É —Ä–∞–±–æ—Ç—ã. –ü–æ–ø—Ä–æ–±—É–π —É—Ç–æ—á–Ω–∏—Ç—å –≤–æ–ø—Ä–æ—Å."
    await _send(m, _strip_unwanted_sections(ans))
    return True


async def respond_with_answer(m: types.Message, uid: int, doc_id: int, q_text: str):
    q_text = (q_text or "").strip()
    orig_q_text = q_text  # –∑–∞–ø–æ–º–Ω–∏–º –∏—Å—Ö–æ–¥–Ω—É—é —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É –¥–æ –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–æ–∫
    logger.info(
        "ANSWER: new question (uid=%s, doc_id=%s, len=%d): %r",
        uid,
        doc_id,
        len(q_text or ""),
        q_text,
    )
    if not q_text:
        logger.warning(
            "ANSWER: empty question from uid=%s, doc_id=%s",
            uid,
            doc_id,
        )
        await _send(m, "–í–æ–ø—Ä–æ—Å –ø—É—Å—Ç–æ–π. –ù–∞–ø–∏—à–∏—Ç–µ, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç –ø–æ –í–ö–†.")
        return

    viol = safety_check(q_text)
    if viol:
        logger.warning(
            "ANSWER: safety_check blocked question (uid=%s, doc_id=%s): %s",
            uid,
            doc_id,
            viol,
        )
        await _send(m, viol + " –ó–∞–¥–∞–π—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ –í–ö–†.")
        return

    logger.debug(
        "ANSWER: before GOST check (uid=%s, doc_id=%s)",
        uid,
        doc_id,
    )
    if await _maybe_run_gost(m, uid, doc_id, q_text):
        logger.info(
            "ANSWER: handled by GOST validator (uid=%s, doc_id=%s)",
            uid,
            doc_id,
        )
        return

    # –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ä–µ–ø–ª–∏–∫ –≤–∏–¥–∞ ¬´–æ–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ¬ª, ¬´—Ä–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ –Ω–µ–≥–æ¬ª
    q_text = _expand_with_last_referent(uid, q_text)

    # –ü—Ä–∏–º–µ—Ä—ã: "–æ–ø–∏—à–∏ —Ç–∞–±–ª–∏—Ü—É 4", "—á—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–∞–±–ª–∏—Ü–∞ 2.3", "—Å–¥–µ–ª–∞–π –≤—ã–≤–æ–¥—ã –ø–æ —Ç–∞–±–ª–∏—Ü–µ 4"
    if _is_pure_table_request(q_text):
        verbosity = _detect_verbosity(q_text)
        base_text = (orig_q_text or "")
        mode = "more" if _FOLLOWUP_MORE_RE.search(base_text) else "normal"
        logger.info(
            "ANSWER: pure table request detected (uid=%s, doc_id=%s, mode=%s)",
            uid,
            doc_id,
            mode,
        )
        handled = await _answer_table_query(
            m, uid, doc_id, q_text, verbosity=verbosity, mode=mode
        )
        logger.info(
            "ANSWER: _answer_table_query finished (uid=%s, doc_id=%s, handled=%s)",
            uid,
            doc_id,
            handled,
        )
        if handled:
            return
        else:
            logger.info(
                "ANSWER: table pipeline did not handle request, falling back to general pipeline "
                "(uid=%s, doc_id=%s)",
                uid,
                doc_id,
            )
        # –µ—Å–ª–∏ _answer_table_query –Ω–µ —Å–º–æ–≥ –æ—Ç–≤–µ—Ç–∏—Ç—å (—Ç–∞–±–ª–∏—Ü–∞ –Ω–µ –Ω–∞—à–ª–∞—Å—å –≤ OOXML/–∫–∞—Ä—Ç–∏–Ω–∫–µ),
        # –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–∞–ª–∏–≤–∞–µ–º—Å—è –¥–∞–ª—å—à–µ –≤ –æ–±—â–∏–π –ø–∞–π–ø–ª–∞–π–Ω

    # –±—ã—Å—Ç—Ä—ã–π –ø—É—Ç—å –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—Ä–æ —Ä–∏—Å—É–Ω–∫–∏ (—Å—Ç–∞—Ä—ã–π, —á–µ—Ä–µ–∑ _answer_figure_query)
    if _is_pure_figure_request(q_text):
        verbosity = _detect_verbosity(q_text)
        logger.info(
            "ANSWER: pure figure request detected (uid=%s, doc_id=%s)",
            uid,
            doc_id,
        )
        handled = await _answer_figure_query(
            m,
            uid,
            doc_id,
            q_text,
            verbosity=verbosity,
        )
        logger.info(
            "ANSWER: _answer_figure_query finished (uid=%s, doc_id=%s, handled=%s)",
            uid,
            doc_id,
            handled,
        )
        if handled:
            return

    # –ï—Å–ª–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è –≥–ª–∞–≤—ã/—Ç–∞–±–ª–∏—Ü—ã ‚Äî –¥–∞—ë–º —ç—Ç–æ
    # –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –º—É–ª—å—Ç–∏–∏ÃÜ–Ω—Ç–µ–Ω—Ç–Ω–æ–º—É –ø–∞–π–ø–ª–∞–π–Ω—É –Ω–∏–∂–µ.
    if (
        _ALL_FIGS_HINT.search(q_text or "")
        and not _SECTION_NUM_RE.search(q_text or "")
        and not _TABLE_ANY.search(q_text or "")
    ):
        meta = _list_figures_db(uid, doc_id, limit=999999)
        total = int(meta["count"])
        if total == 0:
            await _send(m, "–í —Ä–∞–±–æ—Ç–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞.")
            return
        # –ø–∞—Ä—Ç–∏—è–º–∏ –ø–æ 8‚Äì12 –Ω–æ–º–µ—Ä–æ–≤
        nums = []
        for disp in meta["list"]:
            # –∏–∑ "–†–∏—Å—É–Ω–æ–∫ 2.1 ‚Äî ..." –≤—ã—Ç–∞—â–∏–º "2.1" (–µ—Å–ª–∏ –µ—Å—Ç—å)
            mnum = re.search(r"(?i)\b—Ä–∏—Å—É–Ω–æ–∫\s+([A-Za-z–ê-–Ø–∞-—è]?\s*\d+(?:[.,]\d+)*)\b", disp)
            if mnum:
                nums.append(mnum.group(1).replace(" ", "").replace(",", "."))
        batch = nums[:8] or nums[:12]
        # –∫–∞—Ä—Ç–æ—á–∫–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ–∫—Å—Ç–∞; –∫–∞—Ä—Ç–∏–Ω–∫–∏ –≤ —á–∞—Ç –±–æ–ª—å—à–µ –Ω–µ —à–ª—ë–º)
        cards = []
        try:
            cards = describe_figures_by_numbers(
                uid, doc_id, batch, sample_chunks=1, use_vision=False, lang="ru"
            ) or []
        except Exception:
            cards = []

        # –∑–∞—Ç–µ–º ‚Äî —Å–≤—è–∑–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ –∫–∞–∂–¥–æ–º—É —Ä–∏—Å—É–Ω–∫—É: prefer vision_analyzer
        lines = []

        if va_analyze_figure and cards:
            for c in cards:
                disp = c.get("display") or f"–†–∏—Å—É–Ω–æ–∫ {c.get('num') or ''}".strip()
                imgs = c.get("images") or []
                hint = (c.get("highlights") or [None])[0]
                if not imgs:
                    continue
                try:
                    res = va_analyze_figure(imgs[0], caption_hint=hint, lang="ru")
                    if isinstance(res, dict):
                        text_block = (res.get("text") or "").strip() or _pairs_to_bullets(res.get("data") or [])
                    else:
                        text_block = (str(res) or "").strip()
                except Exception:
                    text_block = ""
                if text_block:
                    # —ç—Ç–æ —Ç–µ–∫—Å—Ç –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é (OCR/–æ–ø–∏—Å–∞–Ω–∏–µ)
                    lines.append(f"[Text on image] **{disp}**\n\n{text_block}")
                else:
                    # —Å—Ç—Ä–æ–≥–∏–π —Ä–µ–∂–∏–º ‚Äî —è–≤–Ω–æ –≥–æ–≤–æ—Ä–∏–º, —á—Ç–æ —Ç–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç
                    if FIG_STRICT:
                        lines.append(f"[No precise data] **{disp}**")

        suffix = (f"\n\n–ü–æ–∫–∞–∑–∞–Ω–∞ –ø–µ—Ä–≤–∞—è –ø–∞—Ä—Ç–∏—è –∏–∑ {len(batch)} / {total}." if total > len(batch) else "")
        if lines:
            await _send(m, "\n\n".join(lines) + suffix)
        else:
            # —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–æ–ª–±—ç–∫, –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
            await _send(m, "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø–∏—Å–∞—Ç—å —Ä–∏—Å—É–Ω–∫–∏." + suffix)
        return

    # NEW: –º—É–ª—å—Ç–∏–Ω—É–º–µ—Ä–Ω–∞—è –≤–µ—Ç–∫–∞ ‚Äî –∫–∞–∫ —Ç–æ–ª—å–∫–æ —É–≤–∏–¥–µ–ª–∏ –Ω–æ–º–µ—Ä–∞ —Ç–∞–±–ª–∏—Ü/—Ä–∏—Å—É–Ω–∫–æ–≤/–≥–ª–∞–≤,
    # –ø—Ä–æ—Ö–æ–¥–∏–º—Å—è –ø–æ –Ω–∏–º —Ü–∏–∫–ª–æ–º –∏, –µ—Å–ª–∏ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –º—É–ª—å—Ç–∏–∏ÃÜ–Ω—Ç–µ–Ω—Ç,
    # –¥–∞—ë–º –æ–¥–∏–Ω —Å–æ–±—Ä–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –∏ –ù–ï –∏–¥—ë–º –≤ generic-–≤–µ—Ç–∫–∏ –Ω–∏–∂–µ.
    refs = extract_struct_refs(q_text)
    logger.info(
        "ANSWER: struct refs for %r -> %r",
        q_text,
        refs,
    )
    if refs:
        kinds = {r["kind"] for r in refs}
        nums = {(r["kind"], r["num"]) for r in refs}

        # –û–¥–∏–Ω –æ–±—ä–µ–∫—Ç –æ–¥–Ω–æ–≥–æ —Ç–∏–ø–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´—Ç–∞–±–ª–∏—Ü–∞ 2.1¬ª) –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É
        # –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç pure-–≤–µ—Ç–∫–∏ –≤—ã—à–µ/–Ω–∏–∂–µ.
        is_single_ref = len(nums) == 1

        # –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–æ–º–µ—Ä–æ–≤ –∏–ª–∏ —Å–º–µ—à–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã (—Ç–∞–±–ª–∏—Ü—ã + —Ä–∏—Å—É–Ω–∫–∏ + –≥–ª–∞–≤—ã),
        # —Å—á–∏—Ç–∞–µ–º —ç—Ç–æ –º—É–ª—å—Ç–∏–∏ÃÜ–Ω—Ç–µ–Ω—Ç–æ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ.
        # ‚ùó –í–ê–ñ–ù–û: –∑–∞–ø—Ä–æ—Å—ã, –≥–¥–µ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∏—Å—É–Ω–∫–æ–≤ (kinds == {"figure"}),
        # –±–æ–ª—å—à–µ –ù–ï –æ—Ç–¥–∞—ë–º –≤ _answer_structured_multi ‚Äî –∏—Ö –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –Ω–∏–∂–µ
        # —á–µ—Ä–µ–∑ RAG + —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é "only_figures"-–≤–µ—Ç–∫—É.
        if (not is_single_ref or len(kinds) > 1) and kinds != {"figure"}:
            logger.info(
                "ANSWER: structured-multi pipeline (uid=%s, doc_id=%s, refs=%r)",
                uid,
                doc_id,
                refs,
            )
            handled = await _answer_structured_multi(m, uid, doc_id, q_text, refs)
            if handled:
                # —Ä–∞–∑ —É–∂ —É–≤–∏–¥–µ–ª–∏ —è–≤–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ –∏ –æ—Ç—Ä–∞–±–æ—Ç–∞–ª–∏ –∏—Ö,
                # –ù–ò FULLREAD, –ù–ò generic-–æ—Ç–≤–µ—Ç—ã –≤–Ω–∏–∑—É –ù–ï –≤—ã–∑—ã–≤–∞–µ–º.
                return
            else:
                logger.info(
                    "ANSWER: structured-multi not handled, falling back to regular pipeline "
                    "(uid=%s, doc_id=%s)",
                    uid,
                    doc_id,
                )
        # –µ—Å–ª–∏ is_single_ref –∏ –æ–¥–∏–Ω kind ‚Äî –ø—Ä–æ—Å—Ç–æ –∏–¥—ë–º –¥–∞–ª—å—à–µ:
        # —á–∏—Å—Ç—ã–µ —Ç–∞–±–ª–∏—Ü—ã/—Ä–∏—Å—É–Ω–∫–∏/–≥–ª–∞–≤—ã —Ä–∞–∑—Ä—É–ª—è—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Å–ø–µ—Ü-–≤–µ—Ç–∫–∞–º–∏.

    # NEW: –µ—Å–ª–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ —è–≤–Ω–æ —É–∫–∞–∑–∞–Ω —Ä–∞–∑–¥–µ–ª/–ø—É–Ω–∫—Ç ‚Äî –∑–∞–ø–æ–º–∏–Ω–∞–µ–º –µ–≥–æ –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–∏–π
    m_area = _SECTION_NUM_RE.search(q_text)
    if m_area:
        try:
            area = (m_area.group(1) or "").replace(" ", "").replace(",", ".")
            LAST_REF.setdefault(uid, {})["area"] = area
        except Exception:
            pass

    # --- –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–Ω—Ç–µ–Ω—Ç—ã –∑–∞—Ä–∞–Ω–µ–µ
        # --- –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–Ω—Ç–µ–Ω—Ç—ã –∑–∞—Ä–∞–Ω–µ–µ
        # --- –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–Ω—Ç–µ–Ω—Ç—ã –∑–∞—Ä–∞–Ω–µ–µ
    intents = detect_intents(q_text)
    # –ë–µ–∑ FULLREAD-–∏—Ç–µ—Ä–∞—Ü–∏–π –∏ –±–µ–∑ RAG, —á—Ç–æ–±—ã –Ω–∏—á–µ–≥–æ –Ω–µ –æ–±—Ä–µ–∑–∞–ª–æ—Å—å –∏ –Ω–µ —Ç–µ—Ä—è–ª–æ—Å—å.
    if _is_structural_intro_question(q_text):
        handled = await _answer_fulltext_simple(m, uid, doc_id, q_text)
        if handled:
            return


    # üö´ –ù–ï —Å—á–∏—Ç–∞–µ–º –≤–æ–ø—Ä–æ—Å "—á–∏—Å—Ç–æ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–º", –µ—Å–ª–∏ –≤ –Ω—ë–º —è–≤–Ω–æ –ø—Ä–æ—Å—è—Ç —Ä–∞–∑–æ–±—Ä–∞—Ç—å
    # –≤–≤–µ–¥–µ–Ω–∏–µ/–≥–ª–∞–≤—ã/—Ä–∞–∑–¥–µ–ª—ã/–æ–±—ä–µ–∫—Ç-–ø—Ä–µ–¥–º–µ—Ç –í–ö–† ‚Äî —Ç–∞–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –∏–¥—Ç–∏ —á–µ—Ä–µ–∑
    # —Ç–µ–∫—Å—Ç —Å–∞–º–æ–π —Ä–∞–±–æ—Ç—ã (FULLREAD/RAG), –∞ –Ω–µ "–æ–±—â—É—é —Ç–µ–æ—Ä–∏—é".
    structural_re = re.compile(
        r"\b(–≤–≤–µ–¥–µ–Ω–∏–µ|–≥–ª–∞–≤–∞|–≥–ª–∞–≤–µ|–≥–ª–∞–≤—ã|—Ä–∞–∑–¥–µ–ª|–ø–∞—Ä–∞–≥—Ä–∞—Ñ|–ø—É–Ω–∫—Ç|–≤—ã–≤–æ–¥—ã –ø–æ –≥–ª–∞–≤–µ|–æ–±—ä–µ–∫—Ç|–ø—Ä–µ–¥–º–µ—Ç|–í–ö–†|–¥–∏–ø–ª–æ–º)\b",
        re.IGNORECASE,
    )
    mentions_structure = bool(structural_re.search(q_text))

    # ‚úÖ –ß–∏—Å—Ç–æ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å (–±–µ–∑ —Å—Å—ã–ª–æ–∫ –Ω–∞ –≥–ª–∞–≤—ã/—Ç–∞–±–ª–∏—Ü—ã/—Ä–∏—Å—É–Ω–∫–∏/—Å—Ç—Ä—É–∫—Ç—É—Ä—É –í–ö–†) ‚Äî
    # –æ—Ç–≤–µ—á–∞–µ–º –ø—Ä–æ—Å—Ç–æ –∫–∞–∫ —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä, –≤–æ–æ–±—â–µ –Ω–µ —Ç—Ä–æ–≥–∞—è RAG.
    if intents.get("general_question") and not (
        intents["tables"]["want"]
        or intents["figures"]["want"]
        or intents["sources"]["want"]
        or _SECTION_NUM_RE.search(q_text)
        or mentions_structure           # ‚Üê –¥–æ–±–∞–≤–∏–ª–∏ —ç—Ç–æ—Ç —Ñ–∏–ª—å—Ç—Ä
    ):
        system_prompt = (
            "–¢—ã —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ –í–ö–†. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –ø—Ä–æ—Å—Ç—ã–º –ø–æ–Ω—è—Ç–Ω—ã–º —Å—Ç—É–¥–µ–Ω—Ç—É "
            "—è–∑—ã–∫–æ–º. –ú–æ–∂–Ω–æ –æ–ø–∏—Ä–∞—Ç—å—Å—è –Ω–∞ –æ–±—â—É—é —Ç–µ–æ—Ä–∏—é –∏ —É—á–µ–±–Ω–∏–∫–∏, –Ω–æ –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã –ø—Ä–æ "
            "–∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Ä–∞–±–æ—Ç—É, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç –≤ –≤–æ–ø—Ä–æ—Å–µ."
        )
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": q_text},
        ]

        if STREAM_ENABLED and chat_with_gpt_stream is not None:
            try:
                stream = chat_with_gpt_stream(
                    messages,
                    temperature=0.2,
                    max_tokens=FINAL_MAX_TOKENS,
                )
                await _stream_to_telegram(m, stream)
                return
            except Exception as e:
                logging.exception("general theory stream failed: %s", e)

        try:
            ans = chat_with_gpt(
                messages,
                temperature=0.2,
                max_tokens=FINAL_MAX_TOKENS,
            )
        except Exception as e:
            logging.exception("general theory non-stream failed: %s", e)
            ans = ""

        ans = (ans or "").strip()
        if not ans:
            ans = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
        await _send(m, ans)
        return


    # –ß–∏—Å—Ç—ã–π –∑–∞–ø—Ä–æ—Å –ø—Ä–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–∏—Å—É–Ω–∫–∏ (–Ω–µ—Ç —Å–µ–∫—Ü–∏–π/—Ç–∞–±–ª–∏—Ü/–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤/–æ–±—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞)
    pure_figs = intents["figures"]["want"] and not (
        intents["tables"]["want"]
        or intents["sources"]["want"]
        or intents.get("summary")
        or intents.get("general_question")
        or _SECTION_NUM_RE.search(q_text)
    )


    # NEW: —è–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ ¬´–ø–æ –ø—É–Ω–∫—Ç—É/—Ä–∞–∑–¥–µ–ª—É/–≥–ª–∞–≤–µ X.Y¬ª (–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è –ß–ò–°–¢–´–• –∑–∞–ø—Ä–æ—Å–æ–≤)
    m_sec = _SECTION_NUM_RE.search(q_text)
    sec = None
    if m_sec:
        raw_sec = (m_sec.group(1) or "").strip()
        raw_sec = re.sub(r"^[A-Za-z–ê-–Ø–∞-—è]\s+(?=\d)", "", raw_sec)
        sec = raw_sec.replace(" ", "").replace(",", ".")

    # –°—Ç—Ä–æ–≥–∏–π —Å–µ–∫—Ü–∏–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ —Å–º–µ—à–∞–Ω–Ω—ã–π
    if sec and _is_pure_section_request(q_text, intents):
        verbosity = _detect_verbosity(q_text)
        ctx = _section_context(uid, doc_id, sec, max_chars=9000)
        if ctx:
            base_sys = (
                "–¢—ã —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ –í–ö–†. –ù–∏–∂–µ ‚Äî –∫–æ–Ω—Ç–µ–∫—Å—Ç –¢–û–õ–¨–ö–û –ø–æ –æ–¥–Ω–æ–º—É –ø—É–Ω–∫—Ç—É/–≥–ª–∞–≤–µ –¥–∏–ø–ª–æ–º–∞.\n"
                "–û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –ø–æ —ç—Ç–æ–º—É —Ç–µ–∫—Å—Ç—É: –Ω–µ –¥–æ–±–∞–≤–ª—è–π –≤–Ω–µ—à–Ω–∏—Ö —Ñ–∞–∫—Ç–æ–≤, –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã—Ö –ø–æ–ª–æ–∂–µ–Ω–∏–π "
                "–∏ –Ω–µ –ø–µ—Ä–µ—Å–∫–∞–∑—ã–≤–∞–π —Ç–æ, —á–µ–≥–æ –≤ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ –Ω–µ—Ç. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —á–µ—Å—Ç–Ω–æ –Ω–∞–ø–∏—à–∏, "
                "—á—Ç–æ –¥–∞–Ω–Ω—ã—Ö –≤ —ç—Ç–æ–º –ø—É–Ω–∫—Ç–µ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞."
            )
            if verbosity == "brief":
                sys_prompt = base_sys + " –ù—É–∂–Ω–∞ –ö–†–ê–¢–ö–ê–Ø –≤—ã–∂–∏–º–∫–∞."
                user_prompt = (
                    f"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {q_text}\n\n"
                    f"–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫—É—é –≤—ã–∂–∏–º–∫—É –ø–æ –ø—É–Ω–∫—Ç—É {sec}. {_verbosity_addendum('brief')}"
                )
            elif verbosity == "detailed":
                sys_prompt = base_sys + " –ù—É–∂–µ–Ω –ü–û–î–†–û–ë–ù–´–ô —Ä–∞–∑–±–æ—Ä."
                user_prompt = (
                    f"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {q_text}\n\n"
                    f"–°–¥–µ–ª–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–π —Ä–∞–∑–±–æ—Ä –ø–æ –ø—É–Ω–∫—Ç—É {sec}. {_verbosity_addendum('detailed')}"
                )
            else:
                sys_prompt = base_sys + " –û—Ç–≤–µ—Ç—å –ø–æ –¥–µ–ª—É, –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π."
                user_prompt = (
                    f"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {q_text}\n\n"
                    f"–û—Ç–≤–µ—Ç—å –ø–æ –ø—É–Ω–∫—Ç—É {sec}. {_verbosity_addendum('normal')}"
                )

            messages = [
                {"role": "system", "content": sys_prompt},
                {"role": "assistant", "content": f"[–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ –ø—É–Ω–∫—Ç—É {sec}]\n{ctx}"},
                {"role": "user", "content": user_prompt},
            ]

            if STREAM_ENABLED and chat_with_gpt_stream is not None:
                try:
                    stream = chat_with_gpt_stream(
                        messages, temperature=0.2, max_tokens=FINAL_MAX_TOKENS
                    )  # type: ignore
                    await _stream_to_telegram(m, stream)
                    return
                except Exception as e:
                    logging.exception("section summary stream failed: %s", e)
            try:
                ans = chat_with_gpt(
                    messages, temperature=0.2, max_tokens=FINAL_MAX_TOKENS
                )
                if ans:
                    await _send(m, _strip_unwanted_sections(ans))
                    return
            except Exception as e:
                logging.exception("section summary non-stream failed: %s", e)
                # –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è ‚Äî –ø—É—Å—Ç—å –ø–æ–π–¥—ë—Ç –æ–±—ã—á–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –Ω–∏–∂–µ, –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ —Å–ª–æ–º–∞–ª–æ—Å—å
        else:
            await _send(m, f"–ü—É–Ω–∫—Ç {sec} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∏–Ω–¥–µ–∫—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.")
            return

    # ====== FULLREAD: auto ======
        # ====== FULLREAD: auto ======
    fr_mode = getattr(Cfg, "FULLREAD_MODE", "off")
    # FULLREAD(auto) –≤–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–±—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é,
    # —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–±–∏–≤–∞—Ç—å —Å–ø–µ—Ü-–ª–æ–≥–∏–∫–∏ –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º/—Ä–∏—Å—É–Ω–∫–∞–º/–∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
    # –∏ –ø–æ –≤–≤–µ–¥–µ–Ω–∏—é/–≥–ª–∞–≤–∞–º (–∏—Ö –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ).
    if (
        fr_mode == "auto"
        and intents.get("general_question")
        and not intents["tables"]["want"]
        and not intents["figures"]["want"]
        and not intents["sources"]["want"]
        and not _is_structural_intro_question(q_text)   # üëà –¥–æ–±–∞–≤–∏–ª–∏ —Ñ–∏–ª—å—Ç—Ä
    ):

        logger.info(
            "ANSWER: FULLREAD(auto) mode, uid=%s, doc_id=%s",
            uid,
            doc_id,
        )
        _limit = int(getattr(Cfg, "DIRECT_MAX_CHARS", 80000))
        full_text = _full_document_text(uid, doc_id, limit_chars=_limit + 1)
        full_len = len(full_text or "")
        logger.debug(
            "ANSWER: FULLREAD(auto) full_text_len=%d (limit=%d)",
            full_len,
            _limit,
        )

        # 1) –≤–æ–æ–±—â–µ –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç ‚Üí —á–µ—Å—Ç–Ω–æ –ø–∞–¥–∞–µ–º –≤ –æ–±—ã—á–Ω—ã–π RAG-–ø–∞–π–ø–ª–∞–π–Ω –Ω–∏–∂–µ
        if not full_text.strip():
            logger.warning(
                "ANSWER: FULLREAD(auto) got empty full_text, falling back to RAG (uid=%s, doc_id=%s)",
                uid,
                doc_id,
            )
        # 2) –¥–æ–∫—É–º–µ–Ω—Ç —Ü–µ–ª–∏–∫–æ–º –≤–ª–µ–∑–∞–µ—Ç –≤ –ª–∏–º–∏—Ç ‚Üí –ø—Ä—è–º–æ–π FULLREAD
        elif full_len <= _limit:
            system_prompt = (
                "–¢—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –¥–∏–ø–ª–æ–º–Ω—ã–º —Ä–∞–±–æ—Ç–∞–º. –¢–µ–±–µ –¥–∞–Ω –ü–û–õ–ù–´–ô —Ç–µ–∫—Å—Ç –í–ö–†/–¥–æ–∫—É–º–µ–Ω—Ç–∞.\n"
                "–û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –ø–æ —ç—Ç–æ–º—É —Ç–µ–∫—Å—Ç—É, –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö —Ñ–∞–∫—Ç–æ–≤. –ù–µ –¥–æ–±–∞–≤–ª—è–π —Ä–∞–∑–¥–µ–ª–æ–≤ –≤–∏–¥–∞ "
                "¬´–ß–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç¬ª –∏ –Ω–µ –ø—Ä–æ—Å–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.\n"
                "–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ —Ç–∞–±–ª–∏—Ü—ã/—Ä–∏—Å—É–Ω–∫–∏ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –ø–æ–¥–ø–∏—Å–∏ –∏ –±–ª–∏–∂–∞–π—à–∏–π —Ç–µ–∫—Å—Ç; –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–º–µ—Ä–∞/–∑–Ω–∞—á–µ–Ω–∏—è. "
                "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ç–∞–∫–∂–µ –ø—Ä–µ–¥–º–µ—Ç–Ω—É—é –æ–±–ª–∞—Å—Ç—å –∏ —Ç–µ—Ä–º–∏–Ω—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ–¥–∞–∂–∏, –∫–ª–∏–µ–Ω—Ç—ã, –≤—ã—Ä—É—á–∫–∞, –º–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ —Ç.–ø.), "
                "–µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä—è–º–æ –Ω–µ —É–∫–∞–∑–∞–Ω—ã –≤ —Ç–µ–∫—Å—Ç–µ.\n"
                "–ï—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞/—Ç–∞–±–ª–∏—Ü—ã –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ ‚Äî –æ—Ç–≤–µ—Ç—å: ¬´–¥–∞–Ω–Ω–æ–≥–æ —Ä–∏—Å—É–Ω–∫–∞ –Ω–µ—Ç –≤ —Ä–∞–±–æ—Ç–µ¬ª.\n"
                "–ï—Å–ª–∏ –æ–±—ä–µ–∫—Ç –µ—Å—Ç—å, –Ω–æ –æ–Ω –≤ –ø–ª–æ—Ö–æ–º –∫–∞—á–µ—Å—Ç–≤–µ/–Ω–µ—á–∏—Ç–∞–µ–º ‚Äî –æ—Ç–≤–µ—Ç—å: ¬´–†–∏—Å—É–Ω–æ–∫ –ø–ª–æ—Ö–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞, –Ω–µ –º–æ–≥—É –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å¬ª, "
                "–∏ –¥–æ–±–∞–≤—å –∫—Ä–∞—Ç–∫—É—é –ø–æ–¥–ø–∏—Å—å/–∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞. –¶–∏—Ç–∏—Ä—É–π –∫–æ—Ä–æ—Ç–∫–æ, –±–µ–∑ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã."
            )

            verbosity = _detect_verbosity(q_text)
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "assistant", "content": f"[–î–æ–∫—É–º–µ–Ω—Ç ‚Äî –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç]\n{full_text}"},
                {
                    "role": "user",
                    "content": f"{q_text}\n\n{_verbosity_addendum(verbosity)}",
                },
            ]

            if STREAM_ENABLED and chat_with_gpt_stream is not None:
                try:
                    stream = chat_with_gpt_stream(
                        messages,
                        temperature=0.2,
                        max_tokens=FINAL_MAX_TOKENS,
                    )  # type: ignore
                    await _stream_to_telegram(m, stream)
                    return
                except Exception as e:
                    logging.exception("auto fullread stream failed: %s", e)

            try:
                ans = chat_with_gpt(
                    messages,
                    temperature=0.2,
                    max_tokens=FINAL_MAX_TOKENS,
                )
                if ans:
                    await _send(m, _strip_unwanted_sections(ans))
                    return
            except Exception as e:
                logging.exception("auto fullread non-stream failed: %s", e)
        # 3) –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª–∏–Ω–Ω—ã–π ‚Üí –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ —á—Ç–µ–Ω–∏–µ (map‚Üíreduce)
        else:
            messages, err = _iterative_fullread_build_messages(uid, doc_id, q_text)
            if messages:
                if STREAM_ENABLED and chat_with_gpt_stream is not None:
                    try:
                        stream = chat_with_gpt_stream(
                            messages,
                            temperature=0.2,
                            max_tokens=FINAL_MAX_TOKENS,
                        )  # type: ignore
                        await _stream_to_telegram(m, stream)
                        return
                    except Exception as e:
                        logging.exception("auto iterative stream failed: %s", e)
                try:
                    ans = chat_with_gpt(
                        messages, temperature=0.2, max_tokens=FINAL_MAX_TOKENS
                    )
                    if ans:
                        await _send(m, _strip_unwanted_sections(ans))
                        return
                except Exception as e:
                    logging.exception("auto iterative non-stream failed: %s", e)
            elif err:
                # –í auto-—Ä–µ–∂–∏–º–µ –Ω–µ —Ä–≤—ë–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω, –∞ —Ç–∏—Ö–æ –ª–æ–≥–∏—Ä—É–µ–º
                logging.warning(
                    "ANSWER: FULLREAD(auto) iterative build failed, "
                    "falling back to RAG (uid=%s, doc_id=%s): %s",
                    uid,
                    doc_id,
                    err,
                )
                # –±–µ–∑ return ‚Äî –Ω–∏–∂–µ —Å–ø–æ–∫–æ–π–Ω–æ –æ—Ç—Ä–∞–±–æ—Ç–∞–µ—Ç –æ–±—ã—á–Ω—ã–π RAG-–æ—Ç–≤–µ—Ç

    # ====== FULLREAD: iterative/digest ======
    if fr_mode in {"iterative", "digest"} and not pure_figs:
        messages, err = _iterative_fullread_build_messages(uid, doc_id, q_text)
        if messages:
            if STREAM_ENABLED and chat_with_gpt_stream is not None:
                try:
                    stream = chat_with_gpt_stream(
                        messages, temperature=0.2, max_tokens=FINAL_MAX_TOKENS
                    )  # type: ignore
                    await _stream_to_telegram(m, stream)
                    return
                except Exception as e:
                    logging.exception("iterative fullread stream failed: %s", e)
            try:
                ans = chat_with_gpt(
                    messages, temperature=0.2, max_tokens=FINAL_MAX_TOKENS
                )
                if ans:
                    await _send(m, _strip_unwanted_sections(ans))
                    return
            except Exception as e:
                logging.exception("iterative fullread non-stream failed: %s", e)
        else:
            if err:
                await _send(m, err)
                return
        # –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–µ –≤—ã—à–ª–æ ‚Äî –ø—Ä–æ–≤–∞–ª–∏–≤–∞–µ–º—Å—è –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–µ–∂–∏–º –Ω–∏–∂–µ

    # ====== –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –º—É–ª—å—Ç–∏-–∏–Ω—Ç–µ–Ω—Ç –ø–∞–π–ø–ª–∞–π–Ω (RAG) ======
    await _ensure_modalities_indexed(m, uid, doc_id, intents)
    facts = _gather_facts(uid, doc_id, intents)
    logger.info(
        "ANSWER: RAG facts gathered (uid=%s, doc_id=%s, keys=%s)",
        uid,
        doc_id,
        list(facts.keys()) if isinstance(facts, dict) else type(facts),
    )

    # ‚úÖ –ù–û–í–û–ï: –µ—Å–ª–∏ –ø–æ –≤–æ–ø—Ä–æ—Å—É –ø–æ—á—Ç–∏ –Ω–µ—Ç —Ñ–∞–∫—Ç–æ–≤ –∏–∑ RAG, –∞ —Ä–µ—á—å —è–≤–Ω–æ –ø—Ä–æ
    # –≤–≤–µ–¥–µ–Ω–∏–µ/–≥–ª–∞–≤—ã/—Ä–∞–∑–¥–µ–ª—ã, –¥–µ–ª–∞–µ–º –ø—Ä—è–º–æ–µ —á—Ç–µ–Ω–∏–µ –≤—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞,
    # –≤–º–µ—Å—Ç–æ ¬´–ø–æ –∏–º–µ—é—â–∏–º—Å—è –¥–∞–Ω–Ω—ã–º –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–µ–ª—å–∑—è¬ª.
    try:
        no_ctx = not isinstance(facts, dict) or (
            not (facts.get("general_ctx") or facts.get("summary_text"))
            and not (facts.get("coverage") or {}).get("items")
        )

        mentions_structure = bool(
            re.search(r"\b(–≤–≤–µ–¥–µ–Ω–∏–µ|–≥–ª–∞–≤–∞|—Ä–∞–∑–¥–µ–ª|–ø—É–Ω–∫—Ç)\b", q_text, re.IGNORECASE)
        )

        if no_ctx and mentions_structure:
            # üëá –í–º–µ—Å—Ç–æ –æ–¥–Ω–æ–≥–æ –æ–≥—Ä–æ–º–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ ‚Äî –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π fullread –ø–æ –∫—É—Å–æ—á–∫–∞–º
            messages, err = _iterative_fullread_build_messages(uid, doc_id, q_text)

            if messages:
                if STREAM_ENABLED and chat_with_gpt_stream is not None:
                    try:
                        stream = chat_with_gpt_stream(
                            messages,
                            temperature=0.2,
                            max_tokens=FINAL_MAX_TOKENS,
                        )
                        await _stream_to_telegram(m, stream)
                        return
                    except Exception as e:
                        logging.exception("fallback iterative fullread stream failed: %s", e)

                try:
                    ans = chat_with_gpt(
                        messages,
                        temperature=0.2,
                        max_tokens=FINAL_MAX_TOKENS,
                    )
                except Exception as e:
                    logging.exception("fallback iterative fullread non-stream failed: %s", e)
                    ans = ""

                ans = (ans or "").strip()
                if not ans:
                    ans = (
                        "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –ø–æ —Ç–µ–∫—Å—Ç—É —Ä–∞–±–æ—Ç—ã –¥–∞–∂–µ –ø–æ—Å–ª–µ –ø–æ–ª–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è. "
                        "–ü–æ–ø—Ä–æ–±—É–π —Å—É–∑–∏—Ç—å –∏–ª–∏ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å."
                    )
                await _send(m, _strip_unwanted_sections(ans))
                return

            elif err:
                # –Ω–µ —Ä–≤—ë–º –ø–∞–π–ø–ª–∞–π–Ω, –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º –∏ –¥–∞—ë–º —à–∞–Ω—Å—É –Ω–∏–∂–Ω–µ–º—É RAG-–æ—Ç–≤–µ—Ç—É
                logging.warning(
                    "fallback iterative fullread build failed (uid=%s, doc_id=%s): %s",
                    uid,
                    doc_id,
                    err,
                )
                # –±–µ–∑ return ‚Äî –ø–æ–π–¥—ë–º –¥–∞–ª—å—à–µ –ø–æ –æ–±—ã—á–Ω–æ–º—É RAG-–ø—É—Ç–∏

    except Exception as e:
        logging.exception("fallback fullread guard failed: %s", e)

    # üí° –ù–û–í–û–ï: –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å ‚Äî –ß–ò–°–¢–û –ø—Ä–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–∏—Å—É–Ω–∫–∏ –ø–æ –Ω–æ–º–µ—Ä–∞–º,
    # –∞ –∫–∞—Ä—Ç–æ—á–∫–∏ —É–∂–µ —Å–æ–±—Ä–∞–Ω—ã –≤ facts["figures"]["describe_cards"],
    # –æ—Ç–¥–∞—ë–º –±—ã—Å—Ç—Ä—ã–π "—Ñ–∏–≥—É—Ä–Ω—ã–π" –æ—Ç–≤–µ—Ç –∏ –ù–ï –∏–¥—ë–º –≤ LLM-–≥–µ–Ω–µ—Ä–∞—Ü–∏—é.
    try:
        figs_int = intents.get("figures") or {}
        tables_int = intents.get("tables") or {}
        sources_int = intents.get("sources") or {}
        explicit_fig_nums = list(figs_int.get("describe") or [])

        only_figures = (
            explicit_fig_nums
            and figs_int.get("want")
            and not (tables_int.get("want") or sources_int.get("want"))
            and not intents.get("summary")
            and not intents.get("general_question")
        )

        if only_figures and isinstance(facts, dict):
            figs_block = (facts.get("figures") or {}) if isinstance(facts, dict) else {}
            cards = list(figs_block.get("describe_cards") or [])

            if cards:
                logger.info(
                    "ANSWER: only_figures fast path (uid=%s, doc_id=%s, nums=%s, cards=%d)",
                    uid,
                    doc_id,
                    explicit_fig_nums,
                    len(cards),
                )
                parts: list[str] = []
                for c in cards:
                    num = (c.get("num") or c.get("label") or "").strip()
                    display = c.get("display") or (f"–†–∏—Å—É–Ω–æ–∫ {num}" if num else "–†–∏—Å—É–Ω–æ–∫")
                    vision_desc = ((c.get("vision") or {}).get("description") or "").strip()
                    text = (c.get("text") or "").strip()
                    values_str = (c.get("values_str") or "").strip()

                    block_lines: list[str] = []

                    # 1. –ó–∞–≥–æ–ª–æ–≤–æ–∫
                    block_lines.append(display + ".")

                    # 2. –ö–æ—Ä–æ—Ç–∫–æ–µ —Å–º—ã—Å–ª–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (vision ‚Üí text)
                    body = ""
                    if vision_desc:
                        body = vision_desc
                    elif text:
                        paras = [p.strip() for p in text.split("\n") if p.strip()]
                        body = "\n".join(paras[:2])
                    if body:
                        block_lines.append(body)

                    # 3. –ß–∏—Å–ª–∞/–∑–Ω–∞—á–µ–Ω–∏—è ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –ø—Ä–µ–≤—Ä–∞—â–∞—é—Ç—Å—è –≤ –ø—Ä–æ—Å—Ç—ã–Ω—é
                    if values_str:
                        lines = [ln for ln in values_str.splitlines() if ln.strip()]
                        if len(lines) > 8:
                            lines = lines[:8]
                        if lines:
                            block_lines.append("\n".join(lines))

                    parts.append("\n\n".join(block_lines))

                await _send(m, "\n\n\n".join(parts))
                return
    except Exception as e:
        logging.exception("only_figures fast path failed, fallback to generic: %s", e)

    # NEW: –µ—Å–ª–∏ –ø–æ –æ–±—â–µ–º—É –≤–æ–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–æ—Å—å –∏–º–µ–Ω–Ω–æ –≤ —Ç–µ–∫—Å—Ç–µ —Ä–∞–±–æ—Ç—ã ‚Äî
    # —Å–Ω–∞—á–∞–ª–∞ —Å–ø—Ä–∞—à–∏–≤–∞–µ–º, –º–æ–∂–Ω–æ –ª–∏ –æ—Ç–≤–µ—Ç–∏—Ç—å –≤ –æ–±—â–µ–º –≤–∏–¥–µ –∫–∞–∫ [–º–æ–¥–µ–ª—å].
    if intents.get("general_question") and not facts.get("general_ctx") and not facts.get("summary_text"):
        MODEL_EXTRA_PENDING[uid] = {
            "kind": "generic",
            "question": intents["general_question"] or q_text,
        }
        await _send(
            m,
            "–ü–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É —è –Ω–µ –Ω–∞—à—ë–ª —è–≤–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —Å–∞–º–æ–º —Ç–µ–∫—Å—Ç–µ —Ä–∞–±–æ—Ç—ã. "
            "–ú–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å –≤ –æ–±—â–µ–º –≤–∏–¥–µ –∫–∞–∫ [–º–æ–¥–µ–ª—å] (—ç—Ç–æ —É–∂–µ –Ω–µ –±—É–¥–µ—Ç –æ–ø–∏—Ä–∞—Ç—å—Å—è –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç). "
            "–ù–∞–ø–∏—à–∏ ¬´–¥–∞¬ª –∏–ª–∏ ¬´–Ω–µ—Ç¬ª.",
        )
        return

    # ‚Üì –ù–û–í–û–ï: –µ—Å–ª–∏ –µ—Å—Ç—å –ø–ª–∞–Ω –ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤ ‚Äî –≤–∫–ª—é—á–∞–µ–º –º–Ω–æ–≥–æ—à–∞–≥–æ–≤—É—é –ø–æ–¥–∞—á—É,
    # –Ω–æ —Ç–æ–ª—å–∫–æ –∫–æ–≥–¥–∞ —ç—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –æ–ø—Ä–∞–≤–¥–∞–Ω–æ (–µ—Å—Ç—å –ø–æ–¥–ø—É–Ω–∫—Ç—ã –∏ –≤–æ–ø—Ä–æ—Å –Ω–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π).
    discovered_items: list[dict] | None = None
    if isinstance(facts, dict):
        discovered_items = (
            (facts.get("coverage") or {}).get("items")
            or facts.get("general_subitems")
        )

    if _should_use_multistep(q_text, discovered_items):
        try:
            handled = await _run_multistep_answer(
                m,
                uid,
                doc_id,
                q_text,
                discovered_items=discovered_items,  # –æ—Ç–ø—Ä–∞–≤–∏—Ç A‚ÜíB‚Üí‚Ä¶ –∏ –≤–µ—Ä–Ω—ë—Ç True
            )
            if handled:
                return
        except Exception as e:
            logging.exception(
                "multistep pipeline failed, fallback to normal: %s", e
            )
    # –µ—Å–ª–∏ –º—É–ª—å—Ç–∏—à–∞–≥ –Ω–µ –ø–æ–¥–æ—à—ë–ª ‚Äî –Ω–∏–∂–µ –∏–¥—ë–º –ø–æ –æ–±—ã—á–Ω–æ–º—É –ø–∞–π–ø–ª–∞–π–Ω—É

    # –æ–±—ã—á–Ω—ã–π –ø—É—Ç—å + —è–≤–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –≤–µ—Ä–±–æ–∑–Ω–æ—Å—Ç–∏
    verbosity = _detect_verbosity(q_text)
    SAFE_RULES = (
        "–û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –ø–æ –ø—Ä–∏–≤–µ–¥—ë–Ω–Ω—ã–º —Ñ–∞–∫—Ç–∞–º –∏ —Ü–∏—Ç–∞—Ç–∞–º –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. "
        "–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏, –±–µ–∑ –¥–æ–º—ã—Å–ª–æ–≤. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–º–µ—Ä–∞/–∑–Ω–∞—á–µ–Ω–∏—è "
        "–∏ –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –ø—Ä–µ–¥–º–µ—Ç–Ω—É—é –æ–±–ª–∞—Å—Ç—å –∏ —Ç–µ—Ä–º–∏–Ω—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ–¥–∞–∂–∏, –∫–ª–∏–µ–Ω—Ç—ã, –≤—ã—Ä—É—á–∫–∞, "
        "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ —Ç.–ø.), –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç –≤ —Ç–µ–∫—Å—Ç–µ."
    )

    enriched_q = f"{SAFE_RULES}\n\n{q_text}\n\n{_verbosity_addendum(verbosity)}"

    # –µ—Å–ª–∏ —Ö–æ—á–µ—Ç—Å—è –æ–±–Ω–æ–≤–ª—è—Ç—å ¬´–ø–æ—Å–ª–µ–¥–Ω–∏–π —É–ø–æ–º—è–Ω—É—Ç—ã–π —Ä–∏—Å—É–Ω–æ–∫¬ª ‚Äî –≤–æ–∑—å–º–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∑–∞–ø—Ä–æ—Å–∞
    figs_in_q = [_num_norm_fig(n) for n in _extract_fig_nums(q_text)]
    if figs_in_q:
        LAST_REF.setdefault(uid, {})["figure_nums"] = figs_in_q

    # NEW: –ø—Ä—è–º–æ–π –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç, –µ—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    # (–Ω–µ –ª–æ–º–∞–µ—Ç —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É: –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å/–Ω–µ—Ç –∫–∞—Ä—Ç–∏–Ω–æ–∫ ‚Äî –∏–¥—ë–º –≤ generate_answer)
    try:
        if intents.get("general_question") and getattr(Cfg, "vision_active", lambda: False)():
            # –ø–æ–¥—Ç—è–Ω–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫-—Ö–∏—Ç—ã –∏ –≤—ã–±–µ—Ä–µ–º 1‚Äì3 —Ñ–∞–π–ª–∞-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            hits_v = retrieve(uid, doc_id, intents["general_question"], top_k=10) or []
            img_paths = _pick_images_from_hits(
                hits_v, limit=getattr(Cfg, "VISION_MAX_IMAGES_PER_REQUEST", 3)
            )
            if img_paths and (chat_with_gpt_stream_multimodal or chat_with_gpt_multimodal):
                # –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ RAG, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                ctx = (facts.get("general_ctx") or "").strip() if isinstance(facts, dict) else ""
                mm_system = (
                    "–¢—ã —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ –í–ö–†. –£ —Ç–µ–±—è –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å, –∫—Ä–∞—Ç–∫–∏–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Å–∞–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è "
                    "(—Ñ–æ—Ç–æ/—Å–∫–∞–Ω—ã/–¥–∏–∞–≥—Ä–∞–º–º—ã) –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –û—Ç–≤–µ—á–∞–π –ø–æ –¥–µ–ª—É, –∏—Å–ø–æ–ª—å–∑—É—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞–ø—Ä—è–º—É—é. "
                    "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∑–Ω–∞—á–µ–Ω–∏—è –∏ –Ω–æ–º–µ—Ä–∞, –ø–∏—à–∏ —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ –≤–∏–¥–Ω–æ –∏–ª–∏ –µ—Å—Ç—å –≤ —Ç–µ–∫—Å—Ç–µ. "
                    "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ç–∞–∫–∂–µ –ø—Ä–µ–¥–º–µ—Ç–Ω—É—é –æ–±–ª–∞—Å—Ç—å –∏ —Ç–µ—Ä–º–∏–Ω—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ–¥–∞–∂–∏, –∫–ª–∏–µ–Ω—Ç—ã, –≤—ã—Ä—É—á–∫–∞, "
                    "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥ –∏ —Ç.–ø.), –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã –≤ —Ç–µ–∫—Å—Ç–µ –∏–ª–∏ –ø–æ–¥–ø–∏—Å—è—Ö –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º."
                )

                mm_prompt = (
                    f"{q_text}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞:\n{ctx}" if ctx else q_text
                )

                if STREAM_ENABLED and chat_with_gpt_stream_multimodal is not None:
                    stream = chat_with_gpt_stream_multimodal(
                        mm_prompt,
                        image_paths=img_paths,
                        system=mm_system,
                        temperature=0.2,
                        max_tokens=FINAL_MAX_TOKENS,
                    )
                    await _stream_to_telegram(m, stream)
                    return
                elif chat_with_gpt_multimodal is not None:
                    ans_mm = chat_with_gpt_multimodal(
                        mm_prompt,
                        image_paths=img_paths,
                        system=mm_system,
                        temperature=0.2,
                        max_tokens=FINAL_MAX_TOKENS,
                    )
                    ans_mm = (ans_mm or "").strip()
                    if ans_mm:
                        await _send(m, _strip_unwanted_sections(ans_mm))
                        return
    except Exception as e:
        logging.exception("multimodal answer path failed, falling back: %s", e)

    # --- —Å—Ç–∞—Ä—ã–π –ø—É—Ç—å RAG ‚Üí –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –ø–æ —Ñ–∞–∫—Ç–∞–º (answer_builder) ---

    # 1) –ø—Ä–æ–±—É–µ–º —Å—Ç—Ä–∏–º–æ–≤—É—é –≤–µ—Ä—Å–∏—é, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
    if STREAM_ENABLED and generate_answer_stream is not None:
        try:
            stream = generate_answer_stream(
                enriched_q,
                facts,
                language=intents.get("language", "ru"),
            )
            await _stream_to_telegram(m, stream)
            return
        except Exception:
            logging.exception("generate_answer_stream failed, fallback to sync")

    # 2) –Ω–µ—Å—Ç—Ä–∏–º–æ–≤—ã–π —Ñ–æ–ª–±—ç–∫
    try:
        answer = generate_answer(
            enriched_q,
            facts,
            language=intents.get("language", "ru"),
        )
    except Exception as e:
        logging.exception("generate_answer failed: %s", e)
        answer = ""

    # 3) —Å—Ç—Ä–∞—Ö–æ–≤–∫–∞ –æ—Ç –ø—É—Å—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: –≤—Å–µ–≥–¥–∞ —á—Ç–æ-—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º
    answer = (answer or "").strip()
    if not answer:
        answer = (
            "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ä–∞–±–æ—Ç—ã. "
            "–ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ —É—Ç–æ—á–Ω–∏—Ç—å, –∫–∞–∫–æ–π —Ä–∞–∑–¥–µ–ª, —Ç–∞–±–ª–∏—Ü—É –∏–ª–∏ —Ä–∏—Å—É–Ω–æ–∫ —Ç–µ–±—è –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç."
        )

    await _send(m, _strip_unwanted_sections(answer))


async def _qa_worker(m: types.Message, uid: int, doc_id: int, text: str):
    """
    –§–æ–Ω–æ–≤—ã–π –≤–æ—Ä–∫–µ—Ä: –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –∞–ø–¥–µ–π—Ç–∞.
    """
    try:
        # 1. –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –æ–±—ã—á–Ω—ã–π/–Ω–µ–±–æ–ª—å—à–æ–π ‚Äî —Ä–∞–±–æ—Ç–∞–µ–º –ø–æ —Å—Ç–∞—Ä–æ–π —Å—Ö–µ–º–µ
        if not is_big_complex_query(text):
            await respond_with_answer(m, uid, doc_id, text)
            return

        # 2. –°–ª–æ–∂–Ω—ã–π –∑–∞–ø—Ä–æ—Å -> –ø–ª–∞–Ω–∏—Ä—É–µ–º –ø–æ–¥–∑–∞–¥–∞—á–∏
        tasks = plan_tasks_from_user_query(text, max_tasks=8)
        batches = batch_tasks(tasks, batch_size=3)

        # –ñ—ë—Å—Ç–∫–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –≤—Å–µ—Ö –ø–æ–¥-–≤–æ–ø—Ä–æ—Å–æ–≤
        prefix = (
            "–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. "
            "–ù–µ –æ–ø–∏—Å—ã–≤–∞–π —Å–≤–æ–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ –ø–ª–∞–Ω—ã, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ñ—Ä–∞–∑—ã –≤—Ä–æ–¥–µ "
            "\"I need to\", \"I noticed\", \"I shouldn't\". "
            "–°—Ä–∞–∑—É –¥–∞–≤–∞–π –≥–æ—Ç–æ–≤—ã–π, –ø–æ–Ω—è—Ç–Ω—ã–π —Å—Ç—É–¥–µ–Ω—Ç—É –æ—Ç–≤–µ—Ç.\n\n"
        )

        # –ö—Ä–∞—Ç–∫–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞

        header_lines = [
            "–ó–∞–ø—Ä–æ—Å –±–æ–ª—å—à–æ–π, —Ä–∞–∑–æ–±—Ä–∞–ª –µ–≥–æ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–µ–π –∏ –±—É–¥—É –æ—Ç–≤–µ—á–∞—Ç—å –ø–æ –æ—á–µ—Ä–µ–¥–∏.\n",
            "–ü–ª–∞–Ω:\n",
        ]
        for i, task in enumerate(tasks, start=1):
            line = f"{i}. {task.title}"
            if task.table_ref:
                line += f" (—Ç–∞–±–ª–∏—Ü–∞ {task.table_ref})"
            if task.figure_ref:
                line += f" (—Ä–∏—Å—É–Ω–∫–∏/–ø—É–Ω–∫—Ç {task.figure_ref})"
            header_lines.append(line)

        await _send(m, "\n".join(header_lines))

        # 3. –ü–æ –æ—á–µ—Ä–µ–¥–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∏ –ø–æ–¥–∑–∞–¥–∞—á
        for batch in batches:
            for task in batch:
                # –î–ª—è –∫–∞–∂–¥–æ–π –ø–æ–¥–∑–∞–¥–∞—á–∏ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–¥-–≤–æ–ø—Ä–æ—Å, —Å –∫–æ—Ç–æ—Ä—ã–º —É–∂–µ
                # —É–º–µ–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π respond_with_answer.
                if task.type == TaskType.THEORY:
                    # –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ—Å–∏–º –æ–±—ä—è—Å–Ω–∏—Ç—å —Ç–µ–º—ã
                    topics_text = ", ".join(task.topics) if task.topics else "–∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–µ —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã"
                    sub_q = prefix + (
                        "–û–±—ä—è—Å–Ω–∏ –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º —Å–ª–µ–¥—É—é—â–∏–µ —Ç–µ–º—ã –ø–æ –±—É—Ö—É—á—ë—Ç—É –∏ —Ñ–∏–Ω–∞–Ω—Å–∞–º: "
                        f"{topics_text}. "
                        "–°–¥–µ–ª–∞–π –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ–Ω—è—Ç–Ω—ã–º –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞, –º–æ–∂–Ω–æ –æ–ø–∏—Ä–∞—Ç—å—Å—è –Ω–∞ –æ–±—â—É—é —Ç–µ–æ—Ä–∏—é,"
                        " –∞ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Å–≤—è–∑—ã–≤–∞—Ç—å —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–∏–ø–ª–æ–º–∞."
                    )
                    section_title = "–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å"


                elif task.type == TaskType.ENTERPRISE:
                    sub_q = prefix + (
                        "–ö—Ä–∞—Ç–∫–æ —Ä–∞—Å—Å–∫–∞–∂–∏ –æ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–∏, –∫–æ—Ç–æ—Ä–æ–µ –æ–ø–∏—Å–∞–Ω–æ –≤ –¥–∏–ø–ª–æ–º–µ: "
                        "–≤–∏–¥ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –æ—Å–Ω–æ–≤–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞. "
                        "–û–ø–∏—Ä–∞–π—Å—è –Ω–∞ —Ç–µ–∫—Å—Ç –í–ö–†."
                    )
                    section_title = "–û –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–∏ –∏ –æ—Ä–≥—Å—Ç—Ä—É–∫—Ç—É—Ä–µ"


                elif task.type == TaskType.ENTERPRISE_FINANCE:
                    sub_q = prefix + (
                        "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∞–∫—Ç–∏–≤–æ–≤ –∏ –æ–±—â–µ–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è "
                        "–ø–æ –¥–∞–Ω–Ω—ã–º –¥–∏–ø–ª–æ–º–∞. –û—Ç–º–µ—Ç—å, –∫–∞–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –∞–∫—Ç–∏–≤—ã, –µ—Å—Ç—å –ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ "
                        "—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –∏–ª–∏ –ø—Ä–æ–±–ª–µ–º, –ø—Ä–∏–±—ã–ª—å/—É–±—ã—Ç–æ–∫, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤."
                    )
                    section_title = "–§–∏–Ω–∞–Ω—Å–æ–≤–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞–∫—Ç–∏–≤–æ–≤"


                elif task.type == TaskType.TABLE and task.table_ref:
                    sub_q = prefix + (
                        f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–∞–±–ª–∏—Ü—É {task.table_ref} –∏–∑ –¥–∏–ø–ª–æ–º–∞. "
                        "–û–ø–∏—à–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏, –¥–∏–Ω–∞–º–∏–∫—É –∏ —Ç–µ–º–ø—ã —Ä–æ—Å—Ç–∞/—Å–Ω–∏–∂–µ–Ω–∏—è, —Å–¥–µ–ª–∞–π –≤—ã–≤–æ–¥—ã "
                        "–æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–º –ø–æ–ª–æ–∂–µ–Ω–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–π —Ç–∞–±–ª–∏—Ü—ã."
                    )
                    section_title = f"–ê–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü—ã {task.table_ref}"


                elif task.type == TaskType.FIGURES and task.figure_ref:
                    sub_q = prefix + (
                        f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–∏—Å—É–Ω–∫–∏/–≥—Ä–∞—Ñ–∏–∫–∏, –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ –ø—É–Ω–∫—Ç—É/–Ω–æ–º–µ—Ä—É {task.figure_ref} "
                        "–≤ –¥–∏–ø–ª–æ–º–µ. –ö—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏, —á—Ç–æ –Ω–∞ –Ω–∏—Ö –ø–æ–∫–∞–∑–∞–Ω–æ, –∫–∞–∫ –º–µ–Ω—è—é—Ç—Å—è –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ "
                        "–∏ –∫–∞–∫–∏–µ –≤—ã–≤–æ–¥—ã –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å."
                    )
                    section_title = f"–ê–Ω–∞–ª–∏–∑ —Ä–∏—Å—É–Ω–∫–æ–≤ {task.figure_ref}"


                elif task.type == TaskType.POSTINGS:
                    sub_q = prefix + (
                        "–û–±—ä—è—Å–Ω–∏ –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º, –∫–∞–∫–∏–µ —Ç–∏–ø–æ–≤—ã–µ –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–∏–µ –ø—Ä–æ–≤–æ–¥–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è "
                        "–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–∞–Ω–Ω–æ–≥–æ –ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏—è –∏ –¥–∏–ø–ª–æ–º–∞. –ó–∞—Ç–µ–º, –∏—Å–ø–æ–ª—å–∑—É—è –¥–∞–Ω–Ω—ã–µ –¥–∏–ø–ª–æ–º–∞ "
                        "(–æ—Å–æ–±–µ–Ω–Ω–æ –ø–æ –∑–∞–ø–∞—Å–∞–º, –æ–±–æ—Ä–æ—Ç–Ω—ã–º –∞–∫—Ç–∏–≤–∞–º, –æ–±–µ—Å—Ü–µ–Ω–µ–Ω–∏—é –∏ —Ç–µ–∫—É—â–∏–º –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞–º), "
                        "–ø—Ä–µ–¥–ª–æ–∂–∏ –ø—Ä–∏–º–µ—Ä—ã –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–æ–≤–æ–¥–æ–∫ –∏ –ø–æ—è—Å–Ω–∏ –∏—Ö —Å–º—ã—Å–ª."
                    )
                    section_title = "–ë—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–∏–µ –ø—Ä–æ–≤–æ–¥–∫–∏ –ø–æ –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç–µ"


                else:
                    # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç: –æ–±—â–∏–π –≤–æ–ø—Ä–æ—Å –ø–æ –í–ö–†
                    sub_q = prefix + (
                        "–û—Ç–≤–µ—Ç—å –ø–æ–¥—Ä–æ–±–Ω–æ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ –¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ –í–ö–†. "
                        "–°–¥–µ–ª–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏ –ø–æ–Ω—è—Ç–Ω—ã–π –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞ –æ—Ç–≤–µ—Ç."
                    )
                    section_title = task.title or "–û–±—â–∏–π –æ—Ç–≤–µ—Ç –ø–æ –í–ö–†"


                # –ù–µ–±–æ–ª—å—à–æ–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–µ—Ä–µ–¥ –±–ª–æ–∫–æ–º –æ—Ç–≤–µ—Ç–∞
                await _send(m, f"\n=== {section_title} ===")

                # –ó–∞–ø—É—Å–∫–∞–µ–º —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É –æ—Ç–≤–µ—Ç–∞,
                # –∫–æ—Ç–æ—Ä–∞—è —Å–∞–º–∞ —Å–¥–µ–ª–∞–µ—Ç RAG/vision/–∞–Ω–∞–ª–∏–∑ –∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç —Ç–µ–∫—Å—Ç.
                await respond_with_answer(m, uid, doc_id, sub_q)

        # –Ω–∞ —ç—Ç–æ–º –≤—Å—ë: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–ª—É—á–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –±–ª–æ–∫–æ–≤ –ø–æ–¥—Ä—è–¥ ‚Äî
        # –æ–¥–∏–Ω –±–æ–ª—å—à–æ–π –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç–≤–µ—Ç, –Ω–æ —Ä–∞–∑–æ–±—Ä–∞–Ω–Ω—ã–π –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º

    except Exception:
        logger.exception("QA worker failed (uid=%s, doc_id=%s)", uid, doc_id)
        try:
            await _send(
                m,
                "–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ –ø—Ä–∏ —Ä–∞–∑–±–æ—Ä–µ –≤–æ–ø—Ä–æ—Å–∞. "
                "–ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–¥–∞—Ç—å –æ–¥–∏–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤–æ–ø—Ä–æ—Å."
            )
        except Exception:
            logger.exception("failed to send error message")


# ------------------------------ —ç–º–±–µ–¥–¥–∏–Ω–≥-–ø—Ä–æ—Ñ–∏–ª—å ------------------------------

def _current_embedding_profile() -> str:
    dim = probe_embedding_dim(None)
    if dim:
        return f"emb={Cfg.POLZA_EMB}|dim={dim}"
    return f"emb={Cfg.POLZA_EMB}"

def _needs_reindex_by_embeddings(con, doc_id: int) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–æ—Ä–∞ –ª–∏ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑-–∑–∞ —Å–º–µ–Ω—ã embedding-–º–æ–¥–µ–ª–∏
    –∏–ª–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.

    –í layout_profile —Ö—Ä–∞–Ω–∏–º —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞:
      "emb=polza-emb-v1|dim=768"
    """
    if not _table_has_columns(con, "documents", ["layout_profile"]):
        # —Å—Ç–∞—Ä—ã–µ –±–∞–∑—ã –±–µ–∑ layout_profile ‚Äî –ª—É—á—à–µ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å
        return True

    cur = con.cursor()
    cur.execute("SELECT layout_profile FROM documents WHERE id=?", (doc_id,))
    row = cur.fetchone()
    stored = (row["layout_profile"] or "") if row else ""
    if not stored:
        # –ø—Ä–æ—Ñ–∏–ª—è –Ω–µ—Ç ‚Äî —Ç–æ–∂–µ –ø–æ–≤–æ–¥ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å
        return True

    cur_model = Cfg.POLZA_EMB.strip().lower()
    stored_model = ""
    stored_dim: int | None = None

    for part in stored.split("|"):
        part = (part or "").strip().lower()
        if part.startswith("emb="):
            # "emb=polza-emb-v1" ‚Üí "polza-emb-v1"
            stored_model = part[4:]
        elif part.startswith("dim="):
            # "dim=768" ‚Üí 768
            try:
                stored_dim = int(part[4:])
            except ValueError:
                stored_dim = None

    # –µ—Å–ª–∏ embedding-–º–æ–¥–µ–ª—å –ø–æ–º–µ–Ω—è–ª–∞—Å—å ‚Äî —Ç–æ—á–Ω–æ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å
    if stored_model and stored_model != cur_model:
        return True

    # —Å–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, –µ—Å–ª–∏ –æ–Ω–∞ –∏–∑–≤–µ—Å—Ç–Ω–∞
    try:
        cur_dim = probe_embedding_dim(None)
    except Exception:
        cur_dim = None

    if cur_dim and stored_dim and cur_dim != stored_dim:
        return True

    # –≤—Å—ë —Å–æ–≤–ø–∞–ª–æ ‚Äî –º–æ–∂–Ω–æ –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç
    return False


# ------------------------------ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç ------------------------------

@dp.message(F.text & ~F.via_bot & ~F.text.startswith("/"))
async def qa(m: types.Message):
    uid = ensure_user(str(m.from_user.id))
    doc_id = ACTIVE_DOC.get(uid)

    if not doc_id:
        persisted = get_user_active_doc(uid)
        if persisted:
            ACTIVE_DOC[uid] = persisted
            doc_id = persisted

    text = (m.text or "").strip()

    # NEW: –µ—Å–ª–∏ –∂–¥—ë–º –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ—Ç–≤–µ—Ç–∞ ¬´–¥–∞/–Ω–µ—Ç¬ª –ø—Ä–æ [–º–æ–¥–µ–ª—å] ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –µ–≥–æ –æ—Ç–¥–µ–ª—å–Ω–æ
    pending = MODEL_EXTRA_PENDING.get(uid)
    if pending:
        low = text.lower()
        if low in ("–¥–∞", "–¥", "–∞–≥–∞", "–æ–∫", "—Ö–æ—Ä–æ—à–æ", "yes", "y"):
            info = MODEL_EXTRA_PENDING.pop(uid, None) or {}
            kind = (info.get("kind") or "generic").lower()

            if kind == "table_more":
                # doc_id –º–æ–≥–ª–∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –º–æ–º–µ–Ω—Ç –≤–æ–ø—Ä–æ—Å–∞ ¬´–æ–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ¬ª
                doc_id_for_pending = info.get("doc_id") or doc_id

                # –µ—Å–ª–∏ –ø–æ—á–µ–º—É-—Ç–æ doc_id –Ω–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å ‚Äî –ø–∞–¥–∞–µ–º –≤ –æ–±—â–∏–π [–º–æ–¥–µ–ª—å]
                if not doc_id_for_pending:
                    await _answer_with_model_extra(
                        m,
                        uid,
                        info.get("question") or "",
                    )
                    return

                await _answer_with_model_extra_table(
                    m,
                    uid,
                    doc_id_for_pending,
                    info.get("question") or "",
                    info.get("ctx_tables") or "",
                    info.get("nums") or [],
                )
            else:
                await _answer_with_model_extra(
                    m,
                    uid,
                    info.get("question") or "",
                )
            return
        # –ª—é–±–∞—è –¥—Ä—É–≥–∞—è —Ä–µ–ø–ª–∏–∫–∞ —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç –æ–∂–∏–¥–∞–Ω–∏–µ –∏ –∏–¥—ë—Ç –ø–æ –æ–±—ã—á–Ω–æ–º—É –ø—É—Ç–∏
        MODEL_EXTRA_PENDING.pop(uid, None)

    # üëã –†–ê–ù–ù–ò–ô –æ—Ç–≤–µ—Ç –Ω–∞ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ, –±–µ–∑ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ –æ—á–µ—Ä–µ–¥—å
    if _is_greeting(text):
        greet = getattr(
            Cfg, "MSG_GREET",
            "–ü—Ä–∏–≤–µ—Ç! –Ø —Ä–µ–ø–µ—Ç–∏—Ç–æ—Ä –ø–æ —Ç–≤–æ–µ–π –í–ö–†. –ü—Ä–∏—à–ª–∏ —Ñ–∞–π–ª –í–ö–† (.doc/.docx) ‚Äî –∏ —è –ø–æ–º–æ–≥—É –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é."
        )
        await _send(m, greet)
        return

    if not doc_id:
        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ–ø—Ä–æ—Å, —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç–∏—Ç—å –ø–æ—Å–ª–µ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø–µ—Ä–≤–æ–≥–æ —Ñ–∞–π–ª–∞
        if text:
            enqueue_pending_query(uid, text, meta={"source": "chat", "reason": "no_active_doc"})
        await _send(m, Cfg.MSG_NEED_FILE_QUEUED)
        return

    # ‚¨á‚¨á‚¨á –ù–û–í–û–ï: –≤–º–µ—Å—Ç–æ –ø—Ä—è–º–æ–≥–æ await respond_with_answer

    # –ø—Ä–∏ –¥–ª–∏–Ω–Ω–æ–º –≤–æ–ø—Ä–æ—Å–µ –¥–∞—ë–º –±—ã—Å—Ç—Ä—ã–π –∫–≤–∏—Ç–æ–∫, —á—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–∏–¥–µ–ª, —á—Ç–æ —Ä–∞–±–æ—Ç–∞ –Ω–∞—á–∞–ª–∞—Å—å
    if len(text) > 200:
        await _send(
            m,
            "–ó–∞–ø—Ä–æ—Å –±–æ–ª—å—à–æ–π, —è –≥–æ—Ç–æ–≤–ª—é –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç–≤–µ—Ç. –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ üôÇ"
        )

    # –∑–∞–ø—É—Å–∫–∞–µ–º —Ç—è–∂—ë–ª—ã–π –ø–∞–π–ø–ª–∞–π–Ω –≤ —Ñ–æ–Ω–µ, –Ω–µ –±–ª–æ–∫–∏—Ä—É—è –æ–±—Ä–∞–±–æ—Ç–∫—É –∞–ø–¥–µ–π—Ç–∞
    asyncio.create_task(_qa_worker(m, uid, doc_id, text))
