# app/answer_builder.py
from __future__ import annotations

import re
import json
import asyncio
from typing import Dict, List, Any, Optional, AsyncIterable, Iterable, Union

# --- –ü—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ –º–æ–¥–µ–ª–∏ (–±–µ–∑ ACE) ---
try:
    from .polza_client import chat_with_gpt, chat_with_gpt_stream  # type: ignore
except Exception:
    chat_with_gpt = None          # type: ignore
    chat_with_gpt_stream = None   # type: ignore

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ ¬´–ø–æ–¥—Å–∫–∞–∑–∫–∏¬ª –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º (–µ—Å–ª–∏ –º–æ–¥—É–ª—å –µ—Å—Ç—å)
try:
    from .analytics import analyze_table_by_num  # type: ignore
except Exception:
    analyze_table_by_num = None  # type: ignore

# –ù–æ–≤—ã–µ: –¥–ª—è –ø–æ–ª–Ω–æ–π –≤—ã–≥—Ä—É–∑–∫–∏ —Ç–∞–±–ª–∏—Ü
from .config import Cfg
from .db import get_conn

# –•–µ–ª–ø–µ—Ä—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –Ω–æ–º–µ—Ä–æ–≤/—Ñ–ª–∞–≥–æ–≤/–ø–æ–¥—Å–∫–∞–∑–æ–∫ –∏–∑ intents (—á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–≥–µ–∫—Å—ã)
try:
    from .intents import extract_table_numbers, extract_section_hints, extract_figure_numbers  # type: ignore
except Exception:
    extract_table_numbers = None  # type: ignore
    extract_figure_numbers = None  # type: ignore


    # –§–æ–ª–±—ç–∫: –ø—Ä–∏–º–∏—Ç–∏–≤–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –ø–æ–¥—Å–∫–∞–∑–æ–∫ —Ä–∞–∑–¥–µ–ª–æ–≤ ¬´–≥–ª–∞–≤–∞/—Ä–∞–∑–¥–µ–ª/¬ß/section 2.2¬ª
    _SECTION_HINT_RE = re.compile(
        r"(?i)\b(–≥–ª–∞–≤–∞|—Ä–∞–∑–¥–µ–ª|–ø—É–Ω–∫—Ç|–ø–æ–¥—Ä–∞–∑–¥–µ–ª|¬ß|section|chapter|clause)\s*([A-Za-z–ê-–Ø–∞-—è]?\s*\d+(?:[.,]\d+)*)"
    )

    def _normalize_num_fallback(s: str) -> str:
        s = (s or "").replace(" ", "").replace(",", ".")
        s = re.sub(r"([A-Za-z–ê-–Ø–∞-—è])[\.\-]?(?=\d)", r"\1", s)
        return s.strip()

    def extract_section_hints(text: str) -> List[str]:  # type: ignore
        out: List[str] = []
        for m in _SECTION_HINT_RE.findall(text or ""):
            val = _normalize_num_fallback(m[1] or "")
            if val:
                out.append(val)
        # —É–Ω–∏–∫–∞–ª–∏–∑–∏—Ä—É–µ–º, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
        seen = set()
        uniq: List[str] = []
        for v in out:
            if v not in seen:
                seen.add(v)
                uniq.append(v)
        return uniq

try:
    from .intents import TABLE_ALL_VALUES_RE, TABLE_ROWS_LIMIT_RE, EXACT_NUMBERS_RE  # type: ignore
except Exception:
    TABLE_ALL_VALUES_RE = re.compile(
        r"(?i)\b(–≤—Å–µ|–≤—Å—é|—Ü–µ–ª–∏–∫–æ–º|–ø–æ–ª–Ω–æ—Å—Ç—å—é|–ø–æ–ª–Ω–∞—è)\b.*\b(—Ç–∞–±–ª–∏—Ü\w*|—Ç–∞–±–ª–∏—Ü–∞|–∑–Ω–∞—á–µ–Ω–∏\w*|–¥–∞–Ω–Ω\w*|—Å—Ç—Ä–æ–∫\w*|–∫–æ–ª–æ–Ω\w*)\b"
        r"|(?:\ball\b.*\b(table|values|rows|columns)\b|\bfull\s+(table|values)\b|\bentire\s+table\b)"
    )
    TABLE_ROWS_LIMIT_RE = re.compile(
        r"(?i)(?:–ø–æ–∫–∞–∂[–∏–π]|–≤—ã–≤–µ–¥–∏|–¥–∞–π|–æ—Ç–æ–±—Ä–∞–∑–∏|–≤–µ—Ä–Ω–∏|–ø–µ—Ä–≤—ã–µ)\s+(\d{1,4})\s+(—Å—Ç—Ä–æ–∫\w*|rows?)\b"
        r"|(^|\s)(\d{1,4})\s+(—Å—Ç—Ä–æ–∫\w*|rows?)\b"
        r"|top\s+(\d{1,4})\b"
    )
    EXACT_NUMBERS_RE = re.compile(
        r"(?i)(—Ç–æ—á–Ω\w+\s+–∫–∞–∫\s+–≤\s+(–¥–æ–∫—É–º–µ–Ω—Ç–µ|—Ç–µ–∫—Å—Ç–µ|—Ñ–∞–π–ª–µ)|—Ä–æ–≤–Ω–æ\s+–∫–∞–∫\s+–≤\s+(–¥–æ–∫—É–º–µ–Ω—Ç–µ|—Ç–µ–∫—Å—Ç–µ|—Ñ–∞–π–ª–µ)|–∫–∞–∫\s+–µ—Å—Ç—å|"
        r"–±–µ–∑\s+–æ–∫—Ä—É–≥–ª–µ–Ω\w+|–Ω–µ\s*(–º–µ–Ω—è–π|–∏–∑–º–µ–Ω—è–π)\s*(—Ñ–æ—Ä–º–∞—Ç|–∑–∞–ø—è—Ç|—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª)|—Å–æ—Ö—Ä–∞–Ω–∏\w*\s*(—Ñ–æ—Ä–º–∞—Ç|–≤–∏–¥|—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª|–∑–∞–ø—è—Ç)|"
        r"–±–µ–∑\s+–Ω–æ—Ä–º–∞–ª–∏–∑\w+|exact(ly)?\s+as\s+in\s+(doc(ument)?|file|text)|keep\s+format|do\s+not\s+change\s+(format|commas|separators)|"
        r"no\s+round(ing)?|as-is)"
    )

# ----------------------------- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –ª–∏–º–∏—Ç–æ–≤ -----------------------------
FULL_TABLE_MAX_ROWS: int = getattr(Cfg, "FULL_TABLE_MAX_ROWS", 500)
FULL_TABLE_MAX_COLS: int = getattr(Cfg, "FULL_TABLE_MAX_COLS", 40)
FULL_TABLE_MAX_CHARS: int = getattr(Cfg, "FULL_TABLE_MAX_CHARS", 20_000)

# –°–∫–æ–ª—å–∫–æ —Ç–∞–±–ª–∏—Ü –ø–æ–¥—Ç—è–≥–∏–≤–∞—Ç—å —Å ¬´–≥–ª–∞–≤–Ω–æ–≥–æ¬ª —Ä–∞–∑–¥–µ–ª–∞, –µ—Å–ª–∏ –Ω–æ–º–µ—Ä –Ω–µ —É–∫–∞–∑–∞–Ω
SECTION_TABLES_MAX: int = getattr(Cfg, "SECTION_TABLES_MAX", 3)

# ----------------------------- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ -----------------------------

_NUM_TOKEN = re.compile(r"(?<!\d)(\d{1,3}(?:[ \u00A0]\d{3})+|\d+)([.,]\d+)?\s*(%?)")

def _normalize_numbers(s: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–∏—Å–µ–ª –≤ –ë–õ–û–ö–ï –§–ê–ö–¢–û–í (–Ω–µ –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º –æ—Ç–≤–µ—Ç–µ!):
      - 12 345 ‚Üí 12345 (—É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã —Ç—ã—Å—è—á);
      - 1,25 ‚Üí 1.25 (–¥–µ—Å—è—Ç–∏—á–Ω–∞—è —Ç–æ—á–∫–∞);
      - '  %' ‚Üí '%'.
    """
    def repl(m: re.Match) -> str:
        int_part = (m.group(1) or "").replace(" ", "").replace("\u00A0", "")
        frac = (m.group(2) or "").replace(",", ".")
        pct = (m.group(3) or "")
        return f"{int_part}{frac}{pct}"

    s = _NUM_TOKEN.sub(repl, s or "")
    # —É–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–ª–∏–Ω–Ω—ã—Ö —Ç–∏—Ä–µ/–º–∏–Ω—É—Å–æ–≤
    s = s.replace("‚Äì", "‚Äî").replace("--", "‚Äî")
    return s

def _shorten(s: str, limit: int = 300) -> str:
    s = (s or "").strip()
    return s if len(s) <= limit else (s[:limit - 1].rstrip() + "‚Ä¶")

def _md_list(arr: List[str], max_show: int, more: Optional[int], *, norm_numbers: bool = True) -> str:
    out = []
    for x in (arr or [])[:max_show]:
        out.append(f"- {_normalize_numbers(x) if norm_numbers else x}")
    if more and more > 0:
        out.append(f"‚Ä¶ –∏ –µ—â—ë {more}")
    return "\n".join(out)

# ----------------------------- –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ -----------------------------

_DEFAULT_RULES = (
    "1) –ï—Å–ª–∏ –≤ —Å–µ–∫—Ü–∏–∏ [Items] –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã –ø–æ–¥–ø—É–Ω–∫—Ç—ã ‚Äî –æ—Ç–≤–µ—á–∞–π –ø–æ –ö–ê–ñ–î–û–ú–£ –ø–æ–¥–ø—É–Ω–∫—Ç—É –æ—Ç–¥–µ–ª—å–Ω–æ, —Å—Ç—Ä–æ–≥–æ –ø–æ –ø–æ—Ä—è–¥–∫—É, "
    "—Å–æ—Ö—Ä–∞–Ω—è—è –Ω—É–º–µ—Ä–∞—Ü–∏—é 1), 2), 3). –ù–µ —Å–º–µ—à–∏–≤–∞–π –æ—Ç–≤–µ—Ç—ã –ø–æ —Ä–∞–∑–Ω—ã–º –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º. "
    "–ï—Å–ª–∏ –ø–æ–¥–ø—É–Ω–∫—Ç—ã –Ω–µ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã ‚Äî –∑–∞–∫—Ä–æ–π –≤—Å–µ —Å–º—ã—Å–ª–æ–≤—ã–µ –ø—É–Ω–∫—Ç—ã –≤–æ–ø—Ä–æ—Å–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ.\n"
    "2) –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π Markdown-–∑–∞–≥–æ–ª–æ–≤–∫–∏ (#, ##, ###). –î–ª—è –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π –∂–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –¥–≤–æ–µ—Ç–æ—á–∏–µ: **–ü—É–Ω–∫—Ç 2.3:** ...\n"
    "3) –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü: –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–º–µ—Ä ‚Üí ¬´–¢–∞–±–ª–∏—Ü–∞ N ‚Äî –ù–∞–∑–≤–∞–Ω–∏–µ¬ª; –µ—Å–ª–∏ –Ω–æ–º–µ—Ä–∞ –Ω–µ—Ç ‚Äî —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏–µ. "
    "–ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ä–∏—Å—É–Ω–∫–æ–≤/–¥–∏–∞–≥—Ä–∞–º–º: –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–º–µ—Ä ‚Üí ¬´–†–∏—Å—É–Ω–æ–∫ N ‚Äî –ù–∞–∑–≤–∞–Ω–∏–µ¬ª.\n"
    "4) –ù–µ –≤—ã–≤–æ–¥–∏ —Å–ª—É–∂–µ–±–Ω—ã–µ –º–µ—Ç–∫–∏ –∏ —Ä–∞–∑–º–µ—Ä—ã (–Ω–∏–∫–∞–∫–∏—Ö [–¢–∞–±–ª–∏—Ü–∞], ¬´—Ä—è–¥ 1¬ª, ¬´(6√ó7)¬ª).\n"
    "5) –í —Å–ø–∏—Å–∫–∞—Ö –ø–æ–∫–∞–∂–∏ –Ω–µ –±–æ–ª–µ–µ 25 —Å—Ç—Ä–æ–∫, –∑–∞—Ç–µ–º ¬´‚Ä¶ –∏ –µ—â—ë M¬ª, –µ—Å–ª–∏ –µ—Å—Ç—å.\n"
    "6) –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã –≤–Ω–µ –±–ª–æ–∫–∞ Facts (Tables/Figures/TablesRaw/values); –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî —Å–∫–∞–∂–∏ —á–µ—Å—Ç–Ω–æ.\n"
    "7) –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç —Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è ¬´–∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ/–±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏¬ª ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–π –∏—Å—Ö–æ–¥–Ω—ã–π –≤–∏–¥ —á–∏—Å–µ–ª (—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ —Ç—ã—Å—è—á, –∑–∞–ø—è—Ç–∞—è/—Ç–æ—á–∫–∞, –¥–µ—Ñ–∏—Å—ã).\n"
    "8) –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ —Ä–∏—Å—É–Ω–∫–∏/–¥–∏–∞–≥—Ä–∞–º–º—ã/–≥—Ä–∞—Ñ–∏–∫–∏ ‚Äî –æ–ø–∏—Ä–∞–π—Å—è –Ω–∞ —Ä–∞–∑–¥–µ–ª [Figures] (–≤–∫–ª—é—á–∞—è describe, describe_cards –∏ –∑–Ω–∞—á–µ–Ω–∏—è –¥–∏–∞–≥—Ä–∞–º–º), "
    "–Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —á–∏—Å–ª–∞, –∫–æ—Ç–æ—Ä—ã—Ö —Ç–∞–º –Ω–µ—Ç.\n"
    "9) –î–ª—è –¥–∏–∞–≥—Ä–∞–º–º –∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Å–Ω–∞—á–∞–ª–∞ –∫–æ—Ä–æ—Ç–∫–æ –ø–æ—è—Å–Ω–∏, —á—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –æ—Å–∏, –ª–µ–≥–µ–Ω–¥–∞ –∏ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è, –∫–∞–∫ —É—Å—Ç—Ä–æ–µ–Ω –º–∞—Å—à—Ç–∞–± (—à–∞–≥ —à–∫–∞–ª—ã, –Ω–∞—á–∞–ª–æ –æ—Ç—Å—á—ë—Ç–∞). "
    "–ï—Å–ª–∏ –≤ [Figures]/values –Ω–µ—Ç —è–≤–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –º–∞—Å—à—Ç–∞–±–∞, –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –µ–≥–æ: –ø—Ä—è–º–æ —É–∫–∞–∑—ã–≤–∞–π, —á—Ç–æ –º–∞—Å—à—Ç–∞–± –º–æ–∂–Ω–æ —Ç–æ–ª—å–∫–æ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å –ø–æ –ø–æ–¥–ø–∏—Å—è–º.\n"
    "10) –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞: —Å–Ω–∞—á–∞–ª–∞ –¥–∞–π –±–ª–æ–∫ '[–¥–æ–∫—É–º–µ–Ω—Ç]' ‚Äî –æ—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –ø–æ —Ñ–∞–∫—Ç–∞–º –∏–∑ [Facts]; –∑–∞—Ç–µ–º –±–ª–æ–∫ '[–º–æ–¥–µ–ª—å]' ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–µ –æ–±—â–∏–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è, "
    "–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –∏ —Å–æ–≤–µ—Ç—ã –ø–æ —Ç–µ–º–µ –≤–æ–ø—Ä–æ—Å–∞. –í –±–ª–æ–∫–µ '[–º–æ–¥–µ–ª—å]' –Ω–µ –¥–æ–±–∞–≤–ª—è–π –Ω–æ–≤—ã—Ö ¬´—Ñ–∞–∫—Ç–æ–≤¬ª –ø—Ä–æ –¥–æ–∫—É–º–µ–Ω—Ç, —Ç–æ–ª—å–∫–æ –æ–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏. "
    "–ï—Å–ª–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π –Ω–µ—Ç, –≤—Å—ë —Ä–∞–≤–Ω–æ –≤—ã–≤–µ–¥–∏ —Å—Ç—Ä–æ–∫—É '[–º–æ–¥–µ–ª—å] –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –Ω–µ—Ç'.\n"
    "11) –ï—Å–ª–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´—Ä–∏—Å—É–Ω–æ–∫ 2.2, —Ç–∞–±–ª–∏—Ü–∞ 2.1 –∏ –≥–ª–∞–≤–∞ 1¬ª), "
    "–æ—Ñ–æ—Ä–º–ª—è–π –æ—Ç–≤–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ –±–ª–æ–∫–∞–º–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –æ–±—ä–µ–∫—Ç—É: —Å–Ω–∞—á–∞–ª–∞ ¬´–†–∏—Å—É–Ω–æ–∫ 2.2 ‚Äî ‚Ä¶¬ª, –∑–∞—Ç–µ–º ¬´–¢–∞–±–ª–∏—Ü–∞ 2.1 ‚Äî ‚Ä¶¬ª, –∑–∞—Ç–µ–º ¬´–ì–ª–∞–≤–∞ 1 ‚Äî ‚Ä¶¬ª. "
    "–í–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞ –æ–ø–∏—Ä–∞–π—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ —Ñ–∞–∫—Ç—ã, –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ —ç—Ç–æ–º—É –æ–±—ä–µ–∫—Ç—É.\n"
)

# –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏-–∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤ **–∂–∏—Ä–Ω—ã–π**
_HEAD_TO_BOLD_RE = re.compile(r"(?m)^\s*#{1,6}\s*(.+?)\s*$")
def _headings_to_bold(text: str) -> str:
    return _HEAD_TO_BOLD_RE.sub(lambda m: f"**{m.group(1).strip()}**", text or "")

# ----------------------------- –í—Å–ø–æ–º–æ–≥–∞–ª–∫–∏ –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö -----------------------------

_CAP_RE = re.compile(
    r"(?i)\b—Ç–∞–±–ª–∏—Ü–∞\s+([A-Za-z–ê-–Ø–∞-—è]?\s*\d+(?:[.,]\d+)*)\b(?:\s*[‚Äî\-‚Äì:\u2013\u2014]\s*(.+))?"
)

def _normalize_num(s: str) -> str:
    s = (s or "").replace(" ", "").replace(",", ".")
    return s.strip()

# --- –ù–û–í–û–ï: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–º–µ—Ä–æ–≤ —Ä–∏—Å—É–Ω–∫–æ–≤ / —Ñ–æ–∫—É—Å –ø–æ –æ–¥–Ω–æ–º—É —Ä–∏—Å—É–Ω–∫—É ---

def _normalize_fig_num_local(s: str) -> str:
    """
    –õ–æ–∫–∞–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–º–µ—Ä–∞ —Ä–∏—Å—É–Ω–∫–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:
      - —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã;
      - –∑–∞–ø—è—Ç—É—é ‚Üí —Ç–æ—á–∫—É;
      - —Å–∫–ª–µ–∏–≤–∞–µ–º –ª–∏—Ç–µ—Ä—É –∏ —Ü–∏—Ñ—Ä—É: 'A.1'/'A-1' ‚Üí 'A1'.
    """
    s = (s or "").strip()
    s = s.replace(" ", "").replace(",", ".")
    s = re.sub(r"([A-Za-z–ê-–Ø–∞-—è])[\.\-]?(?=\d)", r"\1", s)
    return s

def _figure_focus_from_facts(facts: Dict[str, Any]) -> List[str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –Ω–æ–º–µ—Ä–æ–≤ —Ä–∏—Å—É–Ω–∫–æ–≤, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –Ω—É–∂–Ω–æ —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è.
    –û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏:
      - intents['figures']['single_only'] == True –∏ –µ—Å—Ç—å describe —Å –Ω–æ–º–µ—Ä–∞–º–∏;
      - facts['figures']['single_only'] == True –∏ –µ—Å—Ç—å describe_nums;
      - fallback: –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –∫–∞—Ä—Ç–æ—á–∫–∞ –≤ describe_cards ‚Üí –µ—ë num.
    """
    nums: List[str] = []

    # 1) –ò–∑ intents, –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–æ–±—Ä–æ—à–µ–Ω—ã –≤ facts
    try:
        intents = (facts or {}).get("intents") or {}
        fig_i = (intents.get("figures") or {})
        if fig_i.get("single_only") and fig_i.get("describe"):
            for n in fig_i.get("describe") or []:
                v = _normalize_fig_num_local(str(n))
                if v:
                    nums.append(v)
    except Exception:
        pass

    # 2) –ò–∑ facts['figures'], –µ—Å–ª–∏ —Ç—É–¥–∞ —è–≤–Ω–æ –ø–æ–ª–æ–∂–∏–ª–∏ —Ñ–ª–∞–≥/–Ω–æ–º–µ—Ä–∞
    if not nums:
        try:
            fig_f = (facts or {}).get("figures") or {}
            if fig_f.get("single_only"):
                for n in (fig_f.get("describe_nums") or []):
                    v = _normalize_fig_num_local(str(n))
                    if v:
                        nums.append(v)
        except Exception:
            pass

    # 3) Fallback: —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∞ –∫–∞—Ä—Ç–æ—á–∫–∞ —Ä–∏—Å—É–Ω–∫–∞ ‚Üí —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ –Ω–µ—ë
    if not nums:
        try:
            fig_f = (facts or {}).get("figures") or {}
            cards = fig_f.get("describe_cards") or []
            if isinstance(cards, list) and len(cards) == 1:
                n = cards[0].get("num")
                if n:
                    v = _normalize_fig_num_local(str(n))
                    if v:
                        nums.append(v)
        except Exception:
            pass

    # –¥–µ–¥—É–ø —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞
    seen = set()
    out: List[str] = []
    for v in nums:
        if v and v not in seen:
            seen.add(v)
            out.append(v)
    return out

def _filter_lines_for_figure_focus(lines: List[str], focus_nums: List[str]) -> List[str]:
    """
    –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–Ω–æ —Å—Å—ã–ª–∞—é—Ç—Å—è –Ω–∞ –Ω—É–∂–Ω—ã–π(–µ) –Ω–æ–º–µ—Ä(–∞) —Ä–∏—Å—É–Ω–∫–∞:
      - –ø–∞—Ä—Å–∏–º –Ω–æ–º–µ—Ä–∞ —á–µ—Ä–µ–∑ extract_figure_numbers, –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º;
      - –µ—Å–ª–∏ –≤ —Å—Ç—Ä–æ–∫–µ –Ω–µ—Ç –Ω–æ–º–µ—Ä–æ–≤ ‚Üí –≤ single-—Ä–µ–∂–∏–º–µ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º (—á—Ç–æ–±—ã –Ω–µ –ø—Ä–æ—Ç–∞—â–∏—Ç—å —á—É–∂–æ–π —Ä–∏—Å—É–Ω–æ–∫);
      - –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–æ–º–µ—Ä–∞, –Ω–æ —Å—Ä–µ–¥–∏ –Ω–∏—Ö –µ—Å—Ç—å —á—É–∂–∏–µ ‚Üí —Å—Ç—Ä–æ–∫—É –≤—ã–∫–∏–¥—ã–≤–∞–µ–º.
    """
    if not focus_nums:
        return [str(x).strip() for x in (lines or []) if str(x).strip()]

    focus_set = {n for n in focus_nums if n}
    out: List[str] = []

    for x in (lines or []):
        s = str(x or "").strip()
        if not s:
            continue

        nums: List[str] = []
        if extract_figure_numbers:
            try:
                nums = extract_figure_numbers(s) or []  # type: ignore
            except Exception:
                nums = []

        if not nums:
            # –≤ —Ä–µ–∂–∏–º–µ ¬´—Ç–æ–ª—å–∫–æ –†–∏—Å—É–Ω–æ–∫ N¬ª –Ω–µ —Ç–∞—â–∏–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ —è–≤–Ω–æ–≥–æ –Ω–æ–º–µ—Ä–∞
            continue

        norm_in_line = {_normalize_fig_num_local(n) for n in nums}
        if norm_in_line.issubset(focus_set):
            out.append(s)

    return out

def _parse_table_title(text: str) -> tuple[Optional[str], Optional[str]]:
    m = _CAP_RE.search(text or "")
    if not m:
        return (None, None)
    raw_num = (m.group(1) or "").replace(" ", "")
    return (_normalize_num(raw_num), (m.group(2) or "").strip() or None)

def _last_segment(name: str) -> str:
    s = (name or "").strip()
    if "/" in s:
        s = s.split("/")[-1].strip()
    s = re.sub(r"^\[\s*—Ç–∞–±–ª–∏—Ü–∞\s*\]\s*", "", s, flags=re.IGNORECASE)
    s = re.sub(r"\s*[-‚Äì‚Äî]\s*", " ‚Äî ", s)
    s = re.sub(r"\s+", " ", s).strip(" .")
    return s

def _compose_display(attrs_json: Optional[str], base: str, first_row_text: Optional[str]) -> str:
    num = None
    tail = None
    header_preview = None
    if attrs_json:
        try:
            a = json.loads(attrs_json or "{}")
            num = a.get("caption_num") or a.get("label")
            tail = a.get("caption_tail") or a.get("title")
            header_preview = a.get("header_preview")
        except Exception:
            pass

    if num:
        num = str(num).replace(",", ".").strip()
        tail_like = (tail or header_preview or first_row_text or "").strip()
        return f"–¢–∞–±–ª–∏—Ü–∞ {num}" + (f" ‚Äî {_shorten(tail_like, 160)}" if tail_like else "")

    num_b, title_b = _parse_table_title(_last_segment(base))
    if num_b:
        text_tail = title_b or first_row_text or header_preview
        return f"–¢–∞–±–ª–∏—Ü–∞ {num_b}" + (f" ‚Äî {_shorten(text_tail, 160)}" if text_tail else "")

    if tail:
        return _shorten(str(tail), 160)
    if header_preview:
        return _shorten(str(header_preview), 160)
    if first_row_text:
        return _shorten(first_row_text, 160)

    s = _last_segment(base)
    s = re.sub(r"(?i)^\s*—Ç–∞–±–ª–∏—Ü–∞\s+\d+(?:\.\d+)*\s*", "", s).strip(" ‚Äî‚Äì-")
    return _shorten(s or "–¢–∞–±–ª–∏—Ü–∞", 160)

def _table_has_columns(con, table: str, cols: List[str]) -> bool:
    cur = con.cursor()
    cur.execute(f"PRAGMA table_info({table})")
    have = {row[1] for row in cur.fetchall()}
    return all(c in have for c in cols)

def _find_table_anchor(uid: int, doc_id: int, num: str) -> Optional[Dict[str, Any]]:
    want = _normalize_num(num)
    con = get_conn()
    cur = con.cursor()
    has_ext = _table_has_columns(con, "chunks", ["element_type", "attrs"])

    row = None
    if has_ext:
        like1 = f'%\"caption_num\": \"{want}\"%'
        like2 = f'%\"label\": \"{want}\"%'
        cur.execute(
            """
            SELECT page, section_path, attrs
            FROM chunks
            WHERE owner_id=? AND doc_id=? AND element_type IN ('table','table_row')
              AND (attrs LIKE ? OR attrs LIKE ?)
            ORDER BY id ASC LIMIT 1
            """,
            (uid, doc_id, like1, like2),
        )
        row = cur.fetchone()
        if not row:
            cur.execute(
                """
                SELECT page, section_path, attrs
                FROM chunks
                WHERE owner_id=? AND doc_id=? AND element_type IN ('table','table_row')
                  AND section_path LIKE ? COLLATE NOCASE
                ORDER BY id ASC LIMIT 1
                """,
                (uid, doc_id, f'%–¢–∞–±–ª–∏—Ü–∞ {want}%'),
            )
            row = cur.fetchone()
    else:
        cur.execute(
            """
            SELECT page, section_path, NULL AS attrs
            FROM chunks
            WHERE owner_id=? AND doc_id=? 
              AND (lower(section_path) LIKE '%%—Ç–∞–±–ª–∏—Ü–∞ %%' OR text LIKE '[–¢–∞–±–ª–∏—Ü–∞]%%')
              AND section_path LIKE ? COLLATE NOCASE
            ORDER BY id ASC LIMIT 1
            """,
            (uid, doc_id, f'%–¢–∞–±–ª–∏—Ü–∞ {want}%'),
        )
        row = cur.fetchone()

    con.close()
    return dict(row) if row else None

def _base_from_section(section_path: str) -> str:
    s = section_path or ""
    i = s.find(" [row ")
    return s if i < 0 else s[:i]

def _split_cells(line: str) -> List[str]:
    s = (line or "").strip()
    if " | " in s:
        cells = [c.strip() for c in s.split(" | ")]
    elif "\t" in s:
        cells = [c.strip() for c in s.split("\t")]
    else:
        cells = [c.strip() for c in re.split(r"\s{2,}", s)]
    return [c for c in cells if c != ""]

def _detect_header_and_matrix(rows_texts: List[str]) -> tuple[List[str], List[List[str]]]:
    raw_rows = [_split_cells((t or "").splitlines()[0]) for t in rows_texts if (t or "").strip()]
    if not raw_rows:
        return ([], [])

    def frac_numeric(cells: List[str]) -> float:
        if not cells:
            return 0.0
        num_re = re.compile(r"^[+-]?\d{1,3}(?:[\s\u00A0]\d{3})*(?:[.,]\d+)?%?$|^[+-]?\d+(?:[.,]\d+)?%?$")
        n = sum(1 for c in cells if num_re.match(c.strip()))
        return n / max(1, len(cells))

    header_candidates = raw_rows[0]
    data_candidates = raw_rows[1:] if len(raw_rows) > 1 else []
    use_header = False
    if data_candidates:
        if frac_numeric(header_candidates) <= 0.25 and any(frac_numeric(r) >= 0.4 for r in data_candidates[:3]):
            use_header = True

    if use_header:
        headers = header_candidates
        data_rows = data_candidates
    else:
        max_len = max(len(r) for r in raw_rows)
        headers = [f"–ö–æ–ª–æ–Ω–∫–∞ {i+1}" for i in range(max_len)]
        data_rows = raw_rows

    W = min(len(headers), FULL_TABLE_MAX_COLS)
    headers = headers[:W]
    matrix: List[List[str]] = []
    for r in data_rows:
        row = (r + [""] * W)[:W]
        matrix.append(row)
    headers = [_shorten(h, 80) for h in headers]
    return (headers, matrix)

def _fetch_table_rows(uid: int, doc_id: int, base: str) -> List[Dict[str, Any]]:
    con = get_conn()
    cur = con.cursor()
    if _table_has_columns(con, "chunks", ["element_type"]):
        sql = """
            SELECT text, page FROM chunks
            WHERE owner_id=? AND doc_id=? AND element_type='table_row'
              AND (section_path=? OR section_path LIKE ? || ' [row %')
            ORDER BY id ASC
        """
    else:
        sql = """
            SELECT text, page FROM chunks
            WHERE owner_id=? AND doc_id=? AND (section_path=? OR section_path LIKE ? || ' [row %')
            ORDER BY id ASC
        """
    cur.execute(sql, (uid, doc_id, base, base))
    rows = cur.fetchall() or []
    con.close()
    return [{"text": (r["text"] or ""), "page": r["page"]} for r in rows]

def _apply_rows_and_char_limits(payload: Dict[str, Any]) -> Dict[str, Any]:
    """
    –û–±—Ä–µ–∑–∞–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º/—Å–∏–º–≤–æ–ª–∞–º, —á—Ç–æ–±—ã –Ω–µ –≤—ã–≤–∞–ª–∏—Ç—å—Å—è –∑–∞ —Ä–∞–∑—É–º–Ω—ã–µ –ª–∏–º–∏—Ç—ã –ø—Ä–æ–º–ø—Ç–∞.
    """
    rows: List[List[str]] = payload.get("rows") or []
    headers: List[str] = payload.get("headers") or []
    total_rows = len(rows)
    truncated = False

    # –õ–∏–º–∏—Ç —Å—Ç—Ä–æ–∫
    if total_rows > payload.get("_rows_limit_effective", FULL_TABLE_MAX_ROWS):
        rows = rows[: payload.get("_rows_limit_effective", FULL_TABLE_MAX_ROWS)]
        truncated = True

    # –õ–∏–º–∏—Ç —Å–∏–º–≤–æ–ª–æ–≤ (–≥—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ json.dumps)
    obj = {"headers": headers, "rows": rows}
    text = json.dumps(obj, ensure_ascii=False)
    if len(text) > FULL_TABLE_MAX_CHARS:
        # –≥—Ä—É–±–æ —É–º–µ–Ω—å—à–∞–µ–º, –ø–æ–∫–∞ –Ω–µ –≤–ª–µ–∑–µ—Ç
        step = max(5, len(rows) // 10)
        n = len(rows)
        while n > 0 and len(json.dumps({"headers": headers, "rows": rows[:n]}, ensure_ascii=False)) > FULL_TABLE_MAX_CHARS:
            n -= step
        rows = rows[: max(1, n)]
        truncated = True

    payload["rows"] = rows
    payload["total_rows"] = int(total_rows)
    payload["truncated"] = bool(truncated or total_rows > len(rows))
    payload.pop("_rows_limit_effective", None)
    return payload

# ---------- –ù–û–í–û–ï: —Ç–∞–±–ª–∏—Ü—ã –ø–æ –ø–æ–¥—Å–∫–∞–∑–∫–µ ¬´–≤ –≥–ª–∞–≤–µ/—Ä–∞–∑–¥–µ–ª–µ¬ª (–±–µ–∑ –Ω–æ–º–µ—Ä–∞) ----------

def _distinct_table_bases_by_section(uid: int, doc_id: int, sect_hint: str) -> List[str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ ¬´–±–∞–∑–æ–≤—ã–µ¬ª –∏–º–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü (section_path –±–µ–∑ —Ö–≤–æ—Å—Ç–∞ ' [row ‚Ä¶]')
    –¥–ª—è —Ä–∞–∑–¥–µ–ª–æ–≤, –≤ —Å–µ–∫—Ü–∏–æ–Ω–Ω—ã—Ö –ø—É—Ç—è—Ö –∫–æ—Ç–æ—Ä—ã—Ö –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è `sect_hint` (–Ω–∞–ø—Ä–∏–º–µ—Ä: '2.2', '3', 'A1').
    """
    con = get_conn()
    cur = con.cursor()
    has_type = _table_has_columns(con, "chunks", ["element_type"])

    if has_type:
        cur.execute(
            """
            SELECT DISTINCT
                CASE
                    WHEN instr(section_path, ' [row ')>0
                        THEN substr(section_path, 1, instr(section_path,' [row ')-1)
                    ELSE section_path
                END AS base_name
            FROM chunks
            WHERE owner_id=? AND doc_id=? AND element_type IN ('table','table_row')
              AND section_path LIKE ? COLLATE NOCASE
            """,
            (uid, doc_id, f"%{sect_hint}%"),
        )
    else:
        cur.execute(
            """
            SELECT DISTINCT
                CASE
                    WHEN instr(section_path, ' [row ')>0
                        THEN substr(section_path, 1, instr(section_path,' [row ')-1)
                    ELSE section_path
                END AS base_name
            FROM chunks
            WHERE owner_id=? AND doc_id=? 
              AND (lower(section_path) LIKE '%—Ç–∞–±–ª–∏—Ü–∞ %' OR lower(text) LIKE '[—Ç–∞–±–ª–∏—Ü–∞]%')
              AND section_path LIKE ? COLLATE NOCASE
            """,
            (uid, doc_id, f"%{sect_hint}%"),
        )
    rows = cur.fetchall() or []
    con.close()

    bases = [r["base_name"] for r in rows if r and r["base_name"]]
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ —É–Ω–∏–∫–∞–ª–∏–∑–∏—Ä—É–µ–º, —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞
    seen = set()
    uniq: List[str] = []
    for b in bases:
        k = b.strip()
        if not k:
            continue
        if k not in seen:
            seen.add(k)
            uniq.append(k)
    return uniq

def _tables_raw_by_bases(uid: int, doc_id: int, bases: List[str], rows_limit_effective: int) -> List[Dict[str, Any]]:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç JSON-–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü –ø–æ —Å–ø–∏—Å–∫—É –±–∞–∑–æ–≤—ã—Ö section_path.
    """
    out: List[Dict[str, Any]] = []
    for base in bases:
        try:
            row_objs = _fetch_table_rows(uid, doc_id, base)
            if not row_objs:
                continue
            # –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ display
            first_line = None
            txt0 = (row_objs[0]["text"] or "").split("\n")[0]
            if txt0:
                first_line = " ‚Äî ".join([c.strip() for c in _split_cells(txt0) if c.strip()])

            # –ø–æ–ø—Ä–æ–±—É–µ–º –¥–æ—Å—Ç–∞—Ç—å attrs –∏–∑ –ø–µ—Ä–≤–æ–π –ø–æ–¥—Ö–æ–¥—è—â–µ–π –∑–∞–ø–∏—Å–∏ table/table_row
            con = get_conn()
            cur = con.cursor()
            has_attrs = _table_has_columns(con, "chunks", ["attrs"])
            if has_attrs:
                cur.execute(
                    """
                    SELECT attrs, page FROM chunks
                    WHERE owner_id=? AND doc_id=? AND (section_path=? OR section_path LIKE ? || ' [row %')
                    ORDER BY id ASC LIMIT 1
                    """,
                    (uid, doc_id, base, base),
                )
            else:
                cur.execute(
                    """
                    SELECT page FROM chunks
                    WHERE owner_id=? AND doc_id=? AND (section_path=? OR section_path LIKE ? || ' [row %')
                    ORDER BY id ASC LIMIT 1
                    """,
                    (uid, doc_id, base, base),
                )
            r = cur.fetchone()
            con.close()

            attrs_json = (r["attrs"] if (has_attrs and r and "attrs" in r.keys()) else None)
            page = r["page"] if r else None
            if isinstance(attrs_json, dict):
                attrs_json = json.dumps(attrs_json, ensure_ascii=False)

            display = _compose_display(attrs_json, base, first_line)
            rows_texts = [ro["text"] for ro in row_objs]
            headers, matrix = _detect_header_and_matrix(rows_texts)

            payload = {
                "num": None,  # –Ω–æ–º–µ—Ä –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω (–Ω–µ –ø—Ä–æ—Å–∏–ª–∏ –ø–æ –Ω–æ–º–µ—Ä—É)
                "display": display,
                "where": {"page": page, "section_path": base},
                "headers": headers,
                "rows": matrix,
                "_rows_limit_effective": rows_limit_effective,
            }
            out.append(_apply_rows_and_char_limits(payload))
        except Exception:
            continue
    return out

def _make_tables_raw_for_prompt(
    owner_id: Optional[int],
    doc_id: Optional[int],
    question: str,
    include_all: Optional[bool] = None,
    rows_limit: Optional[int] = None,
) -> List[Dict[str, Any]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Å—Å–∏–≤ —Ç–∞–±–ª–∏—Ü (–≤ –≤–∏–¥–µ JSON-–ø–∞–∫–µ—Ç–æ–≤) –¥–ª—è —Å–µ–∫—Ü–∏–∏ [TablesRaw] –ø—Ä–æ–º–ø—Ç–∞.

    –°—Ü–µ–Ω–∞—Ä–∏–∏:
      1) –í–æ–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ —Ç–∞–±–ª–∏—Ü ‚Üí —Ç–∞—â–∏–º –ø–æ –Ω–æ–º–µ—Ä–∞–º.
      2) –ù–æ–º–µ—Ä–æ–≤ –Ω–µ—Ç, –Ω–æ —É–ø–æ–º—è–Ω—É—Ç–∞ ¬´–≥–ª–∞–≤–∞/—Ä–∞–∑–¥–µ–ª/–ø—É–Ω–∫—Ç ¬ß‚Ä¶¬ª –∏ ¬´—Ç–∞–±–ª–∏—Ü–∞¬ª ‚Üí —Ç–∞—â–∏–º –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞(–æ–≤).
    """
    if owner_id is None or doc_id is None:
        return []

    q = question or ""

    # –µ—Å–ª–∏ —Ñ–ª–∞–≥–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–ª–∏ —è–≤–Ω–æ ‚Äî –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Ö –∏–∑ —Ç–µ–∫—Å—Ç–∞ –≤–æ–ø—Ä–æ—Å–∞
    if include_all is None or rows_limit is None:
        inc_all_auto, rows_limit_auto = _extract_fulltable_request(q)
        if include_all is None:
            include_all = inc_all_auto
        if rows_limit is None:
            rows_limit = rows_limit_auto

    rows_limit_effective = min(
        FULL_TABLE_MAX_ROWS,
        rows_limit if rows_limit is not None else (FULL_TABLE_MAX_ROWS if include_all else 80),
    )

    # --- 1) –ü–æ–ø—ã—Ç–∫–∞ –ø–æ –Ω–æ–º–µ—Ä–∞–º
    want_nums: List[str] = []
    if extract_table_numbers:
        try:
            want_nums = extract_table_numbers(q) or []
        except Exception:
            want_nums = []
    out: List[Dict[str, Any]] = []
    if want_nums:
        for num in want_nums:
            try:
                anchor = _find_table_anchor(owner_id, doc_id, num)
                if not anchor:
                    continue
                page = anchor.get("page")
                sec = anchor.get("section_path") or ""
                base = _base_from_section(sec)

                row_objs = _fetch_table_rows(owner_id, doc_id, base)
                first_line = None
                if row_objs:
                    txt = (row_objs[0]["text"] or "").split("\n")[0]
                    if txt:
                        first_line = " ‚Äî ".join([c.strip() for c in _split_cells(txt) if c.strip()])
                attrs_json = anchor.get("attrs")
                if isinstance(attrs_json, dict):
                    attrs_json = json.dumps(attrs_json, ensure_ascii=False)
                display = _compose_display(attrs_json, base, first_line)

                rows_texts = [r["text"] for r in row_objs]
                headers, matrix = _detect_header_and_matrix(rows_texts)

                payload = {
                    "num": str(num),
                    "display": display,
                    "where": {"page": page, "section_path": base},
                    "headers": headers,
                    "rows": matrix,
                    "_rows_limit_effective": rows_limit_effective,
                }
                out.append(_apply_rows_and_char_limits(payload))
            except Exception:
                continue
        if out:
            return out  # –µ—Å–ª–∏ –Ω–∞—à–ª–∏ –ø–æ –Ω–æ–º–µ—Ä–∞–º ‚Äî —ç—Ç–æ–≥–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ

    # --- 2) –ù–æ–º–µ—Ä–æ–≤ –Ω–µ—Ç ‚Üí –ø—Ä–æ–±—É–µ–º –ø–æ –ø–æ–¥—Å–∫–∞–∑–∫–∞–º ¬´–≤ –≥–ª–∞–≤–µ/—Ä–∞–∑–¥–µ–ª–µ/¬ß ‚Ä¶¬ª
    sects: List[str] = []
    try:
        sects = extract_section_hints(q) or []
    except Exception:
        sects = []
    if not sects:
        return []  # –Ω–µ—Ç –Ω–∏ –Ω–æ–º–µ—Ä–æ–≤, –Ω–∏ –ø–æ–¥—Å–∫–∞–∑–æ–∫ —Ä–∞–∑–¥–µ–ª–∞ ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ —Ç–∞—â–∏–º

    # –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ö–∏–Ω—Ç–∞ –ø–æ–¥—Ç—è–Ω–µ–º –¥–æ SECTION_TABLES_MAX —Ç–∞–±–ª–∏—Ü
    collected: List[Dict[str, Any]] = []
    for hint in sects:
        try:
            bases = _distinct_table_bases_by_section(owner_id, doc_id, hint)
            if not bases:
                continue
            bases = bases[:SECTION_TABLES_MAX]
            pack = _tables_raw_by_bases(owner_id, doc_id, bases, rows_limit_effective)
            collected.extend(pack)
        except Exception:
            continue

    return collected

# ----------------------------- –°–±–æ—Ä–∫–∞ –±–ª–æ–∫–∞ —Ñ–∞–∫—Ç–æ–≤ -----------------------------

def _cards_for_tables(
    table_describe: List[Dict[str, Any]],
    *,
    owner_id: Optional[int] = None,
    doc_id: Optional[int] = None,
    lang: str = "ru",
    insights_top_k: int = 3,
    norm_numbers: bool = True,
) -> List[Dict[str, Any]]:
    """
    –ü—Ä–∏–≤–æ–¥–∏–º –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–∞–±–ª–∏—Ü –∫ –∫–æ–º–ø–∞–∫—Ç–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É; –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ analytics –∏ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
    –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ –∏–Ω—Å–∞–π—Ç—ã (–∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç + –Ω–µ–±–æ–ª—å—à–∏–µ —Ç–æ–ø—ã),
    –Ω–µ –Ω–∞—Ä—É—à–∞—è –ø—Ä–∏–Ω—Ü–∏–ø–∞ ¬´—Ç–æ–ª—å–∫–æ –∏–∑ —Ñ–∞–∫—Ç–æ–≤¬ª.
    """
    cards: List[Dict[str, Any]] = []

    for c in (table_describe or []):
        card = {
            "num": c.get("num"),
            "display": _normalize_numbers(c.get("display") or "") if norm_numbers else (c.get("display") or ""),
            "where": c.get("where") or {},
            "highlights": [
                _normalize_numbers(h) if norm_numbers else h
                for h in (c.get("highlights") or [])
            ][:2],
        }

        # –ú—è–≥–∫–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å owner_id/doc_id –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è.
        num = (c.get("num") or "").strip() if isinstance(c.get("num"), str) else None
        if analyze_table_by_num and owner_id is not None and doc_id is not None and num:
            try:
                res = analyze_table_by_num(owner_id, doc_id, num, top_k=max(1, insights_top_k), lang=lang)  # type: ignore
                if isinstance(res, dict) and res.get("ok"):
                    insight: Dict[str, Any] = {}

                    # –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç –æ—Ç—á—ë—Ç–∞ (—É–∂–∏–º–∞–µ–º)
                    text = res.get("text") or ""
                    if text:
                        insight["text"] = (_normalize_numbers if norm_numbers else (lambda x: x))(
                            _shorten(str(text), 420)
                        )

                    # –¢–æ–ø—ã –ø–æ —á–∏—Å–ª–æ–≤—ã–º –∫–æ–ª–æ–Ω–∫–∞–º (–¥–æ 2 –∫–æ–ª–æ–Ω–æ–∫, –∫–∞–∂–¥—ã–π —Ç–æ–ø ‚Äî –¥–æ insights_top_k —Å—Ç—Ä–æ–∫)
                    tops: List[Dict[str, Any]] = []
                    for col in (res.get("numeric_summary") or [])[:2]:
                        col_name = str(col.get("col") or "").strip() or "–ö–æ–ª–æ–Ω–∫–∞"
                        col_top = col.get("top") or []
                        small = []
                        for item in col_top[:insights_top_k]:
                            row_lbl = (_normalize_numbers if norm_numbers else (lambda x: x))(
                                str(item.get("row") or "")
                            )
                            val = item.get("value")
                            try:
                                small.append({"row": row_lbl, "value": float(val) if val is not None else None})
                            except Exception:
                                small.append({"row": row_lbl, "value": val})
                        if small:
                            tops.append({"col": (_normalize_numbers(col_name) if norm_numbers else col_name), "top": small})
                    if tops:
                        insight["tops"] = tops

                    if insight:
                        card["insights"] = insight
            except Exception:
                # –ú—è–≥–∫–∞—è –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è ‚Äî –±–µ–∑ –∏–Ω—Å–∞–π—Ç–æ–≤
                pass

        cards.append(card)
    return cards


def facts_to_prompt(
    facts: Dict[str, Any],
    *,
    rules: Optional[str] = None,
    owner_id: Optional[int] = None,
    doc_id: Optional[int] = None,
    lang: str = "ru",
    tables_raw: Optional[List[Dict[str, Any]]] = None,
    norm_numbers: bool = True,
) -> str:
    """
    –ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç dict `facts` (–∫–∞–∫ —Å–æ–±–∏—Ä–∞–µ—Ç—Å—è –≤ bot._gather_facts) –≤ —É—Å—Ç–æ–π—á–∏–≤—ã–π markdown-–±–ª–æ–∫
    –¥–ª—è –º–æ–¥–µ–ª–∏: [Facts] ... [Rules] ...
    –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –º–æ–∂–µ—Ç –≤–∫–ª—é—á–∞—Ç—å [TablesRaw] —Å –ø–æ–ª–Ω–æ–π –º–∞—Ç—Ä–∏—Ü–µ–π —Ç–∞–±–ª–∏—Ü –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    """
    parts: List[str] = []

    # ----- –ü–æ–¥–ø—É–Ω–∫—Ç—ã (Items) -----
    # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –¥–≤–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞: facts['coverage']['items'] (–∫–∞–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç retrieve_coverage)
    # –∏ –ø–ª–æ—Å–∫–∏–π facts['items'] (–µ—Å–ª–∏ –∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é —Å–ª–æ–µ–º-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º).
    items_src = (
        ((facts or {}).get("coverage") or {}).get("items")
        or (facts or {}).get("items")
        or []
    )
    if items_src:
        lines: List[str] = []
        for it in items_src[:25]:
            if isinstance(it, dict):
                idx = it.get("id") or it.get("index")
                text = it.get("ask") or it.get("text") or ""
                if idx is not None:
                    lines.append(f"{idx}) {(_normalize_numbers(text) if norm_numbers else text)}")
                else:
                    lines.append(f"- {(_normalize_numbers(text) if norm_numbers else text)}")
            else:
                s = str(it)
                lines.append(f"- {(_normalize_numbers(s) if norm_numbers else s)}")
        # –û—Ç–¥–µ–ª—å–Ω–∞—è —Å–µ–∫—Ü–∏—è, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å —è–≤–Ω–æ –ø–æ–Ω–∏–º–∞–ª–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞
        parts.append("- Items:\n  " + "\n  ".join(lines))

    # ----- –¢–∞–±–ª–∏—Ü—ã -----
    raw_tables = (facts or {}).get("tables") or {}
    tables: Dict[str, Any] = raw_tables if isinstance(raw_tables, dict) else {}

    # –µ—Å—Ç—å –ª–∏ –•–û–¢–¨ –ö–ê–ö–ò–ï-–¢–û —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—á–Ω—ã–µ —Ñ–∞–∫—Ç—ã?
    has_table_facts = False
    if tables:
        if (tables.get("count") or 0) > 0:
            has_table_facts = True
        if tables.get("list"):
            has_table_facts = True
        if tables.get("describe"):
            has_table_facts = True

    # –Ω–∞ –±—É–¥—É—â–µ–µ: –µ—Å–ª–∏ –≥–¥–µ-—Ç–æ –æ—Ç–¥–µ–ª—å–Ω–æ –ø–æ–ª–æ–∂–∏–ª–∏ tables_raw –≤ facts
    if not has_table_facts and (facts or {}).get("tables_raw"):
        has_table_facts = True

    if has_table_facts:
        block: List[str] = []
        if "count" in tables:
            block.append(f"count: {int(tables.get('count') or 0)}")
        if tables.get("list"):
            block.append(
                "list:\n"
                + _md_list(tables["list"], 25, tables.get("more", 0), norm_numbers=norm_numbers)
            )
        if tables.get("describe"):
            cards = _cards_for_tables(
                tables.get("describe") or [],
                owner_id=owner_id,
                doc_id=doc_id,
                lang=lang,
                norm_numbers=norm_numbers,
            )
            block.append("describe:\n" + json.dumps(cards, ensure_ascii=False, indent=2))
        parts.append("- Tables:\n  " + "\n  ".join(block))


        # ----- –†–∏—Å—É–Ω–∫–∏ -----
    figures = (facts or {}).get("figures") or {}
    cards = figures.get("describe_cards") if figures else None
    describe_lines = (figures.get("describe") or []) if figures else []

    if cards or describe_lines:
        # –ï—Å–ª–∏ –≤ –∏–Ω—Ç–µ–Ω—Ç–∞—Ö/—Ñ–∞–∫—Ç–∞—Ö —Å—Ç–æ–∏—Ç —Ñ–ª–∞–≥ single_only ‚Äî —Å—Ñ–æ–∫—É—Å–∏—Ä—É–µ–º—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ –Ω—É–∂–Ω–æ–º(—ã—Ö) –Ω–æ–º–µ—Ä–µ(–∞—Ö)
        try:
            focus_nums = _figure_focus_from_facts(facts)
        except Exception:
            focus_nums = []

        # —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–∞—Ä—Ç–æ—á–µ–∫ –ø–æ –Ω–æ–º–µ—Ä–∞–º, –µ—Å–ª–∏ –µ—Å—Ç—å —Ñ–æ–∫—É—Å
        if cards and focus_nums:
            focus_set = {n for n in focus_nums if n}
            filtered_cards: List[Dict[str, Any]] = []
            for c in cards:
                num = c.get("num") or c.get("label")
                if not num:
                    continue
                norm = _normalize_fig_num_local(str(num))
                if norm in focus_set:
                    filtered_cards.append(c)
            if filtered_cards:
                cards = filtered_cards

        block: List[str] = []

        # –ö–∞—Ä—Ç–æ—á–∫–∏ –æ—Ç vision_analyzer (describe_cards)
        if cards:
            for c in cards[:25]:
                title = c.get("title") or c.get("display") or "–†–∏—Å—É–Ω–æ–∫"
                desc = c.get("description") or ""
                values = c.get("values") or []  # –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç vision_analyzer

                # –ó–∞–≥–æ–ª–æ–≤–æ–∫
                block.append(f"- **{title}**")

                # –ó–Ω–∞—á–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å —è–≤–Ω—ã–π —Å–ø–∏—Å–æ–∫)
                if values:
                    vals = ", ".join(values)
                    block.append(f"  –ó–Ω–∞—á–µ–Ω–∏—è: {vals}")

                # –û–ø–∏—Å–∞–Ω–∏–µ
                if desc:
                    block.append(f"  –û–ø–∏—Å–∞–Ω–∏–µ: {desc}")

        # –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç facts['figures']['describe'] (—Å—Ç–∞—Ä—ã–π/—Ä–µ–∑–µ—Ä–≤–Ω—ã–π –ø—É—Ç—å)
        if describe_lines:
            # –µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω —Ä–µ–∂–∏–º single_only ‚Äî –æ—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ –ø—Ä–æ –Ω—É–∂–Ω—ã–π(–µ) –Ω–æ–º–µ—Ä(–∞)
            lines = _filter_lines_for_figure_focus(describe_lines, focus_nums or [])
            for s in lines[:25]:
                txt = _normalize_numbers(str(s)) if norm_numbers else str(s)
                block.append(f"- {txt}")

        if block:
            parts.append("- Figures:\n  " + "\n  ".join(block))




    # ----- –ò—Å—Ç–æ—á–Ω–∏–∫–∏ -----
    sources = (facts or {}).get("sources") or {}
    if sources:
        block = [f"count: {int(sources.get('count') or 0)}"]
        if sources.get("list"):
            block.append("list:\n" + _md_list(sources.get("list") or [], 25, sources.get("more", 0), norm_numbers=norm_numbers))
        parts.append("- Sources:\n  " + "\n  ".join(block))

    # ----- –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å -----
    if "practical_present" in (facts or {}):
        parts.append(f"- PracticalPartPresent: {bool(facts.get('practical_present'))}")

    # ----- –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ -----
    if (facts or {}).get("summary_text"):
        st = str(facts["summary_text"])
        # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–æ–ª–Ω—ã–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥ –æ—Ç summarizer
        parts.append("- Summary:\n  " + st.replace("\n", "\n  "))

    # ----- –í–µ—Ä–±–∞—Ç–∏–º-—Ü–∏—Ç–∞—Ç—ã (—à–∏–Ω–≥–ª—ã) -----
    if (facts or {}).get("verbatim_hits"):
        hits_md = []
        for h in facts["verbatim_hits"]:
            page = h.get("page")
            sec = (h.get("section_path") or "").strip()
            page_str = (str(page) if page is not None else "?")
            where = f'–≤ —Ä–∞–∑–¥–µ–ª–µ ¬´{sec}¬ª, —Å—Ç—Ä. {page_str}' if sec else f'–Ω–∞ —Å—Ç—Ä. {page_str}'
            snippet = (_normalize_numbers(h.get("snippet") or "") if norm_numbers else (h.get("snippet") or ""))
            hits_md.append(f"- Match {where}: ¬´{snippet}¬ª")
        parts.append("- Citations:\n  " + "\n  ".join(hits_md))

    # ----- –û–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç -----
    if (facts or {}).get("general_ctx"):
        ctx = str(facts.get("general_ctx") or "")
        ctx = (_normalize_numbers(_shorten(ctx, 1500)) if norm_numbers else _shorten(ctx, 1500))
        parts.append("- Context:\n  " + ctx.replace("\n", "\n  "))

    # ----- –ü–æ–ª–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É -----
    if tables_raw:
        try:
            payload = json.dumps(tables_raw, ensure_ascii=False)  # —É–∂–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–æ –ø–æ —Å–∏–º–≤–æ–ª–∞–º/—Å—Ç—Ä–æ–∫–∞–º
        except Exception:
            payload = json.dumps([], ensure_ascii=False)
        parts.append("- TablesRaw:\n  " + payload.replace("\n", "\n  "))

    facts_md = "[Facts]\n" + "\n".join(parts) + "\n\n[Rules]\n" + (rules or _DEFAULT_RULES)
    return facts_md

# ----------------------------- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–∏–º-—É—Ç–∏–ª—ã -----------------------------

def _extract_ids_from_facts(facts: Dict[str, Any]) -> tuple[Optional[int], Optional[int]]:
    owner_id = (
        facts.get("owner_id")
        or facts.get("_owner_id")
        or (facts.get("meta") or {}).get("owner_id")
    )
    doc_id = (
        facts.get("doc_id")
        or facts.get("_doc_id")
        or (facts.get("meta") or {}).get("doc_id")
    )
    try:
        owner_id = int(owner_id) if owner_id is not None else None
    except Exception:
        owner_id = None
    try:
        doc_id = int(doc_id) if doc_id is not None else None
    except Exception:
        doc_id = None
    return owner_id, doc_id

def _smart_cut_point(s: str, limit: int) -> int:
    if len(s) <= limit:
        return len(s)
    cut = s.rfind("\n", 0, limit)
    if cut == -1:
        cut = s.rfind(". ", 0, limit)
    if cut == -1:
        cut = s.rfind(" ", 0, limit)
    if cut == -1:
        cut = limit
    return max(1, cut)

def _chunk_text(s: str, maxlen: int = 480) -> Iterable[str]:
    s = s or ""
    i = 0
    n = len(s)
    if n == 0:
        return []
    while i < n:
        cut = _smart_cut_point(s[i:], maxlen)
        yield s[i:i+cut]
        i += cut

async def _aiter_any(obj: Union[str, Iterable[str], AsyncIterable[str]]) -> AsyncIterable[str]:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ª—é–±–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫ –≤ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ —Å—Ç—Ä–æ–∫.
    """
    if isinstance(obj, str):
        for part in _chunk_text(obj, 480):
            yield part
            await asyncio.sleep(0)
        return

    if hasattr(obj, "__aiter__"):
        async for x in obj:  # type: ignore
            if x:
                yield str(x)
        return

    if hasattr(obj, "__iter__"):
        for x in obj:  # type: ignore
            if x:
                yield str(x)
            await asyncio.sleep(0)
        return

# ----------------------------- –ü—É–±–ª–∏—á–Ω–æ–µ API -----------------------------

# –í–æ–ø—Ä–æ—Å –≤–æ–æ–±—â–µ –ø—Ä–æ —Ç–∞–±–ª–∏—Ü—É?
# –í–æ–ø—Ä–æ—Å –≤–æ–æ–±—â–µ –ø—Ä–æ —Ç–∞–±–ª–∏—Ü—É?
_ASKS_TABLE_RE = re.compile(r"(?i)\b—Ç–∞–±–ª–∏—Ü[–∞-—è]*\b|\btable\b")

def _asks_about_table(question: str) -> bool:
    q = (question or "").strip()
    return bool(_ASKS_TABLE_RE.search(q))


def _has_any_table_facts(facts: Dict[str, Any]) -> bool:
    """
    –ü–æ–Ω–∏–º–∞–µ–º, –µ—Å—Ç—å –ª–∏ –≤ —Ñ–∞–∫—Ç–∞—Ö —Ö–æ—Ç—å –∫–∞–∫–∞—è-—Ç–æ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∞ –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º.
    –ù—É–∂–µ–Ω, —á—Ç–æ–±—ã –Ω–µ –æ—Ç–¥–∞–≤–∞—Ç—å –≤ –º–æ–¥–µ–ª—å –≤–æ–ø—Ä–æ—Å –ø—Ä–æ —Ç–∞–±–ª–∏—Ü—É –±–µ–∑ —Ç–∞–±–ª–∏—Ü.
    """
    if not isinstance(facts, dict):
        return False

    tables = (facts.get("tables") or {})
    if not isinstance(tables, dict):
        return False

    if (tables.get("count") or 0) > 0:
        return True
    if tables.get("list"):
        return True
    if tables.get("describe"):
        return True

    # –Ω–∞ –±—É–¥—É—â–µ–µ: –µ—Å–ª–∏ –≥–¥–µ-—Ç–æ –≤—Ä—É—á–Ω—É—é –ø–æ–ª–æ–∂–∏–ª–∏ tables_raw
    if facts.get("tables_raw"):
        return True

    return False


def _has_any_figure_facts(facts: Dict[str, Any]) -> bool:
    """
    –ú—è–≥–∫–∏–π –∞–Ω–∞–ª–æ–≥ _has_any_table_facts –¥–ª—è —Ä–∏—Å—É–Ω–∫–æ–≤.
    –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ ¬´—Å—Ç—Ä–∞—Ö–æ–≤–∫—É¬ª: –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Ñ–æ—Ä–º—É–ª–∏—Ä—É—é—Ç –∫–∞–∫ –ø—Ä–æ —Ç–∞–±–ª–∏—Ü—É,
    –Ω–æ –≤ —Ñ–∞–∫—Ç–∞—Ö –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –±–ª–æ–∫ –ø–æ —Ä–∏—Å—É–Ω–∫–∞–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ç–∞–±–ª–∏—Ü–∞ –∫–∞–∫ –∫–∞—Ä—Ç–∏–Ω–∫–∞),
    –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç.
    """
    if not isinstance(facts, dict):
        return False

    figures = (facts.get("figures") or {})
    if not isinstance(figures, dict):
        return False

    if (figures.get("count") or 0) > 0:
        return True
    if figures.get("list"):
        return True
    if figures.get("describe_cards"):
        return True
    if figures.get("describe"):
        return True

    return False

def _extract_fulltable_request(question: str) -> tuple[bool, Optional[int]]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –ø—Ä–æ—Å–∏–ª–∏ –ª–∏ ¬´–≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è/–ø–æ–ª–Ω–æ—Å—Ç—å—é¬ª –∏/–∏–ª–∏ –ª–∏–º–∏—Ç —Å—Ç—Ä–æ–∫.
    """
    q = question or ""
    include_all = bool(TABLE_ALL_VALUES_RE.search(q))
    rows_limit = None
    m = TABLE_ROWS_LIMIT_RE.search(q)
    if m:
        for g in m.groups():
            if g and g.isdigit():
                try:
                    n = int(g)
                    if n > 0:
                        rows_limit = n
                        break
                except Exception:
                    pass
    return include_all, rows_limit

def _want_exact_numbers(question: str, facts: Dict[str, Any]) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –ø—Ä–æ—Å–∏–ª–∏ –ª–∏ –≤—ã–≤–µ—Å—Ç–∏ —á–∏—Å–ª–∞ ¬´–∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ¬ª (–±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏).
    –ò—Å—Ç–æ—á–Ω–∏–∫–∏ —Å–∏–≥–Ω–∞–ª–∞:
      - —Ñ—Ä–∞–∑–∞ –≤ –≤–æ–ø—Ä–æ—Å–µ (EXACT_NUMBERS_RE),
      - –ª–∏–±–æ —è–≤–Ω—ã–π —Ñ–ª–∞–≥ facts['exact_numbers']=True (–Ω–∞ –±—É–¥—É—â–µ–µ).
    """
    if isinstance(facts, dict) and bool(facts.get("exact_numbers")):
        return True
    q = (question or "")
    try:
        return bool(EXACT_NUMBERS_RE.search(q))
    except Exception:
        return False

def generate_answer(
    question: str,
    facts: Dict[str, Any],
    *,
    language: str = "ru",
    pass_score: int = 85,  # –æ—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏, —Å–µ–π—á–∞—Å –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
    rules_override: Optional[str] = None,
) -> str:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –±–∏–ª–¥–µ—Ä —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (–Ω–µ—Å—Ç—Ä–∏–º–æ–≤—ã–π –ø—É—Ç—å):
      1) –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —á–∏—Å–ª–∞ –≤ –±–ª–æ–∫–µ —Ñ–∞–∫—Ç–æ–≤, –Ω–æ –æ—Ç–∫–ª—é—á–∞–µ—Ç —ç—Ç–æ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ ¬´–∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ¬ª;
      2) —Å–æ–±–∏—Ä–∞–µ—Ç —É—Å—Ç–æ–π—á–∏–≤—ã–π –±–ª–æ–∫ –ø—Ä–æ–º–ø—Ç–∞ (Facts + Rules), –≤–∫–ª—é—á–∞—è TablesRaw –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏;
      3) –æ–±—Ä–∞—â–∞–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é –∫ chat_with_gpt –±–µ–∑ ACE;
      4) –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç.
    """
    q = (question or "").strip()
    if not q:
        return "–í–æ–ø—Ä–æ—Å –ø—É—Å—Ç–æ–π. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —á—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–∞–∑–æ–±—Ä–∞—Ç—å –ø–æ –í–ö–†."

    # üí° –ì–∞—Ä–¥: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø—Ä–æ —Ç–∞–±–ª–∏—Ü—É, –∞ —Ñ–∞–∫—Ç–æ–≤ –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º –Ω–µ—Ç –≤–æ–æ–±—â–µ.
    # –í–º–µ—Å—Ç–æ —Ñ–∞–Ω—Ç–∞–∑–∏–π –º–æ–¥–µ–ª–∏ —Å—Ä–∞–∑—É –ø—Ä–æ—Å–∏–º —É—Ç–æ—á–Ω–∏—Ç—å –Ω–æ–º–µ—Ä.
    if _asks_about_table(q) and not _has_any_table_facts(facts):
        if not _has_any_figure_facts(facts):
            return (
                "–Ø –Ω–µ –≤–∏–∂—É –≤ —Ñ–∞–∫—Ç–∞—Ö, –∫ –∫–∞–∫–æ–π –∏–º–µ–Ω–Ω–æ —Ç–∞–±–ª–∏—Ü–µ –º–æ–∂–Ω–æ –ø—Ä–∏–≤—è–∑–∞—Ç—å—Å—è.\n"
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –Ω–æ–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´—Ç–∞–±–ª–∏—Ü–∞ 2.4¬ª) "
                "–∏–ª–∏ –ø—Ä–∏—à–ª–∏—Ç–µ —Å–∫—Ä–∏–Ω / —Ç–æ—á–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫."
            )

    owner_id, doc_id = _extract_ids_from_facts(facts)
    want_exact = _want_exact_numbers(q, facts)

    # ‚ùó –¢—è–Ω–µ–º TablesRaw (–ø–æ –Ω–æ–º–µ—Ä–∞–º –∏–ª–∏ –ø–æ ¬´–≥–ª–∞–≤–µ/—Ä–∞–∑–¥–µ–ª—É¬ª)
    include_all, rows_limit = _extract_fulltable_request(q)
    tables_raw: List[Dict[str, Any]] = _make_tables_raw_for_prompt(
        owner_id,
        doc_id,
        q,
        include_all=include_all,
        rows_limit=rows_limit,
    )

    ctx = facts_to_prompt(
        facts,
        rules=rules_override,
        owner_id=owner_id,
        doc_id=doc_id,
        lang=language,
        tables_raw=tables_raw if tables_raw else None,
        norm_numbers=not want_exact,
    )

    # --- –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ –º–æ–¥–µ–ª–∏ –±–µ–∑ ACE ---
    system_prompt = (
        "–¢—ã ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —É–º–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –¥–∏–ø–ª–æ–º–Ω—ã–º —Ä–∞–±–æ—Ç–∞–º –∏ –Ω–∞—É—á–Ω—ã–º —Ç–µ–∫—Å—Ç–∞–º.\n"
        "–¢–µ–±–µ –¥–∞–Ω –±–ª–æ–∫ —Ñ–∞–∫—Ç–æ–≤ [Facts] –∏–∑ —Ä–∞–±–æ—Ç—ã –∏ –ø—Ä–∞–≤–∏–ª–∞ –æ—Ç–≤–µ—Ç–∞.\n"
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –¥–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–Ω—ã–π, —Å–≤—è–∑–Ω—ã–π –∏ –ø–æ–Ω—è—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\n"
        "–í –ü–ï–†–í–£–Æ –û–ß–ï–†–ï–î–¨ –æ–ø–∏—Ä–∞–π—Å—è –Ω–∞ —Ñ–∞–∫—Ç—ã –∏–∑ [Facts]. –ï—Å–ª–∏ –∫–∞–∫–∏—Ö-—Ç–æ –¥–µ—Ç–∞–ª–µ–π —Ç–∞–º –Ω–µ—Ç,\n"
        "—Ç—ã –º–æ–∂–µ—à—å –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—â–∏–µ –∑–Ω–∞–Ω–∏—è –ø–æ —Ç–µ–º–µ, –Ω–æ –Ω–µ –ø—Ä–∏–ø–∏—Å—ã–≤–∞–π –¥–æ–∫—É–º–µ–Ω—Ç—É\n"
        "—Ç–æ–≥–æ, —á–µ–≥–æ –≤ –Ω—ë–º –Ω–µ—Ç.\n"
        "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç –ø–æ–¥ –∑–∞–ø—Ä–æ—Å: –∏—Å–ø–æ–ª—å–∑—É–π —Å–ø–∏—Å–∫–∏, –ø–æ–¥–ø—É–Ω–∫—Ç—ã –∏ –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏, –∫–æ–≥–¥–∞ —ç—Ç–æ —É–º–µ—Å—Ç–Ω–æ.\n"
        "–ï—Å–ª–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ —É–ø–æ–º—è–Ω—É—Ç—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã, —Ä–∏—Å—É–Ω–∫–∏ –∏–ª–∏ –≥–ª–∞–≤—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–æ–ø–∏—à–∏ —Ä–∏—Å—É–Ω–æ–∫ 2.2, "
        "—Ç–∞–±–ª–∏—Ü—É 2.1 –∏ –≥–ª–∞–≤—É 1¬ª), –¥–µ–ª–∞–π –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–æ–¥–ø—É–Ω–∫—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –∏ "
        "–ø–æ—è—Å–Ω—è–π –∏—Ö —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ."
    )



    if chat_with_gpt is None:
        # –∂—ë—Å—Ç–∫–∏–π —Ñ–æ–ª–±—ç–∫ ‚Äî –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–π–¥–∂–µ—Å—Ç —Ñ–∞–∫—Ç–æ–≤
        fallback = [
            "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –º–æ–¥–µ–ª–∏. –ù–∏–∂–µ ‚Äî –∫—Ä–∞—Ç–∫–∏–π –∫–æ–Ω—Å–ø–µ–∫—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤:",
            "",
            ctx[:4000],
        ]
        return "\n".join(fallback)

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "assistant", "content": ctx},
        {"role": "user", "content": q},
    ]

    try:
        reply = chat_with_gpt(  # type: ignore
            messages,
            temperature=0.2,
            max_tokens=getattr(Cfg, "FINAL_MAX_TOKENS", 1600),
        )
        return _headings_to_bold((reply or "").strip())
    except Exception:
        fallback = [
            "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª—å—é. –ù–∏–∂–µ ‚Äî –∫—Ä–∞—Ç–∫–∏–π –∫–æ–Ω—Å–ø–µ–∫—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤:",
            "",
            ctx[:4000],
        ]
        return "\n".join(fallback)


async def generate_answer_stream(
    question: str,
    facts: Dict[str, Any],
    *,
    language: str = "ru",
    pass_score: int = 85,  # –æ—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    rules_override: Optional[str] = None,
    temperature: float = 0.2,
    max_tokens: int = getattr(Cfg, "FINAL_MAX_TOKENS", 1600),
) -> AsyncIterable[str]:
    """
    –°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã–π –±–∏–ª–¥–µ—Ä —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (–∫–æ—Ä—É—Ç–∏–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç async-–∏—Ç–µ—Ä–∞—Ç–æ—Ä):
      - —Å–æ–±–∏—Ä–∞–µ—Ç Facts+Rules (+ TablesRaw –µ—Å–ª–∏ –Ω—É–∂–Ω–æ, –ø–æ –Ω–æ–º–µ—Ä–∞–º –∏–ª–∏ –ø–æ ¬´–≥–ª–∞–≤–µ/—Ä–∞–∑–¥–µ–ª—É¬ª);
      - —É—á–∏—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –Ω–∞ ¬´—Ç–æ—á–Ω—ã–µ —á–∏—Å–ª–∞ –∫–∞–∫ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ¬ª (–æ—Ç–∫–ª—é—á–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –≤ –ø—Ä–æ–º–ø—Ç–µ);
      - —Å—Ç—Ä–∏–º–∏—Ç –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ chat_with_gpt_stream (–±–µ–∑ ACE);
      - –µ—Å–ª–∏ —Å—Ç—Ä–∏–º –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî —ç–º—É–ª–∏—Ä—É–µ—Ç —Å—Ç—Ä–∏–º, –Ω–∞—Ä–µ–∑–∞—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç generate_answer.
    """
    q = (question or "").strip()
    if not q:
        async def _empty():
            yield "–í–æ–ø—Ä–æ—Å –ø—É—Å—Ç–æ–π. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —á—Ç–æ –∏–º–µ–Ω–Ω–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–∞–∑–æ–±—Ä–∞—Ç—å –ø–æ –í–ö–†."
        return _empty()

    # üí° –¢–æ—Ç –∂–µ –≥–∞—Ä–¥, —á—Ç–æ –∏ –≤ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏:
    # –µ—Å–ª–∏ –ø—Ä–æ —Ç–∞–±–ª–∏—Ü—É —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç, –∞ —Ç–∞–±–ª–∏—Ü –≤ —Ñ–∞–∫—Ç–∞—Ö –Ω–µ—Ç ‚Äî —Å—Ä–∞–∑—É –ø—Ä–æ—Å–∏–º —É—Ç–æ—á–Ω–∏—Ç—å –Ω–æ–º–µ—Ä.
    if _asks_about_table(q) and not _has_any_table_facts(facts):
        if not _has_any_figure_facts(facts):
            async def _need_table_num():
                yield (
                    "–Ø –Ω–µ –≤–∏–∂—É –≤ —Ñ–∞–∫—Ç–∞—Ö, –∫ –∫–∞–∫–æ–π –∏–º–µ–Ω–Ω–æ —Ç–∞–±–ª–∏—Ü–µ –º–æ–∂–Ω–æ –ø—Ä–∏–≤—è–∑–∞—Ç—å—Å—è.\n"
                    "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –Ω–æ–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´—Ç–∞–±–ª–∏—Ü–∞ 2.4¬ª) "
                    "–∏–ª–∏ –ø—Ä–∏—à–ª–∏—Ç–µ —Å–∫—Ä–∏–Ω / —Ç–æ—á–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫."
                )
            return _need_table_num()

    owner_id, doc_id = _extract_ids_from_facts(facts)
    want_exact = _want_exact_numbers(q, facts)

    # –ü–æ–ª–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã: –ø–æ –Ω–æ–º–µ—Ä—É –∏–ª–∏ –ø–æ –ø–æ–¥—Å–∫–∞–∑–∫–µ ¬´–≤ –≥–ª–∞–≤–µ/—Ä–∞–∑–¥–µ–ª–µ¬ª
    include_all, rows_limit = _extract_fulltable_request(q)
    tables_raw: List[Dict[str, Any]] = _make_tables_raw_for_prompt(
        owner_id,
        doc_id,
        q,
        include_all=include_all,
        rows_limit=rows_limit,
    )

    ctx = facts_to_prompt(
        facts,
        rules=rules_override,
        owner_id=owner_id,
        doc_id=doc_id,
        lang=language,
        tables_raw=tables_raw if tables_raw else None,
        norm_numbers=not want_exact,
    )

    system_prompt = (
        "–¢—ã ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —É–º–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –¥–∏–ø–ª–æ–º–Ω—ã–º —Ä–∞–±–æ—Ç–∞–º –∏ –Ω–∞—É—á–Ω—ã–º —Ç–µ–∫—Å—Ç–∞–º.\n"
        "–¢–µ–±–µ –¥–∞–Ω –±–ª–æ–∫ —Ñ–∞–∫—Ç–æ–≤ [Facts] –∏–∑ —Ä–∞–±–æ—Ç—ã –∏ –ø—Ä–∞–≤–∏–ª–∞ –æ—Ç–≤–µ—Ç–∞.\n"
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –¥–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–Ω—ã–π, —Å–≤—è–∑–Ω—ã–π –∏ –ø–æ–Ω—è—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\n"
        "–í –ü–ï–†–í–£–Æ –û–ß–ï–†–ï–î–¨ –æ–ø–∏—Ä–∞–π—Å—è –Ω–∞ —Ñ–∞–∫—Ç—ã –∏–∑ [Facts]. –ï—Å–ª–∏ –∫–∞–∫–∏—Ö-—Ç–æ –¥–µ—Ç–∞–ª–µ–π —Ç–∞–º –Ω–µ—Ç,\n"
        "—Ç—ã –º–æ–∂–µ—à—å –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—â–∏–µ –∑–Ω–∞–Ω–∏—è –ø–æ —Ç–µ–º–µ, –Ω–æ –Ω–µ –ø—Ä–∏–ø–∏—Å—ã–≤–∞–π –¥–æ–∫—É–º–µ–Ω—Ç—É\n"
        "—Ç–æ–≥–æ, —á–µ–≥–æ –≤ –Ω—ë–º –Ω–µ—Ç.\n"
        "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç –ø–æ–¥ –∑–∞–ø—Ä–æ—Å: –∏—Å–ø–æ–ª—å–∑—É–π —Å–ø–∏—Å–∫–∏, –ø–æ–¥–ø—É–Ω–∫—Ç—ã –∏ –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏, –∫–æ–≥–¥–∞ —ç—Ç–æ —É–º–µ—Å—Ç–Ω–æ.\n"
        "–ï—Å–ª–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ —É–ø–æ–º—è–Ω—É—Ç—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã, —Ä–∏—Å—É–Ω–∫–∏ –∏–ª–∏ –≥–ª–∞–≤—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–æ–ø–∏—à–∏ —Ä–∏—Å—É–Ω–æ–∫ 2.2, "
        "—Ç–∞–±–ª–∏—Ü—É 2.1 –∏ –≥–ª–∞–≤—É 1¬ª), –¥–µ–ª–∞–π –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–æ–¥–ø—É–Ω–∫—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –∏ "
        "–ø–æ—è—Å–Ω—è–π –∏—Ö —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ."
    )



    # 1) –ù–æ—Ä–º–∞–ª—å–Ω—ã–π –ø—É—Ç—å ‚Äî —Å—Ç—Ä–∏–º –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –º–æ–¥–µ–ª–∏
    if chat_with_gpt_stream is not None:
        try:
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "assistant", "content": ctx},
                {"role": "user", "content": q},
            ]
            stream_obj = chat_with_gpt_stream(
                messages,
                temperature=temperature,
                max_tokens=max_tokens,  # type: ignore
            )

            async def _fmt():
                async for chunk in _aiter_any(stream_obj):
                    yield _headings_to_bold(chunk)
            return _fmt()

        except Exception:
            # –ø–æ–π–¥—ë–º –≤ —ç–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç—Ä–∏–º
            pass

    # 2) –§–æ–ª–±—ç–∫ ‚Äî —ç–º—É–ª–∏—Ä—É–µ–º —Å—Ç—Ä–∏–º —á–µ—Ä–µ–∑ generate_answer
    async def _emulated() -> AsyncIterable[str]:  # type: ignore
        try:
            final = generate_answer(
                question=q,
                facts=facts,
                language=language,
                pass_score=pass_score,
                rules_override=rules_override,
            )
        except Exception:
            final = "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç."
        for part in _chunk_text(final, 480):
            yield part
            await asyncio.sleep(0)
    return _emulated()


def debug_digest(facts: Dict[str, Any]) -> str:
    """
    –ö–æ—Ä–æ—Ç–∫–∏–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –¥–∞–π–¥–∂–µ—Å—Ç –ø–æ —Ñ–∞–∫—Ç–∞–º ‚Äî —É–¥–æ–±–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å/–ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –≤ /diag.
    """
    parts = []
    tbl = (facts or {}).get("tables") or {}
    fig = (facts or {}).get("figures") or {}
    src = (facts or {}).get("sources") or {}

    parts.append(f"–¢–∞–±–ª–∏—Ü: {int(tbl.get('count') or 0)} (–ø–æ–∫–∞–∑–∞–Ω–æ: {len(tbl.get('list') or [])})")
    parts.append(f"–†–∏—Å—É–Ω–∫–æ–≤: {int(fig.get('count') or 0)} (–ø–æ–∫–∞–∑–∞–Ω–æ: {len(fig.get('list') or [])})")
    parts.append(f"–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {int(src.get('count') or 0)} (–ø–æ–∫–∞–∑–∞–Ω–æ: {len(src.get('list') or [])})")

    if facts.get("practical_present") is not None:
        parts.append(f"–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å: {'–¥–∞' if facts.get('practical_present') else '–Ω–µ—Ç'}")

    if facts.get("summary_text"):
        parts.append("–ï—Å—Ç—å –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ (summary_text).")

    if facts.get("general_ctx"):
        parts.append("–ï—Å—Ç—å –æ–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (general_ctx).")

    if facts.get("verbatim_hits"):
        parts.append(f"–ï—Å—Ç—å —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (verbatim_hits): {len(facts.get('verbatim_hits') or [])}")

    return "\n".join(parts)
